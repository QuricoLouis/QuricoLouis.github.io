{"meta":{"title":"QuricoLouis","subtitle":"QuricoLouisの博客","description":"本科 | 软件工程 | java后端开发","author":"QuricoLouis","url":"http://QuricoLouis.github.io","root":"/"},"pages":[{"title":"404","date":"2019-08-10T08:41:10.000Z","updated":"2021-07-29T15:54:31.389Z","comments":true,"path":"404.html","permalink":"http://quricolouis.github.io/404.html","excerpt":"","text":""},{"title":"","date":"2021-09-10T07:49:59.572Z","updated":"2021-09-10T03:19:58.226Z","comments":true,"path":"baidu_verify_code-sZvuEUvAh1.html","permalink":"http://quricolouis.github.io/baidu_verify_code-sZvuEUvAh1.html","excerpt":"","text":"3ff4406bb39519bfa5c261777a77fa91"},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2021-07-29T15:54:31.432Z","comments":true,"path":"archives/index.html","permalink":"http://quricolouis.github.io/archives/index.html","excerpt":"","text":""},{"title":"统计","date":"2020-10-31T02:11:28.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"census/index.html","permalink":"http://quricolouis.github.io/census/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-10-24T16:00:00.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"categories/index.html","permalink":"http://quricolouis.github.io/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2019-10-24T16:00:00.000Z","updated":"2021-07-29T15:54:31.432Z","comments":true,"path":"about/index.html","permalink":"http://quricolouis.github.io/about/index.html","excerpt":"","text":""},{"title":"留言板","date":"2019-10-24T16:00:00.000Z","updated":"2021-08-01T07:44:50.374Z","comments":true,"path":"contact/index.html","permalink":"http://quricolouis.github.io/contact/index.html","excerpt":"","text":"畅所欲言 在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链，一起交流学习！ 友链 QuricoLouisの友链信息 博客名称: QuricoLouisの博客 博客网址: http://QuricoLouis.github.io 博客头像: https://cdn.jsdelivr.net/gh/QuricoLouis/imgBed/blog/20210731104423.png 博客介绍: The harder you work, the luckier you will be"},{"title":"友链","date":"2019-07-19T08:42:10.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"friends/index.html","permalink":"http://quricolouis.github.io/friends/index.html","excerpt":"","text":""},{"title":"资源分享","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"resource/index.html","permalink":"http://quricolouis.github.io/resource/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"tags/index.html","permalink":"http://quricolouis.github.io/tags/index.html","excerpt":"","text":""},{"title":"放松一下","date":"2019-08-10T08:41:10.000Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/index.html","permalink":"http://quricolouis.github.io/List/index.html","excerpt":"","text":"影音资源共享"},{"title":"相册","date":"2021-07-29T15:54:31.392Z","updated":"2021-07-29T15:54:31.392Z","comments":true,"path":"List/galleries/index.html","permalink":"http://quricolouis.github.io/List/galleries/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.395Z","comments":true,"path":"List/tools/index.html","permalink":"http://quricolouis.github.io/List/tools/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/music/index.html","permalink":"http://quricolouis.github.io/List/music/index.html","excerpt":"","text":""},{"title":"视频","date":"2019-08-10T08:41:10.000Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/movies/index.html","permalink":"http://quricolouis.github.io/List/movies/index.html","excerpt":"","text":""},{"title":"乖巧小狗","date":"2021-07-29T15:54:31.392Z","updated":"2021-07-29T15:54:31.392Z","comments":true,"path":"List/galleries/乖巧小狗/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E4%B9%96%E5%B7%A7%E5%B0%8F%E7%8B%97/index.html","excerpt":"","text":""},{"title":"二次元风","date":"2021-07-29T15:54:31.392Z","updated":"2021-07-29T15:54:31.392Z","comments":true,"path":"List/galleries/二次元风/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E4%BA%8C%E6%AC%A1%E5%85%83%E9%A3%8E/index.html","excerpt":"","text":""},{"title":"动漫插画","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/动漫插画/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/index.html","excerpt":"","text":""},{"title":"动漫人物","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/动漫人物/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E4%BA%BA%E7%89%A9/index.html","excerpt":"","text":""},{"title":"动漫风景","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/动漫风景/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"城市风光","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/城市风光/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%9F%8E%E5%B8%82%E9%A3%8E%E5%85%89/index.html","excerpt":"","text":""},{"title":"清新花卉","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/清新花卉/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E6%B8%85%E6%96%B0%E8%8A%B1%E5%8D%89/index.html","excerpt":"","text":""},{"title":"炫酷跑车","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/炫酷跑车/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E7%82%AB%E9%85%B7%E8%B7%91%E8%BD%A6/index.html","excerpt":"","text":""},{"title":"璀璨星空","date":"2021-07-29T15:54:31.394Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/galleries/璀璨星空/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/index.html","excerpt":"","text":""},{"title":"甜美食品","date":"2021-07-29T15:54:31.394Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/galleries/甜美食品/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E7%94%9C%E7%BE%8E%E9%A3%9F%E5%93%81/index.html","excerpt":"","text":""},{"title":"呆萌猫咪","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/呆萌猫咪/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%91%86%E8%90%8C%E7%8C%AB%E5%92%AA/index.html","excerpt":"","text":""},{"title":"自然风景","date":"2021-07-29T15:54:31.394Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/galleries/自然风景/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E8%87%AA%E7%84%B6%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""}],"posts":[{"title":"海量数据处理问题总结","slug":"海量数据处理问题总结","date":"2021-09-13T03:28:44.845Z","updated":"2021-09-13T06:57:32.001Z","comments":true,"path":"posts/a3ce51c4.html","link":"","permalink":"http://quricolouis.github.io/posts/a3ce51c4.html","excerpt":"","text":"==此博客主要总结海量数据处理问题，如对海量数据处理方法不是很了解，可移步海量数据处理方法总结，如果对此博客分析数据计算不了解，可移步海量数据处理计算及算法实现总结== 方法回顾 分而治之 / Hash 映射 + Hash 统计 + 堆 / 快速 / 归并排序 双层桶划分 BitMap / Bloom Filter Trie 树 / 数据库索引 / 倒排索引 外排序 分布式处理之Hadoop / Mapreduce 面试问题总结给定 a、b 两个文件，各存放 50 亿个url，每个 url 各占 64 字节，内存限制是 4G，让你找出 a、b 文件共同的 url？100亿 * 64 byte = 6400 亿 byte = 640 GB，远大于内存限制。 方案一：算法思想：分而治之 / Hash 映射 + Hash 统计 使用哈希函数分流，即 hash(url) %1000，320GB 文件分到 1000 个小文件后, 每个平均是 320 MB. 这里运用两个哈希的性质： 优秀的哈希函数能保证映射的均匀，因此每个小文件的大小应该都是 320MB 左右。 同 key 必同桶，同桶不一定同 keys。因此a, b俩文件中相同的url一定在同一个小文件中。 对a，b映射的小文件 pair-by-pair 地进行比对，使用 java 中的 hashset, 来看是否有重复. 有重复的就输出写入到一个输出txt文件中. 方案二：算法思想：bitmit / bloom Filter 建立 bitmap，把每个 url 映射到 k 个 bit 上, 先把 a 的放进去, 再把 b 的url逐一映射进行检查, 如果重复, 就写出到文本文件上。相同的判断有一定的错误率, 这是bloomFilter 不完美的地方。 海量日志数据，提取出某日访问百度次数最多的那个IP。 方案：算法思想：分而治之 / Hash 映射 + Hash 统计 IP 地址最多有 2^32=4G 种取值情况，所以不能完全加载到内存中处理； 可以考虑采用”分而治之”的思想，按照 IP 地址的 Hash(IP)%1024 值，把海量 IP 日志分别存储到 1024 个小文件中。这样，每个小文件最多包含 4MB 个IP地址； 对于每一个小文件，可以构建一个 IP 为 key，出现次数为 value 的 HashMap，同时记录当前出现次数最多的那个 IP 地址； 可以得到 1024 个小文件中的出现次数最多的 IP，再依据常规的排序算法得到总体上出现次数最多的 IP； 拓展：找出 Top 100 的 IP 找出每个小文件的 top100, 然后再对所有小文件的 top100 进行内外结合排序(可以内部使用 quicksort,每个花费 O(nlgn)，然后外部使用多路归并算法，O(N) 时间). 100w个数中找出最大的100个数。 方案1：用一个含100个元素的最小堆完成。复杂度为O(100w*lg100)。 方案2：采用快速排序的思想，每次分割之后只考虑比轴大的一部分，知道比轴大的一部分在比 100 多的时候，采用传统排序算法排序，取前 100 个。复杂度为 O(100w*100)。 方案3：采用局部淘汰法。选取前 100 个元素，并排序，记为序列 L。然后一次扫描剩余的元素 x，与排好序的 100 个元素中最小的元素比，如果比这个最小的要大，那么把这个最小的元素删除，并把x利用插入排序的思想，插入到序列 L 中。依次循环，知道扫描了所有的元素。复杂度为 O(100w*100)。 有 10 个文件，每个文件 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求你按照 query 的频度排序。Top-K 算法问题变种 方案1：算法思想：Hash 映射 + Hash 统计 + 堆 / 快速 / 归并排序 Hash映射：顺序读取 10 个文件，按照 hash(query)%10 的结果将 query 写入到另外 10 个文件（记为a0，a1，..a9）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。 hashMap统计：找一台内存在 2G 左右的机器，依次对用 hashmap(query, query_count) 来统计每个 query 出现的次数。注：hash_map(query,query_count) 是用来统计每个query的出现次数，不是存储他们的值，出现一次，则count+1。 堆/快速/归并排序：利用快速/堆/归并排序按照出现次数进行排序，将排序好的query和对应的 query_cout 输出到文件中，这样得到了 10个 排好序的文件（记为）。最后，对这10个文件进行归并排序（内排序与外排序相结合） 方案2：算法思想：Trie 树 一般 query 的总量是有限的，只是重复的次数比较多而已，可能对于所有的 query，一次性就可以加入到内存了。这样，我们就可以采用 trie 树 / hash_map 等直接来统计每个 query 出现的次数，然后按出现次数做快速 / 堆 / 归并排序就可以了。 方案3：算法思想：Hadoop / Mapreduce 与方案1类似，但在做完 hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。 方案：算法思想：分而治之 / Hash 映射 + Hash 统计 / Trie 树 + 堆 / 快速 / 归并排序 分而治之/hash映射：顺序读文件中，对于每个词 x，取 hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,…x4999）中。这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。 hashmap统计：对每个小文件，采用 trie 树 / hashmap 等统计每个文件中出现的词以及相应的频率。 堆/归并排序：取出出现频率最大的 100 个词（可以用含 100 个结点的最小堆）后，再把100个词及相应的频率存入文件，这样又得到了 5000 个文件。最后就是把这5000个文件进行归并（类似于归并排序）的过程了。 在2.5亿个整数中找出不重复的整数，内存不足以容纳这2.5亿个整数 方案1：算法思想：分而治之 / Hash 映射 + Hash 统计 分而治之/hash映射 hashmap统计 找出所有value为1的key值 方案2：Bitmap / bloom Filter 采用 2-Bitmap（每个数分配 2bit，00 表示不存在，01 表示出现一次，10 表示多次，11 无意义）进行，共需内存 2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。 1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？ 方法1：分而治之，先哈希到 1000 个小文件，由于同 key 必同桶. 再对每个小文件使用 hashset / hashmap 找出不重复的, 输出到对应的一个小文件上. 最后合并这 1000 个小文件. 方法2：也可以使用字典树(trie树)，这样查找效率会很高。不过凡是 trie 树能做的，用 hashmap 都能做。 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。原题：搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请你统计最热门的10个查询串，要求使用的内存不能超过1G。 数据规模大，一次处理不了，我们就需要将数据通过hash映射切分；而本题的情况属于数据量可以一次放入内存(300万个字符串假设没有重复，都是最大长度，那么最多占用内存3M*1K / 4=0.75G。所以可以将所有字符串都存放在内存中进行处理)，所以只是需要一个合适的数据结构 所以我们在此直接读数据进行 hash 统计，统计后的数据只有 0.75G，可以直接进行排序，而对这种 TopK 问题，一般是采用堆来解决。 方案1：算法思想：分而治之 / Hash 映射 + Hash 统计 HashMap 统计：先对这批海量数据预处理。具体方法是：维护一个 Key 为 Query 字串，Value 为该 Query 出现次数的 HashMap，即 HashMap(Query，Value)，每次读取一个 Query，如果该字串不在 HashMap 中，那么加入该字串，并且将 Value 值设为1；如果该字串在 HashMap 中，那么将该字串的计数加一即可。最终我们在 O(N) 的时间复杂度内用 Hash 表完成了统计； 堆排序：借助堆这个数据结构，找出 Top K，时间复杂度为 O(NlogK)。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的 Query，分别和根元素进行对比。所以，我们最终的时间复杂度是：O(N) + N’ * O(logK)，(N 为 1000 万，N’ 为 300 万)。 方案2：算法思想：Trie 采用 Trie 树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。 40亿个不重复的 unsigned int 的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那 40 亿个数当中？ 方案1：算法思想：BitMap 申请512M的内存，一个 bit 位代表一个 unsigned int 值。读入 40 亿个数，设置相应的 bit 位，读入要查询的数，查看相应bit位是否为 1，为 1 表示存在，为 0 表示不存在。 方案2：因为 2^32 为 40 亿多，所以给定一个数可能在，也可能不在其中； 把 40 亿个数中的每一个用 32 位的二进制来表示 假设这40亿个数开始放在一个文件中。将这40亿个数分成两类:a. 最高位为0b. 最高位为1并将这两类分别写入到两个文件中，其中一个文件中数的个数 &lt;= 20亿，而另一个 &gt;= 20亿（这相当于折半了）；与要查找的数的最高位比较并接着进入相应的文件再查找 再把这个文件为又分成两类:a. 次最高位为0b. 次最高位为1 并将这两类分别写入到两个文件中，其中一个文件中数的个数&lt;=10亿，而另一个&gt;=10亿（这相当于折半了）；与要查找的数的次最高位比较并接着进入相应的文件再查找。……. 以此类推，就可以找到了,而且时间复杂度为 O(logn)。 附：位图方法： 使用位图法判断整形数组是否存在重复 判断集合中存在重复是常见编程任务之一，当集合中数据量比较大时我们通常希望少进行几次扫描，这时双重循环法就不可取了。 位图法比较适合于这种情况，它的做法是按照集合中最大元素 max 创建一个长度为 max+1 的新数组，然后再次扫描原数组，遇到几就给新数组的第几位置上 1，如遇到5就给新数组的第六个元素置1，这样下次再遇到5想置位时发现新数组的第六个元素已经是 1了，这说明这次的数据肯定和以前的数据存在着重复。这种给新数组初始化时置零其后置一的做法类似于位图的处理方法故称位图法。它的运算次数最坏的情况为 2N。如果已知数组的最大值即能事先给新数组定长的话效率还能提高一倍。 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10 如果每个数据元素只出现一次，而且只出现在某一台机器中，那么可以采取以下步骤统计出现次数TOP10的数据元素：求出每台电脑上的TOP10后，然后把这100台电脑上的TOP10组合起来，共1000个数据，再利用上面类似的方法求出TOP10就可以了。 如果同一个元素重复出现在不同的电脑中,则有两种方法： 遍历一遍所有数据，重新hash取摸，如此使得同一个元素只出现在单独的一台电脑中，然后采用上面所说的方法，统计每台电脑中各个元素的出现次数找出TOP10，继而组合100台电脑上的TOP10，找出最终的TOP10。 暴力求解：直接统计统计每台电脑中各个元素的出现次数，然后把同一个元素在不同机器中的出现次数相加，最终从所有数据中找出TOP10。 10亿个QQ号，让我找出一个QQ号是不是在其中，时间复杂度要求O(1) 用 Bitmap 来做这个问题。首先对数据进行预处理。定义 10 亿 bit 位个 int。在 32 位计算机下，一个 int 是 32 位，10 亿位的话，就需要 10 亿除以 32 个 int 整数。大概有很多个。第一个 int 标记 0-31 这个数字范围的 QQ 号存不存在，比如说 0000001 这个 QQ 号，我就把第一个 int 的第1位置1。第二个 int 能够标记 32-63 这个范围的QQ存不存在，以此类推。把这 10 亿个 QQ 号预处理一遍。然后计算你给我的这个 QQ 号，它是在哪个 int 里面，然后找到相应的数据位，看是1还是0，就能在O(1)的时间里找到。 移动公司需要对已经发放的所有139段的号码进行统计排序，已经发放的139号码段的文件都存放在一个文本文件中（原题是放在两个文件中），一个号码一行，现在需要将文件里的所有号码进行排序，并写入到一个新的文件中；号码可能会有很多，最多可能有一亿个不同的号码（所有的139段号码），存入文本文件中大概要占1.2G的空间；jvm最大的内存在300以内，程序要考虑程序的可执行性及效率；只能使用Java标准库，不得使用第三方工具。 方案1： 顺序读取存放号码文件的中所有号码，并取 139 之后的八位转换为 int 类型；每读取号码数满一百万个(这个数据可配置)将已经读取的号码排序并存入新建的临时文件。将所有生成的号码有序的临时文件合并存入结果文件。 这个算法虽然解决了空间问题，但是运行效率极低，由于IO读写操作太多，加上步骤1中的排序的算法（快速排序）本来效率就不高 方案2：bitmap 一个号码占一个 bit，一共需要 99999999 bit ，一个 int32 位，所以需要312.5万个 int 值，即 1250万Byte = 12.5M，算法如下 初始化 bits[capacity]； 顺序所有读入电话号码，并转换为int类型，修改位向量值 bits[phoneNum]=1； 遍历bits数组，如果 bits[index]=1，转换 index 为电话号码输出。 5亿个int找它们的中位数。 方案1：多层桶结构 首先我们将 int 划分为 2^16 个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。实际上，如果不是 int 是 int64，我们可以经过 3 次这样的划分即可降低到可以接受的程度。即可以先将 int64 分成 2 ^24个区域，然后确定区域的第几大数，在将该区域分成2^ 20个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有 2^20，就可以直接利用 direct addr table 进行统计了。 方案2：同样需要做两遍统计，如果数据存在硬盘上，就需要读取2次。方法同基数排序有些像，开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况，也就是0-65535，都算作0,65536 - 131071都算作1。就相当于用该数除以65536。Int32 除以 65536的结果不会超过65536种情况，因此开一个长度为65536的数组计数就可以。每读取一个数，数组中对应的计数+1，考虑有负数的情况，需要将结果加32768后，记录在相应的数组内。第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间，比如处于区间k，那么0- k-1的区间里数字的数量sum应该&lt;n/2（2.5亿）。而k+1 - 65535的计数和也&lt;n/2，第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，也就是说(x / 65536) + 32768 = k。统计只统计低16位的情况。并且利用刚才统计的sum，比如sum = 2.49亿，那么现在就是要在低16位里面找100万个数(2.5亿-2.49亿)。这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。 参考链接如何正确地解答海量数据处理面试题海量数据处理方法总结面试中的海量数据处理问题总结海量数据处理：十个海量数据处理方法总结面试笔记–海量数据题目处理总结Big Data Processing","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://quricolouis.github.io/tags/Big-Data/"},{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"author":"QuricoLouis"},{"title":"STL容器介绍","slug":"STL容器介绍","date":"2021-09-11T14:42:28.986Z","updated":"2021-09-11T15:21:23.133Z","comments":true,"path":"posts/8c5c4d28.html","link":"","permalink":"http://quricolouis.github.io/posts/8c5c4d28.html","excerpt":"","text":"STL容器分类:一：序列容器：vector、list、deque、string. 二 : 关联容器：set、multiset、map、mulmap、hash_set、hash_map、hash_multiset、hash_multimap 三: 其他的杂项：stack、queue、valarray、bitset 关联式容器。关联式容器又分为set(集合)和map(映射表)两大类，以及这两大类的衍生体multiset(多键集合)和multimap(多键映射表)，这些容器均以RB-tree完成。此外，还有第3类关联式容器，如hashtable(散列表)，以及以hashtable为底层机制完成的hash_set(散列集合)、hash_map(散列映射表)、hash_multiset(散列多键集合)、hash_multimap(散列多键映射表)。也就是说，set、map、multiset、multimap都内含一个RB-tree，而hash_set、hash_map、hash_multiset、hash_multimap都内含一个hashtable。所谓关联式容器，类似关联式数据库，每笔数据或每个元素都有一个键值(key)和一个实值(value)，即所谓的Key-Value(键-值对)。当元素被插入到关联式容器中时，容器内部结构(RB-tree、hashtable)便依照其键值大小，以某种特定规则将这个元素放置于适当位置。 包括在非关联式数据库中，比如，在MongoDB内，文档(document)是最基本的数据组织形式，每个文档也是以Key-Value（键-值对）的方式组织起来。一个文档可以有多个Key-Value组合，每个Value可以是不同的类型，比如String、Integer、List等等。 STL各个容器的实现 vector内部数据结构：数组。随机访问每个元素，所需要的时间为常量。在末尾增加或删除元素所需时间与元素数目无关，在中间或开头增加或删除元素所需时间随元素数目呈线性变化。可动态增加或减少元素，内存管理自动完成，但程序员可以使用reserve()成员函数来管理内存。vector的迭代器在内存重新分配时将失效（它所指向的元素在该操作的前后不再相同）。当把超过capacity() - size()个元素插入vector中时，内存会重新分配，所有的迭代器都将失效；否则，指向当前元素以后的任何元素的迭代器都将失效。当删除元素时，指向被删除元素以后的任何元素的迭代器都将失效。 deque内部数据结构：数组。随机访问每个元素，所需要的时间为常量。在开头和末尾增加元素所需时间与元素数目无关，在中间增加或删除元素所需时间随元素数目呈线性变化。可动态增加或减少元素，内存管理自动完成，不提供用于内存管理的成员函数。增加任何元素都将使deque的迭代器失效。在deque的中间删除元素将使迭代器失效。在deque的头或尾删除元素时，只有指向该元素的迭代器失效。 list内部数据结构：双向环状链表。不能随机访问一个元素。可双向遍历。在开头、末尾和中间任何地方增加或删除元素所需时间都为常量。可动态增加或减少元素，内存管理自动完成。增加任何元素都不会使迭代器失效。删除元素时，除了指向当前被删除元素的迭代器外，其它迭代器都不会失效。 slist内部数据结构：单向链表。不可双向遍历，只能从前到后地遍历。其它的特性同list相似。 stack适配器，它可以将任意类型的序列容器转换为一个堆栈，一般使用deque作为支持的序列容器。元素只能后进先出（LIFO）。不能遍历整个stack。 queue适配器，它可以将任意类型的序列容器转换为一个队列，一般使用deque作为支持的序列容器。元素只能先进先出（FIFO）。不能遍历整个queue。 priority_queue适配器，它可以将任意类型的序列容器转换为一个优先级队列，一般使用vector作为底层存储方式。只能访问第一个元素，不能遍历整个priority_queue。第一个元素始终是优先级最高的一个元素。 set键和值相等。键唯一。元素默认按升序排列。如果迭代器所指向的元素被删除，则该迭代器失效。其它任何增加、删除元素的操作都不会使迭代器失效。 multiset键可以不唯一。其它特点与set相同。 hash_set与set相比较，它里面的元素不一定是经过排序的，而是按照所用的hash函数分派的，它能提供更快的搜索速度（当然跟hash函数有关）。其它特点与set相同。 hash_multiset键可以不唯一。其它特点与hash_set相同。 map键唯一。元素默认按键的升序排列。如果迭代器所指向的元素被删除，则该迭代器失效。其它任何增加、删除元素的操作都不会使迭代器失效。 multimap键可以不唯一。其它特点与map相同。 hash_map与map相比较，它里面的元素不一定是按键值排序的，而是按照所用的hash函数分派的，它能提供更快的搜索速度（当然也跟hash函数有关）。其它特点与map相同。 hash_multimap键可以不唯一。其它特点与hash_map相同。","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://quricolouis.github.io/tags/Big-Data/"},{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"author":"QuricoLouis"},{"title":"布隆过滤器(Bloom Filter)的原理和实现","slug":"布隆过滤器(Bloom Filter)的原理和实现","date":"2021-09-11T14:42:14.032Z","updated":"2021-09-11T15:21:23.140Z","comments":true,"path":"posts/58823f19.html","link":"","permalink":"http://quricolouis.github.io/posts/58823f19.html","excerpt":"","text":"假设要你写一个网络蜘蛛（web crawler）。由于网络间的链接错综复杂，蜘蛛在网络间爬行很可能会形成“环”。为了避免形成“环”，就需要知道蜘蛛已经访问过那些URL。给一个URL，怎样知道蜘蛛是否已经访问过呢？ 把这个问题抽象出来，就是说：现在需要一种算法（工具），帮助我们实现一种高效而准确的，元素在集合中的存在性判断。 为了解决上面说的这一类问题，人们从简入难，想出了很多办法： 将访问过的URL保存到数据库。 用HashSet将访问过的URL保存起来。那只需接近O(1)的代价就可以查到一个URL是否被访问过了。 URL经过MD5或SHA-1等单向哈希后再保存到HashSet或数据库。 Bit-Map方法。建立一个BitSet，将每个URL经过一个哈希函数映射到某一位。 方法1~3都是将访问过的URL完整保存，方法4则只标记URL的一个映射位。 以上方法在数据量较小的情况下都能完美解决问题，但是当数据量变得非常庞大时问题就来了。 方法1的缺点：数据量变得非常庞大后关系型数据库查询的效率会变得很低。而且每来一个URL就启动一次数据库查询是不是太小题大做了？ 方法2的缺点：太消耗内存。随着URL的增多，占用的内存会越来越多。就算只有1亿个URL，每个URL只算50个字符，就需要5GB内存。 方法3：由于字符串经过MD5处理后的信息摘要长度只有128Bit，SHA-1处理后也只有160Bit，因此方法3比方法2节省了好几倍的内存。 方法4消耗内存是相对较少的，但缺点是单一哈希函数发生冲突的概率太高。还记得数据结构课上学过的Hash表冲突的各种解决方法么？若要降低冲突发生的概率到1%，就要将BitSet的长度设置为URL个数的100倍。 实质上上面的算法都忽略了一个重要的隐含条件：允许小概率的出错，不一定要100%准确！也就是说少量url实际上没有没网络蜘蛛访问，而将它们错判为已访问的代价是很小的——大不了少抓几个网页呗。 布隆过滤器原理 误报率(False positive)，又叫假阳性拿最开始讲的网页爬虫的问题来说，在建立 BitMap 时，如果发生碰撞，那我们就会认为新爬到的这个 URL 是已经存在于已有集合中了，而事实上，却是不存在的。这个意思抽象出来，就是把本来不存在的事物(False)误报为已存在事物(Positive)的错误率。在一般的应用场景中，有极小的误报率是可以被接受的。比如爬虫时，少爬几个网页并没有什么太大关系；医疗检查时，一个健康的人被医生误判我们患了某种疾病(False Positive)，总比一个有病的人没有被检查出来(False Negative)要强得多。我们把后面一种情况称为假阴性，也就是“漏报”。 上面的分析可知，碰撞在元素针对集合的存在性判断问题中，会导致误报率的发生，而误报率如果不大的话，对这个问题的影响也就不大。所以，当然可以设计一种方法，在降低碰撞概率的前提下，生成相应的bit串。降低碰撞概率的两个途径： 使用多个哈希，替代之前的单个哈希； 增大bit数组的长度。 布隆过滤器（Bloom Filter）的核心实现是一个超大的位数组和几个哈希函数。假设位数组的长度为m，哈希函数的个数为k以上图为例，具体的操作流程：假设集合里面有3个元素{x, y, z}，哈希函数的个数为3。首先将位数组进行初始化，将里面每个位都设置位0。对于集合里面的每一个元素，将元素依次通过3个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。查询W元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。反之，如果3个点都为1，则该元素可能存在集合中。注意：此处不能判断该元素是否一定存在集合中，可能存在一定的误判率。可以从图中可以看到：假设某个元素通过映射对应下标为4，5，6这3个点。虽然这3个点都为1，但是很明显这3个点是不同元素经过哈希得到的位置，因此这种情况说明元素虽然不在集合中，也可能对应的都是1，这是误判率存在的原因。 布隆过滤器实现public class MyBloomFilter { //你的布隆过滤器容量 private static final int DEFAULT_SIZE = 2 &lt;&lt; 28; //bit数组，用来存放key private static BitSet bitSet = new BitSet(DEFAULT_SIZE); //后面hash函数会用到，用来生成不同的hash值，可随意设置，别问我为什么这么多8，图个吉利 private static final int[] ints = {1, 6, 16, 38, 58, 68}; //add方法，计算出key的hash值，并将对应下标置为true public void add(Object key) { Arrays.stream(ints).forEach(i -&gt; bitSet.set(hash(key, i))); } //判断key是否存在，true不一定说明key存在，但是false一定说明不存在 public boolean isContain(Object key) { boolean result = true; for (int i : ints) { //短路与，只要有一个bit位为false，则返回false result = result &amp;&amp; bitSet.get(hash(key, i)); } return result; } //hash函数，借鉴了hashmap的扰动算法，强烈建议大家把这个hash算法看懂，这个设计真的牛皮加闪电 private int hash(Object key, int i) { int h; return key == null ? 0 : (i * (DEFAULT_SIZE - 1) &amp; ((h = key.hashCode()) ^ (h &gt;&gt;&gt; 16))); } } 测试： public static void main(String[] args) { MyNewBloomFilter myNewBloomFilter = new MyNewBloomFilter(); myNewBloomFilter.add(\"张学友\"); myNewBloomFilter.add(\"郭德纲\"); myNewBloomFilter.add(\"蔡徐鸡\"); myNewBloomFilter.add(666); System.out.println(myNewBloomFilter.isContain(\"张学友\"));//true System.out.println(myNewBloomFilter.isContain(\"张学友 \"));//false System.out.println(myNewBloomFilter.isContain(\"张学友1\"));//false System.out.println(myNewBloomFilter.isContain(\"郭德纲\"));//true System.out.println(myNewBloomFilter.isContain(\"蔡徐老母鸡\"));//false System.out.println(myNewBloomFilter.isContain(666));//true System.out.println(myNewBloomFilter.isContain(888));//false } 通过对比hash算法计算出来的下标，注意，我们是对比一组，而不是只看一次，一次hash结果对应一个下标 把同一个key进行多次hash运算，将hash出来的下标放入数组，数组默认全为0，放入元素后该下标就为1，后面判断是否存在元素的时候也是进行同样次数的hash运算，看下结果对应的所有下标是否全为1，若全为1，则代表该key可能存在，若存在不为1的，则说明该key一定不存在； 默认位数组：[0，0，0，0，0，0]比方说有个已知key的下标是0，2，5对应位数组：[1，0，1，0，0，1]判断某个未知key存不存在的时候，假设我们计算出来的下标是0，2，4对应位数组：[1，0，1，0，1，0]此时位数组内5对应下标值为0，而已知key位数组的5对应下标位1，说明这两个一定不是同一个key 相反，如果某个key计算出来的下标为[1，0，1，0，0，1]，只能说这个key可能存在，因为这个位置可能是其它key计算出来的 布隆过滤器的应用场景 HTTP 缓存服务器、Web 爬虫等主要工作是判断一条 URL 是否在现有的 URL 集合之中（可以认为这里的数据量级上亿）。对于 HTTP 缓存服务器，当本地局域网中的 PC 发起一条 HTTP 请求时，缓存服务器会先查看一下这个 URL 是否已经存在于缓存之中，如果存在的话就没有必要去原始的服务器拉取数据了（为了简单起见，我们假设数据没有发生变化），这样既能节省流量，还能加快访问速度，以提高用户体验。对于 Web 爬虫，要判断当前正在处理的网页是否已经处理过了，同样需要当前 URL 是否存在于已经处理过的 URL 列表之中。 垃圾邮件过滤假设邮件服务器通过发送方的邮件域或者IP地址对垃圾邮件进行过滤，那么就需要判断当前的邮件域或者 IP 地址是否处于黑名单之中。如果邮件服务器的通信邮件数量非常大（也可以认为数据量级上亿），那么也可以使用 Bloom Filter 算法。 参考链接Bloom Filter原理与实现Bloom Filter 算法简介 (增加 Counting Bloom Filter 内容)BloomFilter——大规模数据处理利器布隆过滤器(Bloom Filter)详解布隆过滤器(Bloom Filter)的原理和实现布隆过滤器原理（小白都能看懂的demo）","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"java","permalink":"http://quricolouis.github.io/tags/java/"}],"author":"QuricoLouis"},{"title":"海量数据处理方法总结","slug":"海量数据处理方法总结","date":"2021-09-11T14:33:37.210Z","updated":"2021-09-13T06:54:03.933Z","comments":true,"path":"posts/dbd91440.html","link":"","permalink":"http://quricolouis.github.io/posts/dbd91440.html","excerpt":"","text":"==本文主要讲解海量数据处理方法的总结，由于字数较多，为了有更好的阅读体验，海量数据处理问题总结请移步海量数据处理问题总结== 数据时代来临，数据量的爆炸式增长是最为显著的特征。当高性能硬件的普及还跟不上这样的数据大潮时，如何在有限的时空资源内处理海量数据成为了计算机科学以及数理统计等领域最大的挑战。 海量数据处理海量数据处理，是基于海量数据上的存储、处理、操作。何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。 海量数据处理的困难用一句话概括，就是时间和空间资源不够。具体来说， 时间受限：无法在有限时间内，完成针对海量数据的某项处理工作； 空间受限：无法将海量数据一次性读入内存 对于时间受限的问题，我们一般的解决办法是高效的算法配合恰当的数据结构，比如哈希表，Bloom Filter，堆，倒排索引，Tire树；而对于空间受限的问题，一般的解决办法是“大而化小，分而治之”的策略，既然一次性行不通，那就一部分一部分读，每读入一部分可以生成一个小文件，小文件是可以直接读入内存的，我们这样分割大数据之后，再依次处理小文件的数据。 至于所谓的单机及集群问题，通俗点来讲，单机就是处理装载数据的机器有限(只要考虑 cpu，内存，硬盘的数据交互)，而集群，机器有多个，适合分布式处理，并行计算(更多考虑节点和节点间的数据交互)。 处理海量数据问题的方法： 分而治之 / hash映射 + hash统计 + 堆/快速/归并排序； 双层桶划分 Bloom filter / Bitmap； Trie树 / 数据库 / 倒排索引； 外排序； 分布式处理之Hadoop / Mapreduce。 算法与数据结构基础STL容器分为三种： 序列容器：vector、 list、deque、string 关联容器：set、multiset、map、mulmap、hash_set、hash_map、hash_multiset、hash_multimap 其他的杂项： stack、queue、valarray、bitset 关联式容器，关联式容器又分为set(集合)和map(映射表)两大类，以及这两大类的衍生体 multiset (多键集合)和 multimap (多键映射表)，这些容器均以 RB-tree 完成。此外，还有第3类关联式容器，如 hashtable (散列表)，以及以 hashtable 为底层机制完成的 hash_set (散列集合) / hash_map (散列映射表)、hash_multiset (散列多键集合)、hash_multimap (散列多键映射表)。也就是说，set/map、multiset、multimap都内含一个 RB-tree，而hash_set、hash_map、hash_multiset、hash_multimap都内含一个hashtable。所谓关联式容器，类似关联式数据库，每笔数据或每个元素都有一个键值(key)和一个实值(value)，即所谓的Key-Value(键-值对)。当元素被插入到关联式容器中时，容器内部结构(RB-tree/hashtable)便依照其键值大小，以某种特定规则将这个元素放置于适当位置。 包括在非关联式数据库中，比如，在 MongoDB 内，文档(document)是最基本的数据组织形式，每个文档也是以 Key-Value（键-值对）的方式组织起来。一个文档可以有多个Key-Value组合，每个 Value 可以是不同的类型，比如String、Integer、List等等。 ==注：详细了解STL容器可移步STL容器介绍== set / map / multiset / multimapset 同 map 一样，所有元素都会根据元素的键值自动被排序，因为 set / map两者的所有各种操作，都只是转而调用 RB-tree 的操作行为，不过，值得注意的是，两者都不允许两个元素有相同的键值。不同的是：set 的元素不像 map 那样可以同时拥有实值(value)和键值(key)，set元素的键值就是实值，实值就是键值，而 map 的所有元素都是 pair，同时拥有实值(value)和键值(key)，pair的第一个元素被视为键值，第二个元素被视为实值。至于multiset/multimap，他们的特性及用法和 set / map完全相同，唯一的差别就在于它们允许键值重复，即所有的插入操作基于 RB-tree 的 insert_equal() 而非insert_unique()。 hash_set / hash_map / hash_multiset / hash_multimaphash_set / hash_map，两者的一切操作都是基于 hashtable 之上。不同的是，hash_set 同 set一样，同时拥有实值和键值，且实质就是键值，键值就是实值，而 hash_map 同 map 一样，每一个元素同时拥有一个实值(value)和一个键值(key)，所以其使用方式，和上面的map基本相同。但由于 hash_set / hash_map 都是基于hashtable之上，所以不具备自动排序功能。为什么?因为 hashtable 没有自动排序功能。至于 hash_multiset / hash_multimap 的特性与上面的 multiset / multimap 完全相同，唯一的差别就是它们 hash_multiset / hash_multimap 的底层实现机制是hashtable（而multiset / multimap，上面说了，底层实现机制是 RB-tree），所以它们的元素都不会被自动排序，不过也都允许键值重复。 综上，什么样的结构决定其什么样的性质，因为 set / map / multiset / multimap 都是基于 RB-tree 之上，所以有自动排序功能，而 hash_set / hash_map / hash_multiset / hash_multimap 都是基于 hashtable 之上，所以不含有自动排序功能，至于加个前缀 multi_ 无非就是允许键值重复而已。： 海量数据处理方法归纳分而治之 / hash 映射 + hash 统计 + 堆 / 快速 / 归并排序 解决问题：海量数据不能一次性读入内存，而我们需要对海量数据进行的计数、排序等操作 使用工具：hash函数（hash表）；堆 解题思路： 分而治之 / hash映射：针对数据太大，内存受限，只能把大文件化成(取模映射)小文件 hash_map 统计：当大文件转化了小文件，那么我们便可以采用常规的hash_map(key，value)来进行频率统计。 堆 / 快速排序：统计完了之后，便进行排序(可采取堆排序)，得到次数最多的key。 这种方法是典型的“分而治之”的策略，也是解决空间限制最常用的方法。基本思路可以用下图表示。先借助哈希算法，计算每一条数据的hash值，按照hash值将海量数据分布存储到多个桶中（所谓桶，一般可以用小文件实现）。根据hash函数的唯一性，相同的数据一定在同一个桶中。如此，我们再依次处理这些小文件，最后做合并运算即可（有点类似于Map-Reduce的思想）注：一般用hash函数将数据映射到桶的方法是：bucketID=H(mi) % n其中mi为第 i 条数据，bucket_ID为桶标号，n为要设置的桶数量。关于桶数量（即小文件数量）设置的基本的原则是：每个小文件的大小比内存限制要小。比如处理1G的大文件，内存限制为1M，那就可以把大文件分成2000个小文件（甚至更多），这样每个小文件的大小约500K（甚至更小），我们就可以轻松读入内存处理了。 问题1 top-k筛选：海量数据存储于多个文件，任何一条数据都可能存在于任何一个文件当中，现需要筛选出现的次数最多的 k 条数据。解决思路： 依次遍历这些文件，通过 hash 映射，将每个文件的每条数据映射到新构造的多个小文件中（设生成了n个小文件）； 依次统计每个小文件中出现次数最多的 k 条数据，构成 hash 表，hash 表中每个键值对的形式为 dataItem: count； 利用堆排序，依次遍历这些hash表，在 n∗k 条数据中，找出 count 值最大的 k 个； 这里之所以使用堆排序，也是为了能尽可能地提高排序效率。就上例而言，堆排序的时间复杂度为 nklog(k) 问题2 对比查重：现有A和B两个大文件，每个文件都存储着海量数据，要求给出A，B中重复的数据。解决思路： 遍历A中的所有数据，通过hash映射将他们分布存储在 n 个小文件中，记为 {a1,a2,…,an}； 遍历B中的所有数据，通过hash映射将他们分布存储在 n 个小文件中，记为{b1,b2,…,bn}； 根据hash函数性质可知，A 和 B 中的相同数据一定被映射到序号相同的小文件，所以我们依次比较{ai,bi}即可； 如果问题更进一步，要求返回重复次数最多的 k 条数据，则可以将对比小文件找到的数据存入hash表，键为数据，值为该数据出现的次数。再用大小为 k 的堆，排序找出即可。 多层桶结构解决问题：海量数据求取第 k 大数；中位数；不重复或重复的数字使用工具：hash 函数 多层桶结构其实和最开始我们用 hash 映射分割大文件的思路是一致的，都是一种“分而治之”的策略。只不过多层桶结构是对有些桶分割之后再分割，构成了一种层次化的结构，它主要应用于一次分割的结果依然不能解决内存限制的情况。 问题3 求取海量整数的中位数。解决思路： 依次遍历整数，按照其大小将他们分拣到 n 个桶中。但是现在出现了一种不好的情况，就是可能有的桶数据量很小，有的则数据量很大，大到内存放不下了； 对于那些太大的桶，我们就再分割成更小的桶，当然分割的准则还是依据数据大小，这样，其实是构成了一种类似于不平衡的多叉树的结构； 根据多叉树第一层的数量统计结果，我们可以知道中位数在哪个节点中，如果该节点还有孩子，就判断在其哪个孩子节点中，直到找到叶子节点，最后找出目标。 Bitmap / Bloom filterBitmapBitmap 就是用一个 bit 位来标记某个元素对应的 Value， 而 Key 即是该元素。由于采用了 Bit 为单位来表示某个元素是否存在，因此在存储空间方面，可以大大节省。 Bitmap排序方法： 将所有的位都置为0，从而将集合初始化为空。 通过读入文件中的每个整数来建立集合，将每个对应的位都置为1。 检验每一位，如果该位为1，就输出对应的整数。 例如：我们要对0-7内的5个元素(4,7,2,5,3)排序（这里假设这些元素没有重复）;那么我们就可以采用Bitmap的方法来达到排序的目的。要表示8个数，我们就只需要8个 Bit（1Bytes）;将对应的第四位置为1，最终处理结果如下： 我们只想知道某个元素出现过没有。如果为每个所有可能的值分配1个 bit；但对于海量的、取值分布很均匀的集合进行去重，Bitmap 极大地压缩了所需要的内存空间。与此同时，还额外地完成了对原始数组的排序工作。缺点是，Bitmap 对于每个元素只能记录1bit信息，如果还想完成额外的功能，恐怕只能靠牺牲更多的空间、时间来完成了。 Bloom filter解决问题：数据字典的构建；判定目标数据是否存在于一个海量数据集；集合求交集使用工具：Bloom Filter；hash函数基本原理：当一个元素被加入集合时，通过 K 个 Hash 函数将这个元素映射成一个位阵列（Bit array）中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个 0，则被检索元素一定不在；如果都是1，则被检索元素很可能在。 以存在性判定为例，Bloom Filter 通过对目标数据的映射，能够以 O(k) 的时间复杂度判定目标数据的存在性，其中 k 为使用的 hash 函数个数。这样就能大大缩减遍历查找所需的时间。 == 注：有关Bloom Filter树的详细讲解可以参考博客布隆过滤器(Bloom Filter)的原理和实现，建议去了解一下。宁可误报，不可错报== 问题4 集合求交：与上面的问题2类似，只不过现在不是A和B两个大文件，而是A, B, C, D….多个大文件。解决思路： 依次遍历每个大文件中的每条数据，遍历每条数据时，都将它插入Bloom Filter； 如果已经存在，则在另外的集合（记为 S）中记录下来； 如果不存在，则插入Bloom Filter； 最后，得到的 S 即为所有这些大文件中元素的交集 问题5 unsigned int型整数存在性判定：判定一个unsigned int型整数是否在一个大的unsigned int型整数数据集中。解决思路： 假设 unsigned int 型整数数据集长度为 N，则申请一个大小为 512M 的数组作为 Bloom Filter； 遍历数据集，按照遍历到的整数（记为 a）将 Bloom Filter 的第 a 位变成1； 检查 Bloom Filter 中，目标数据所代表的位是 0 还是 1； 问题5用的其实是一种简化了的Bloom Filter，不再采取hash映射的方式，而是直接根据整数的大小确定要改变的位数，这在某些特殊情况下（比如数据种类不多时）非常有效。 Trie树/数据库/倒排索引Trie树解决问题：当需要处理的是海量字符串数据时，有时Trie树会比直接上面说的hash映射的策略更高效。适用范围：数据量大，重复多，但是数据种类小可以放入内存使用工具：Trie 树；堆扩展：压缩实现。结构：Trie树是如图所示的一棵多叉树。其中存储的字符串集合为:{“a”,”aa”,”ab”,”ac”,”aab”,”aac”,”bc”,”bd”,”bca”,”bcc”}从上图我们可以看出，Trie树有如下3点特征： 根节点不代表（包含）字符，除根节点外每一个节点都只代表（包含）一个字符。 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符都不相同。 其实，一棵完整的 Trie 树应该每个非叶节点都拥有 26 个指针，正好对应着英文的 26 个字母，这样整棵树的空间成本为26L，L 为最长字符串的长度。但是为了节省空间，我们可以根据字符串集本身为每个非叶节点，“量身定做”子节点。以上面的图为例，以 ”a” 开头的字符串中，第二个字符只有 ”a, b, c” 3种可能，我们当然没有必要为节点 u1 生成 26 个子节点了，3 个就够了。 除此之外，由于有些字符就是集合中其他字符的前缀，为了能够分辨清楚集合中到底有哪些字符串，我们还需要为每个节点赋予一个判断终止与否的bool值，记为endend。比如上图，由于同时存在字符串 {“a”,”ab”,”ac”,”aa”,”aab”,”aac”}，我们就令节点 u1,u2 的 end 值为 True，表示从根节点到 u1,u2 的路径上的字符按顺序可以构成集合中一个完整的字符串（如”a”, “aa”）。图中，我们将end == True的节点标红。 Trie 树是一种非常强大的处理海量字符串数据的工具。尤其是大量的字符串数据中存在前缀时，Trie 树特别好用。Trie 树在字典的存储，字符串的查找，求取海量字符串的公共前缀，以及字符串统计等方面发挥着重要的作用。用于存储时，Trie 树因为不重复存储公共前缀，节省了大量的存储空间；用于以字符串的查找时，Trie 树依靠其特殊的性质，实现了在任意数据量的字符串集合中都能以 O(len) 的 时间复杂度完成查找（len 为要检索的字符串长度）；在字符串统计中，Trie 树能够快速记录每个字符串出现的次数。 应用： 节约字符串的存储空间假设现在我们需要对海量字符串构建字典。所谓字典就是一个集合，这个集合包含了所有不重复的字符串，字典在对文本数据做信息检索系统时的作用我想毋庸赘述了。那么现在就出现了一个问题，那就是字典对存储空间的消耗过大。而当这些字符串中存在大量的串拥有重复的前缀时，这种消耗就显得过于浪费了。比如：”ababc”, “ababd”, “ababrf”, “abab…”，这些字符串几乎都拥有公共前缀 ”abab”。 我们直接的想法是，能不能通过一种存储结构节约存储成本，使得所有拥有重复前缀的串对于公共前缀只存储一遍。这种存储的应用场景如果是对DNA序列的存储，那么出现重复前缀的可能性更大，空间需求也就更为强烈。 字符串检索检索一个字符串是否属于某个词典时，我们当前一般有两种思路：a. 线性遍历词典，计算复杂度 O(n)，n 为词典长度；b. 利用hash表，预先处理字符串集合。这样再搜索运算时，计算复杂度 O(1)。但是 hash 计算可能存在碰撞问题，一般的解决办法比如对某个 hash 值所代表的字符串实施二次检索，则计算时间也会上来。而且，hash 虽说是一种高效算法，其计算效率比直接字符匹配还是要略高的。 字符串公共前缀问题两个非常典型的例子：a. 求取已知的 n 个字符串的最长公共前缀，朴素方法的时间复杂度为 O(nt)，t 为最长公共前缀的长度；b. 给定字符串 a，求取 a 在某 n 个字符串中和哪些串拥有公共前缀 对于问题 b，除了朴素的比较法之外，我们还可以采取对每个字符串的所有前缀计算 hash 值的方法，这样一来，计算所有前缀 hash 值复杂度 O(n∗len)，len 为字符串的平均长度，查询的复杂度为 O(n)。虽然降低了查询复杂度，但是计算hash值显然费时费力。 问题6 数据去重：一个超大文件（不能直接读入内存），里面包含海量字符串数据，但字符串数据种类有限（可见含有大量重复），现需要对字符串去重。并统计去重后每个字符串出现的次数解决思路： 将大文件分割成多个小文件，依次遍历每个小文件，读取其中存储的每一个字符串，构建Trie树，并在每一个终止节点记录该节点代表的字符串（即从根节点到该节点的字符组成的字符串）当前出现的次数，解决问题的时间复杂度为 O(N∗len)，其中 N 为字符串总数，len 为字符串的平均长度； 如果问题更进一步，需要排序，那就再建一个堆，读取 Trie 树，将字符串依次插入堆，时间复杂度为 O(N′∗len∗log⁡N′)，其中 N′ 是去重后字符串的数量。 总结一下，Trie树对于海量字符串数据，在数据种类有限（构建的Trie树可以完全读入内存）时，能够使我们轻松的进行存储，查找，计数等工作。 数据库索引适用范围：大数据量的增删改查基本原理及要点：利用数据的设计实现方法，对海量数据的增删改查进行处理。 倒排索引(Inverted index)适用范围：搜索引擎，关键字查询基本原理及要点：一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。 外排序适用范围：大数据的排序，去重基本原理及要点：外排序的归并方法，置换选择败者树原理，最优归并树 两个独立阶段： 首先按内存大小，将外存上含n个记录的文件分成若干长度L的子文件或段。依次读入内存并利用有效的内部排序对他们进行排序，并将排序后得到的有序字文件重新写入外存，通常称这些子文件为归并段。 对这些归并段进行逐趟归并，使归并段逐渐由小到大，直至得到整个有序文件为之。 外排序的优化方法：置换选择败者树原理，最优归并树。 提高外部排序需要考虑以下问题： 如何减少排序所需的归并趟数。 如果高效利用程序缓冲区，使得输入、输出和CPU运行尽可能地重叠。 如何生成初始归并段（Segment）和如何对归并段进行归并。 实例： 问题7 要对外存中 4500 个记录进行归并，而内存大小只能容纳750个记录。 每次读取 750 个记录进行排序，这样可以分六次读取，进行排序，可以得到六个有序的归并段，每个归并段的大小是 750 个记录，记住，这些归并段已经全部写到临时缓冲区（由一个可用的磁盘充当）内了，这是第一步的排序结果。 将内存空间划分为三份，每份大小 250 个记录，其中两个用作输入缓冲区，另外一个用作输出缓冲区。首先对 Segment_1 和 Segment_2 进行归并，先从每个归并段中读取 250 个记录到输入缓冲区，对其归并，归并结果放到输出缓冲区，当输出缓冲区满后，将其写道临时缓冲区内，如果某个输入缓冲区空了，则从相应的归并段中再读取 250 个记录进行继续归并，反复以上步骤，直至 Segment_1 和Segment_2 全都排好序，形成一个大小为 1500 的记录，然后对 Segment_3 和 Segment_4、Segment_5 和 Segment_6 进行同样的操作。 对归并好的大小为 1500 的记录进行如同步骤1一样的操作，进行继续排序，直至最后形成大小为 4500 的归并段，至此，排序结束。 分布式处理之Hadoop/Mapreduce适用范围：数据量大，但是数据种类小可以放入内存基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。 MapReduce是一种计算模型，分为”Map”和”Reduce”两个阶段： Map：将大量数据分割后（或者将困难任务分解后）“各个击破”； Reduce：将“各个击破”的结果按照一定的规律进行合并操作； 这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，从而突破时间或者空间的限制。时间上显然更快，空间上，单个机器只需要处理空间允许的数据量即可。举个简单的例子就是归并排序，我们先将数据集分割成小数据集，使用多个机器排序每个分割后的小数据集（Map），再将处理好的归并段依次归并（Reduce）。 参考链接海量数据处理技巧教你如何迅速秒杀掉：99%的海量数据处理面试题面试笔记–海量数据题目处理总结Big Data Processing如何正确地解答海量数据处理面试题海量数据处理：十个海量数据处理方法总结面试中的海量数据处理问题总结排序之外部排序Trie树的构建和应用","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://quricolouis.github.io/tags/Big-Data/"},{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"author":"QuricoLouis"},{"title":"常用限流算法及原理","slug":"常用限流算法及原理","date":"2021-09-10T08:31:53.441Z","updated":"2021-09-11T14:52:24.361Z","comments":true,"path":"posts/42956def.html","link":"","permalink":"http://quricolouis.github.io/posts/42956def.html","excerpt":"","text":"为什么限流限流即限制流量，通过流量控制来保证系统接收到的请求量在正常范围内。由于任何系统的吞吐量都有上限，所以必须设置合理的限定值，以避免流量洪峰将整个系统打垮。 假如一个系统可以承载的网络带宽是1G，如果流量大于1G就会导致带宽打满，影响整个服务。在现实生活中，限流场景也随处可见：例如银行的叫号系统、餐厅的排队系统，如今的疫情，政府也是全力排除隐患，保证医疗系统健康运行。 限流的目的只有一个：保护系统，保证系统在可控的负载下平稳运行。 常用算法计数器算法（固定窗口限流+滑动窗口限流）计数器算法是在单位时间内统计用户请求数，一旦请求数量超出设定的阈值，即触发限流策略。计数器算法根据单位时间的计算方式又分为固定窗口算法及滑动窗口算法。 固定窗口算法固定窗口算法指每个单位时间相对隔离，一个单位区间的请求量统计跟其他单位区间的请求量统计完全独立。当一个单位时间过期，自动进入下一个时间阶段重新进行计数，固定窗口计数器算法逻辑图如下： 固定窗口计数器算法实现代码（伪代码）如下： int unitTime = 1s //设置单位时间为1s int limitCount = 1000 //设置单位时间只能1000次请求 string limitKey = 'limitkey'; //单位时间限流状态key if（!has（limitKey））{ //初始化单位时间限流状态，并设定期有效期（有效期为一个单位时间） //参考redis的set命令 set（limitKey,0,unitTime） } //原子递增请求量，并返回当前单位时间已有的请求数 int counter = incr（limitKey,1） if counter&gt;limitCount then //超出设置的限流规则，直接返回503（也可自定义返回内容） return 503 else continue;//继续执行业务逻辑 end 滑动窗口限流为了解决固定窗口算法的临界问题，我们将其升级为滑动窗口算法。滑动窗口算法实现借鉴滑动窗口协议，将单位时间继续细化为更小粒度的时间网格，每当用户请求，时间网格随之推移，计数器的的统计时间区间也随之变动。滑动窗口算法的单位时间不再是彼此独立，而是步步递进，彼此重叠。这也是滑动窗口算法跟固定窗口算法最大的区别。 （滑动窗口协议主要用于网络数据传输时的流量控制，避免发送网络堵塞 ） 如下图所示，滑动窗口算法将计数器算法（固定窗口算法）的单位时间进一步细化，例如将1秒分为10个时间网格，每个网格占用100ms的时间。第一个单位时间为0ms-1000ms（以毫秒为单位）、第二个单位时间为100ms-1100ms、第三个单位时间为200ms-1200ms，以此类推。每个单位时间的请求总量都需小于设定的最大请求量由于滑动窗口算法每次都需要统计单位时间的请求量，开销远大于固定窗口算法，所以在真实的业务环境中需要慎重使用滑动窗口算法。 滑动窗口计数器算法实现代码（伪代码）如下： int unitTime = 1000ms //设置单位时间为1s（1000ms） int limitCount = 1000 //设置单位时间只能1000次请求 string listKey = 'limitkey'; //单位时间限流状态key //获取当前毫秒数 demo：1589510627001 int curMilliseconds = nowMilliseconds（）; //计算单位时间的起始时间 int startMilliseconds = curMilliseconds-unitTime*1000 //获取单位时间的起始时间 //获取当前往前推1s 之内的所有请求量（这一步及耗性能） //参考redis的ZCOUNT命令 int counter = ZCOUNT（listKey,startMilliseconds,curMilliseconds） if counter&gt;limitCount //超出设置的限流规则，直接返回503（也可自定义返回内容） return 503 else ZADD（listKey,curMilliseconds,唯一标识） continue;//继续执行业务逻辑 end 漏桶算法漏桶算法业务逻辑也相对简单，如下图所示：水滴（用户请求）优先注入到桶中（定长队列、先进先出队列），桶（队列）盛满后自动抛弃（限流）多余的水（请求），另外桶以匀速的方式漏出水滴（处理请求）。 由此可见，漏桶算法以绝对平均的速度处理用户请求，无论用户请求有多大，最终消费用户请求的速率是固定不变的。在真实的业务场景中，漏桶算法可以解决请求毛刺问题（不平均问题），但面对合法的突发流量，漏桶算法就有点捉襟见肘。漏桶算法的业务逻辑如下： 创建定长队列（demo：长度固定为1000的队列） 用户请求优先入队列（如果队列已满，直接抛弃请求）（入队列速率不限定） 事件调度器以固定速率（demo：1000r/s）消费队列数据，并释放队列资源 漏桶算法实现代码（伪代码）如下： //代码实现(伪代码) local rate = 1ms //设置生产速率为1个/ms local bucketSize = 1000 //漏桶大小 设置可容纳1000个水滴 //初始化漏桶 local bucketQueue = new BucketQueue(bucketSize) //用户请求 local userRequest = new UserRequest(); local res = bucketQuest.push(userRequest) if res ==false then //目前漏桶已满，无法将请求放入漏桶(队列),直接返回503(也可自定义） return 503 else //等待事件调度处理 end //队列消费（每1ms处理一个请求(一滴水)） setTimeout(function () { local userRequest = bucketQuest.lpop() //执行业务逻辑 }, rate); 令牌桶算法令牌桶算法与漏桶算法有相似之处，都包含2部分业务逻辑。漏桶算法的2部分业务逻辑为：漏桶队列+事件调度器；令牌桶算法的2部分业务逻辑为：令牌生产+令牌消费。漏桶算法是以固定的速率处理用户请求（消费），而令牌桶算法则以固定的速率生产令牌（生产）。 如下图所示：令牌工厂以固定的速率生产令牌并注入到令牌桶中，令牌桶满时会自动抛弃多余的令牌。当有用户请求，优先从令牌桶获取有效令牌（可以理解为打开大门的钥匙），只有获取到令牌的请求才会继续向下执行业务逻辑，否则直接拒绝请求（限流）。其中需要重点关注的是：1、一个令牌不可被2个请求获取（需要加锁，并置为不可用状态）；2、在请求处理完毕后需销毁令牌。 令牌桶算法实现代码（伪代码）如下： //代码实现(伪代码) local tokenProducerRate = 1ms //设置生产速率为1个/ms local bucketSize = 1000 //令牌桶大小 设置可容纳1000个令牌 local bucketKey = \"bucketKey\" //令牌桶名称 bucketKey.setSize(bucketSize) //设置令牌桶大小 local token = bucketKey.getValidToken() //获取有效令牌 if token ~= false then token.lock() //加锁，需要原子性 else //超出设置的限流规则，直接返回503(也可自定义) return 503 end //继续执行业务逻辑 token.destroy() //令牌销毁 //令牌工厂代码（每1ms向令牌桶推送一个令牌） setTimeout(function () { local token = new Token(); local result = bucketKey.push(token) if result == false then //向令牌桶已满，push命令失败 else //向令牌桶未满，push成功 end }, tokenProducerRate); 限流算法比较","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://quricolouis.github.io/tags/Java/"},{"name":"分布式","slug":"分布式","permalink":"http://quricolouis.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"author":"QuricoLouis"},{"title":"负载均衡原理及算法","slug":"负载均衡原理及算法","date":"2021-09-09T06:39:23.103Z","updated":"2021-09-10T09:09:05.697Z","comments":true,"path":"posts/59472fd8.html","link":"","permalink":"http://quricolouis.github.io/posts/59472fd8.html","excerpt":"","text":"@TOC 背景面对大量用户访问、高并发请求，单机网站可以从软硬件两个方面寻求解决方法： 硬件方面：可以使用高性能的服务器、大型数据库，存储设备，高性能Web服务器； 软件方面：采用高效率的编程语言(比如Go，Erlang，Scala)等。 但是，当单机容量达到极限时，我们需要考虑业务拆分和分布式部署，来解决大型网站访问量大，并发量高，海量数据的问题。即需要从架构方面寻求解决方案。 概述 负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。 负载均衡（Load Balance），意思是将负载（如前端的访问请求）进行平衡、（通过负载均衡算法）分摊到多个操作单元（服务器，中间件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。可以理解为，负载均衡是高可用和高并发共同使用的一种技术。 负载均衡的作用： 1、增加吞吐量，解决并发压力（高性能）； 2、提供故障转移（高可用）； 3、通过添加或减少服务器数量，提供网站伸缩性（扩展性）； 4、安全防护（负载均衡设备上做一些过滤，黑白名单等处理）。 原理系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。 纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。 典型负载均衡架构如下： 分类按照软硬件分类硬件负载均衡采用硬件的方式实现负载均衡，一般是单独的负载均衡服务器，价格昂贵，常用的有：F5、A10、Citrix Netscaler。 优点： 硬件负载均衡稳定性更强，双机或集群的效果更佳，可以应对高并发、高吞吐的网络环境中。 在策略配置方面，可以实现深度的健康检查方法，而不是简单的ping或tcp的方式，而是可以针对业务层进行健康检查，整体的策略调度更灵活、配置更方便，在七层负载方面更具优势。 缺点： 价格昂贵； 扩展能力差，无法进行扩展和定制； 调试和维护比较麻烦，需要专业人员。 选择： 核心系统必须使用硬件负载均衡设备； 测试系统和一般系统可以使用软件负载均衡设备。软件负载均衡硬件负载均衡价格昂贵，在实际应用中远不如软件负载均衡普遍。常用的软件负载均衡软件有Nginx、LVS、HaProxy、ats、perlbal、pound等。 Nginx/LVS/HAProxy是目前使用最广泛的三种负载均衡软件。对比： LVS：是基于四层的转发（只能做端口转发，不能做基于URL、目录的转发） HAproxy：是基于四层和七层的转发，是专业的代理服务器 Nginx：是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发 选择： HAproxy和Nginx可做七层转发，URL和目录转发都可以； 中小型企业推荐使用HAproxy（配置简单）； 在很大并发量的时候选择LVS。 按照地理结构分类本地负载均衡本地负载均衡针对本地范围的服务器群做负载均衡 全局负载均衡全局负载均衡针对不同地理位置、不同网络结构的服务器群做负载均衡 全局负载均衡具备的特点： 提高服务器响应速度，解决网络拥塞问题，达到高质量的网络访问效果。 能够远距离为用户提供完全的透明服务,真正实现与地理位置无关性 能够避免各种单点失效，既包括数据中心、服务器等的单点失效，也包括专线故障引起的单点失效。按照实现技术DNS负载均衡 最早的负载均衡技术，利用域名解析实现负载均衡，在DNS服务器，配置多个A记录，这些A记录对应的服务器构成集群。大型网站总是部分使用DNS解析，作为第一级负载均衡。 优点： 使用简单：负载均衡工作交给DNS服务器处理，不需要专门的服务器维护； 提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址，可以加快访问速度。 缺点： 可用性差：新增/修改DNS后，解析时间较长； 扩展性低：DNS负载均衡的控制权在域名商，扩展性有限。 实践建议：将DNS作为第一级负载均衡。 IP负载均衡IP负载均衡，在网络层通过修改请求目标地址进行负载均衡。优点： 在内核进程完成数据分发，比在应用层分发性能更好。 缺点： 所有请求响应都需要经过负载均衡服务器，集群最大吞吐量受限于负载均衡服务器网卡带宽。 链路层负载均衡在通信协议的数据链路层修改mac地址，进行负载均衡。 数据分发时，不修改ip地址，指修改目标mac地址，配置真实物理服务器集群所有机器虚拟ip和负载均衡服务器ip地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。 优点：性能好。 缺点：配置复杂。 实践建议：直接路由（DR）模式最常用。 混合型负载均衡由于多个服务器群内硬件设备、规模、提供服务等差异，可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务，从而达到最佳的性能，将这种方式称之为混合型负载均衡。 按照OSI层次二层负载均衡（数据链路层）负载均衡服务器对外依然提供一个 VIP（浮动IP），集群中不同的机器采用相同IP地址，但机器的MAC地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标MAC地址的方式将请求转发到目标机器实现负载均衡。 三层负载均衡（网络层）负载均衡服务器对外依然提供一个VIP，但集群中不同的机器采用不同的IP地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过IP将请求转发至不同的真实服务器。 四层负载均衡（传输层）四层负载均衡服务器在接受到客户端请求后，通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。 七层负载均衡（应用层）七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用HTTP、DNS 等。七层负载就可以基于这些协议来负载。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。 部署方式路由模式路由模式的部署方式，服务器的网关必须设置成负载均衡机的LAN口地址，且与WAN口分署不同的逻辑网络。因此所有返回的流量也都经过负载均衡。这种方式对网络的改动小，能均衡任何下行流量。 桥接模式桥接模式配置简单，不改变现有网络。负载均衡的WAN口和LAN口分别连接上行设备和下行服务器。LAN口不需要配置IP（WAN口与LAN口是桥连接），所有的服务器与负载均衡均在同一逻辑网络中。由于这种安装方式容错性差，网络架构缺乏弹性，对广播风暴及其他生成树协议循环相关联的错误敏感，因此一般不推荐这种安装架构。 服务直接返回模式这种安装方式负载均衡的LAN口不使用，WAN口与服务器在同一个网络中，互联网的客户端访问负载均衡的虚IP（VIP），虚IP对应负载均衡机的WAN口，负载均衡根据策略将流量分发到服务器上，服务器直接响应客户端的请求。因此对于客户端而言，响应他的IP不是负载均衡机的虚IP（VIP），而是服务器自身的IP地址。也就是说返回的流量是不经过负载均衡的。因此这种方式适用大流量高带宽要求的服务。 常用算法轮询轮询为负载均衡中较为基础也较为简单的算法，它不需要配置额外参数。假设配置文件中共有 M 台服务器，该算法遍历服务器节点列表，并按节点次序每轮选择一台服务器处理请求。当所有节点均被调用过一次后，该算法将从第一个节点开始重新一轮遍历。 特点：由于该算法中每个请求按时间顺序逐一分配到不同的服务器处理，因此适用于服务器性能相近的集群情况，其中每个服务器承载相同的负载。但对于服务器性能不同的集群而言，该算法容易引发资源分配不合理等问题。 优点：服务器请求数目相同；实现简单、高效；易水平扩展。 缺点：服务器压力不一样，不适合服务器配置不同的情况；请求到目的结点的不确定，造成其无法适用于有写操作的场景。 应用场景：数据库或应用服务层中只有读的场景。 加权轮询为了避免普通轮询带来的弊端，加权轮询应运而生。在加权轮询中，每个服务器会有各自的 weight。一般情况下，weight 的值越大意味着该服务器的性能越好，可以承载更多的请求。该算法中，客户端的请求按权值比例分配，当一个请求到达时，优先为其分配权值最大的服务器。 特点：加权轮询可以应用于服务器性能不等的集群中，使资源分配更加合理化。 其核心思想是，遍历各服务器节点，并计算节点权值，计算规则为 current_weight 与其对应的 effective_weight 之和，每轮遍历中选出权值最大的节点作为最优服务器节点。其中 effective_weight 会在算法的执行过程中随资源情况和响应情况而改变。 IP哈希ip_hash 依据发出请求的客户端 IP 的 hash 值来分配服务器，该算法可以保证同 IP 发出的请求映射到同一服务器，或者具有相同 hash 值的不同 IP 映射到同一服务器。 特点：该算法在一定程度上解决了集群部署环境下 Session 不共享的问题。 比率（Ratio）给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。 优先权（Priority）给所有服务器分组，给每个组定义优先权。当最高优先级中所有服务器出现故障，将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。 最少连接将请求分配到连接数最少的服务器（目前处理请求最少的服务器）。 优点：根据服务器当前的请求处理情况，动态分配； 缺点：算法实现相对复杂，需要监控服务器请求连接数； 最快模式（Fastest）传递连接给那些响应最快的服务器。 观察模式（Observed）连接数目和响应时间这两项的最佳平衡为依据为新的请求选择服务器。 预测模式（Predictive）利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。 动态性能分配(Dynamic Ratio-APM)根据收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。 动态服务器补充(Dynamic Server Act)当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。 服务质量(QoS）按不同的优先级对数据流进行分配。 服务类型(ToS)按不同的服务类型（在 Type of Field 中标识）负载均衡对数据流进行分配。 规则模式针对不同的数据流设置导向规则，用户可自行设置。 网络分层负载均衡架构互联网领域对于负载均衡的架构是随着网站规模提升不断演进的，大致分为如下几个阶段： 第一阶段：利用Nginx或HAProxy进行单点的负载均衡，该阶段服务器刚从单机向集群转变，需要在七层做转发。 第二阶段：随着网络规模扩大，Nginx单点瓶颈突出，这时使用LVS或者商用Array就是首要选择，Nginx此时就作为LVS或者Array的节点来使用，具体LVS或Array的是选择是根据公司规模和预算来选择。 第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。 常见互联网分布式架构可分为用户层、反向代理层、Web站点层、业务服务层、数据存储层。互联网分层架构：每层之间交互都有相应的负载均衡方案： 客户端层-&gt;反向代理层：DNS轮询。 反向代理层-&gt;Web站点层：Ngnix（均衡策略：请求轮询/最少连接路由/IP哈希）。 Web站点层-&gt;业务服务层：连接池。 业务服务层-&gt;数据存储层：数据分片，读写分离。 拓：四层负载均衡和七层负载均衡的区别1. 从技术实现原理上 所谓四层负载均衡就是使用IP加端口的方式进行路由转发；七层负载均衡一般是基于请求URL地址的方式进行代理转发。同理，还有基于MAC地址信息(虚拟MAC地址到真实MAC地址)进行转发的二层负载均衡和基于IP地址(虚拟IP到真实IP)的三层负载均衡。 四层负载均衡具体实现方式为：通过报文中的IP地址和端口，再加上负载均衡设备所采用的负载均衡算法，最终确定选择后端哪台下游服务器。以TCP为例，客户端向负载均衡发送SYN请求建立第一次连接，通过配置的负载均衡算法选择一台后端服务器，并且将报文中的IP地址信息修改为后台服务器的IP地址信息，因此TCP三次握手连接是与后端服务器直接建立起来的。 七层服务均衡在应用层选择服务器，只能先与负载均衡设备进行TCP连接，然后负载均衡设备再与后端服务器建立另外一条TCP连接通道。因此，七层设备在网络性能损耗会更多一些。 2. 从安全视角上 四层负载均衡与服务器直接建立起TCP连接，很容易遭受SYN Flood攻击。SYN Flood是一种广为人知的DDoS（分布式拒绝服务攻击）的方式之一，这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，从而使得被攻击方资源耗尽的攻击方式。从技术实现原理上可以看出，四层负载均衡很容易将垃圾流量转发至后台服务器，而七层设备则可以过滤这些恶意并清洗这些流量，但要求设备本身具备很强的抗DDOS流量的能力。 3. 常见四层和七层负载均衡设备 四层: F5、LVS等七层: nginx、apache等 参考链接百度百科负载均衡常用算法介绍负载均衡算法及方案四层负载均衡和七层负载均衡区别在哪里？","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://quricolouis.github.io/tags/Java/"},{"name":"分布式","slug":"分布式","permalink":"http://quricolouis.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"author":"QuricoLouis"},{"title":"Java并发实现原理「JDK源码剖析」","slug":"Java并发实现原理「JDK源码剖析」","date":"2021-08-27T03:41:03.000Z","updated":"2021-09-06T08:54:32.104Z","comments":true,"path":"posts/cd039684.html","link":"","permalink":"http://quricolouis.github.io/posts/cd039684.html","excerpt":"","text":"第一章 多线程基础1.1 线程关闭1.1.1 stop() 与 destory() 函数问：运行一半的线程能否强制杀死？答：在Java中，stop()、destory()之类的函数官方明确不建议使用，如果强制杀死线程，则线程中所用的资源，例&nbsp; 如文件描述符、网络连接等不能正常关闭。一个线程一旦运行起，就不要去强行打断它，合理的关闭方法是让其运行完（也就是函数执行完毕），干净地&nbsp; 释放掉所有的资源，然后推出。如果是一个不断循环运行的线程，就需要用到线程间的通信机制，让主线程通知其退出。 1.1.2 守护线程当在一个JVM进程里开多个线程时，这些线程被分成两类：守护线程和非守护线程。默认开的是非守护线程。当所有的非守护线程推出后，整个JVM进程就会退出。意思就是守护线程“不算数”，守护线程不影响整个JVM进程的退出。例如：垃圾回收线程就是守护线程，它们在后台默默工作，当开发者的所有前台线程(非守护线程)都退出之后，整个JVM进程就退出了。 1.2 interruptedException() 函数与 interrupt() 函数1.2.1 什么情况下会抛出 interrupted 异常只有声明了会抛出 InterruptedException 的函数才会抛出异常例： public static native void sleep(long millis) throws InterruptedException{...} public final void wait() throws InterruptedException{...} public final void join() throws InterruptedException{...} 1.2.2 轻量级阻塞与重量级阻塞轻量级阻塞：能够被中断的阻塞。对应的线程状态是 WAITING 或者 TIMED_WAITING。重量级阻塞：像 synchronized 这种不能被中断的阻塞。对应的状态 BLOCKED。图1-1 线程的状态迁移过程 1.2.3 t.isInterrupted() 与 Thread.interrupted()t.interrupted() 相当于给线程发送了一个唤醒的信号,果线程此时恰好处于 waiting 或者 timed_waiting 状态， 就会抛出一个InterruptedException，并且线程被唤醒。而如果线程此时并没有被阻塞，则线程什么都不会做。但在后续，线程可以判断自己是否收到过其他线程发来的中断信号，然后做一些对应的处理。前者是静态函数，后者是非静态函数，两者之间的区别在于前者只是读取中断状态，不做修改状态；后者不仅读取中断状态，还会重置中断标志位。 1.3 synchronized 关键字1.3.1 锁的对象是什么synchronized关键字的意思是给某个对象加了把锁 对于非静态成员函数，锁其实是家在 a 对象上面的； 对于静态成员函数，锁是加在 A.class 上面的 一个静态成员函数和一个非静态成员函数，都加了synchronized关键字，分别被两个线程调用，它们是否互斥？答：因为是两把不同的锁，所以不会互斥 1.3.2 锁的本质是什么图 1-2 线程、锁和资源关系图多个线程要访问同一个资源。线程就是一段段运行的代码；资源就是一个变量、一个对象或一个文件等；而锁就是要实现线程对资源的访问控制，保证同一时间只能有一个线程去访问某一个资源。从程序角度，锁就是一个“对象”，这个对象要完成的事情： 这个对象内部得有一个标志位（state变量），记录自己有没有被某个线程占用。最简单的情况是这个 state 有 0、1 两个取值，0 表示没有线程占用这个锁，1 表示有某个线程占用了这个锁 如果这个对象被某个线程占用，它得记录这个线程的 thread ID，知道自己是被哪个线程占用了。 这个对象还得维护一个 thread id list，记录其他所有阻塞的、等待拿这个锁的线程。在当前线程释放锁之后（也就是把state从1改回0），从这个 thread id list 里面取一个线程唤醒。 既然锁是一个对象，要访问的共享资源本身也是一个对象，这两个对象可以合成一个对象。资源和锁合二为一，使得在 Java 里面，synchronized 关键字可以加在任何对象的成员上面。这也就意味着，这个对象既是共享资源，同时也具备“锁”的功能。 1.3.3 synchronized 实现原理在 Java 的对象头里，有一块数据叫 Mark Word。在64位机器上，Mark Word 是8字节（64位）的，这64位中有2个重要字段：锁标志位和**占用锁的 tread ID。 ** 1.4 wait() 与 notify()1.4.1 生产者-消费者模型生产者-消费者模型是一个常见的多线程编程模型。图 1-4 生产者-消费者模型一个内存队列，多个生产者线程我那个内存队列放数据；多个消费者线程从内存队列中取数据要实现这样一个编程模型，需要做下面几件事情： 内存队列本身要加锁，才能实现线程安全。 阻塞。当内存队列满了，生产者放不进去时，会被阻塞；当内存队列是空的时候，消费者无事可做，会被阻塞。 双向管理。消费者被阻塞之后，生产者放入新数据，要 notify() 消费者；反之，生产者被阻塞之后，消费者消费了数据，要 notify() 生产者。 第 1 件事必须要做，第 2 件事和第 3 件事不一定要做。 如何阻塞？ 办法1：线程自己阻塞自己，也就是生产者、消费者线程各自调用 wait() 和 notify()。办法2：用一个阻塞队列，当取不到或者放不进去数据的时候，入队/出队函数本身就是阻塞的。 如何双向通知？ 办法1：wait() 和 notify() 机制。办法2：Condition机制 1.4.2 为什么必须和 synchronized 一起使用开两个线程，线程A调用f1()，线程B调用f2()。两个线程之间要通信，对于同一个对象来说，一个线程调用该对象的 wait()，另一个线程调用该对象的 notify()，该对象本身就需要同步！所以，在调用 wait()、notify() 之前，要先通过 synchronized 关键字同步给对象，也就是给该对象加锁。 1.4.3 为什么 wait() 的时候必须释放锁wait()内部伪代码： wait(){ //释放锁 //阻塞，等待被其他线程notify //重新拿锁 } 1.4.4 wait() 与 notify() 的问题生产者本来只想通知消费者，但它把其他的生产者也通知了；消费者本来只想通知生产者，但它把其他的消费者也通知了。原因是 wait() 和 notify() 作用的对象和 synchronized 作用的对象是同一个，每个对象没有区分标识。精确唤醒我们可以用 Condition 来实现。 1.5 volatile 关键字volatile三重功效 64位写入的原子性 内存可见性 禁止重排序1.5.1 64位写入的原子性（Half Write）多线程场景下，线程 A 调用 set(100)，线程 B 调用 get()，在某些场景下，返回值可能不是 100 。这是因为 JVM 规范没有要求 64 位的 long 或者 double 的写入是原子的。在 32 位的机器上，一个 64 位变量的写入可能被拆分成两个 32 位的写操作来执行。这样一来，读取线程就可能读到一半的值 。解决办法也：在 long 前面加上 volatile 关键字。1.5.2 内存可见性不仅 64 位，32 位或者位数更小的赋值和取值操作，其实也有问题。比如一个线程修改变量值为 true 之后，另一个线程去读，读到的事 false，但是之后能读到 true。也就是最终一致性，不是强一致性。所以，内存可见性， 指的是写完之后立即对其他线程可见，它的反面不是不可见，而是稍后才能看见。解决这个问题很容易，给变量加上 volatile 关键字即可。1.5.3 重排序：DCL问题单例模式的线程安全，常用写法为DCL（Double Checking Locking）public case Sington { private static Sington instance; private static Sington getInstance() { if (instance == null) { // DCL synchronized(Sington.class) { // 为了性能，延迟使用synchronized if (instance == null) instance = new Instance(); // 有问题的代码 } } } return instance; } 上述的 instance = new Instance() 代码有问题：其底册会分为三个操作： 分配一块内存 在内存上初始化成员变量 把 instance 引用指向内存。 操作2和3可能重排序。即先把 instance 指向内存，再初始化成员变量，因为二者先后没有依赖关系。此时，另一个线程可能拿到一个未完全初始化的对象，直接去访问里面的成员变量，就可能出错。这就是典型的“构造函数溢出”问题。解决方法：为 instance 变量加上 volatile 修饰。 1.6 JVM与happen-before1.6.1 为什么会存在“内存可见性”问题图 1-4 加入 Store Buffer 和 Load Buffer 的 CPU 缓存体系L1、L2、L3 和主内存之间是同步的，有缓存一致性协议的保证，但是 Store Buffer、Load Buffer 和 L1之间却是异步的。也就是说，往内存中写入一个变量，这个变量会保存在 Storre Buffer 里面，稍后才会异步地写入 L1 中，同时同步 写入主内存中。图 1-5 操作系统内核视角下的CPU缓存模型多个 CPU，多个 CPU 多核，每个核上面可能还有多个硬件线程，对于操作系统来讲，就相当于一个个逻辑 CPU。每个逻辑CPU都有自己的缓存，这些缓存和主内存之间不是完全同步的。图 1-6 JVM抽象内存模型对应到 Java 里，就是 JVM 抽象内存模型 1.6.2 重排序与内存可见性的问题重排序分类： 编译器重排序：对于没有先后依赖关系的语句，编译器可以重新调整语句的执行顺序 CPU 指令重排序：在指令级别，让没有依赖关系的多条指令并行 CPU 内存重排序：CPU 有自己的缓存，指令的执行顺序和写入主内存的顺序不完全一致 CPU 内存重排序是造成“内存可见性”问题的主因例：假设有两个线程，线程 1 执行 X = 1 命令 和 a = Y 命令，线程 2 执行 Y = 1 命令 和 b = X 命令。最后 a、b 的结果应该是什么？因为 线程 1 和 线程 2 的执行顺序不确定，所以结果可能是 a = 0, b = 1 a = 1, b = 0 a = 1, b = 1 正常就这三种可能性，但实际还可能是 a = 0, b = 0，为什么呢？原因是线程 1先执行 X = 1 后执行 a = Y，但此时 X = 1 还在自己的 Store Buffer 里，但在线程2看来，a = Y 和 X = 1 顺序却是颠倒的。指令没有重排序，写入内存的操作被延迟了，也就是内存被重排序了，这就造成内存可见行问题。 1.6.3&nbsp; as-if-serial 语义对于开发者而言，希望不要有任何的重排序，指令执行顺序和代码顺序严格一致，写内存的顺序也严格和代码顺序一致。对于编译器和CPU，希望尽最大可能进行重排序，提升运行效率。单线程程序的重排序规则：只要操作之间没有依赖性，编译器和 CPU 就可以任意重排序，因为执行结果不会改变。这也就是 as-if-serial 语义。多线程程序的重排序规则：编译器和 CPU 只能保证每个线程的 as-if-serial 语义。线程之间的数据依赖和线程影响，需要编译器和 CPU 的上层来决定。 1.6.4 happen-before 是什么如果 A happen-before B，意味着 A 的执行结果必须对 B 可见，也就是保证跨线程的内存可见性。A happen-before B 不代表A一定在B之前执行。基于 happen-before 这种描述方法，JMM 对开发者做出了一系列承诺： 单线程中的每个操作，happen-before 对应线程中任意后续操作 对 volatile 变量的写入，happen-before 对应后续对这个变量的读取 对 synchronized 的解锁，happen-before 对应后续对这个锁的加锁 对于非 volatile 变量的写入和读取，不在这个承诺之列。通俗来讲，就是JVM对编译器和CPU来说，volatilt 变量不能重排序；非 volatilt 变量可以任意重排序。 1.6.5 happen-before 的传递性volatile、synchronized 都具有 happen-before 语义。 1.6.6 C++中的 volatile 关键字在 Java 中的 volatile 关键字不仅具有内存可见性，还会禁止 volatile 变量写入和非 volatile 变量写入的重排序；C++ 中的 volatile 关键字不会禁止这种重排序。 1.7 内存屏障为了禁止编译器重排序和CPU重排序，在编译器和CPU层面都有对应的指令。编译器的内存屏障，知只是为了告诉编译器不要对指令进行重排序。当变异完成之后，这种内存屏障就消失了。CPU内存屏障是CPU提供的指令，可以由开发者显示调用。 1.7.1 Linux 中的内存屏障通过函数 smp_wmb() 插入了一个 Store Barrier 屏障，从而确保了： 更新指针的操作，不会被重排序到修改数据之前。 更新指针的时候，Store Cache 被刷新，其他CPU可见1.7.2 JDK 中的内存屏障JDK8开始，Java在 Unsafe 类中提供了三个内存屏障函数(不是最基本的内存屏障)：public final class Unsafe{ public native void loadFence(); //loadFence=LoadLoad+LoadStore public native void storeFence(); //storeFence=StoreFence+LoadStore public native void fullFence(); //fullFence=LoadFence+StoreFence+StoreLoad } 在理论层面，可以把基本的CPU内存屏障分为4种： LoadLoad：禁止读和读的重排序 StoreStore：禁止写和写的重排序 LoadStore：禁止读和写的重排序 StoreLoad：禁止写和读的重排序 1.7.3 volatile 实现原理实现 volatile 关键字的语义参考做法： 在 volatile 写操作的前面插入一个 StoreStore 屏障。保证 volatile 写操作不会和之前的写操作重排序。 在 volatile 写操作的后面插入一个 StoreLoad 屏障。保证 volatile 写操作不会和之后的读操作重排序。 在 volatile 读操作的后面插入一个 LoadLoad 屏障 + LoadStore 屏障。保证 volatile 读操作不会和之后的读操作、写操作重排序。 1.8 final 关键字1.8.1 构造函数溢出问题对于构造函数溢出，就是一个对象的构造并不是“原子的”，当一个线程正在构造对象时，另外一个线程却可以读到未构造好的“一半对象”。 1.8.2 final 的 happen-before 语义解决构造函数溢出的办法： 给变量都加上 volitile 关键字 为 read/write 函数都加上 synchronized 关键字 给变量加上 final 关键字 final 的 happen-before 语义： 对 final 域的写（构造函数内部），happen-before 于后续对 final 域所在对象的读 对 final 域所在对象的读，happen-before 于后续对 final 域的读 通过这种 happen-before 语义的限定，保证了 final 域的赋值，一定在构造函数之前完成，不会出现另外一个线程读取到了对象，但对象里面的变量却还没有初始化的情形，避免出现构造函数溢出的问题。 1.8.3 happen-before 规则总结 单线程中的每个操作，happen-before 于该线程中任意后续操作 对 volatile 变量的写，happen-before 于后续对这个变量的读 对 synchronized 的解锁，happen-before 于后续对这个锁的加锁 对 final 变量的写，happen-before 于 final 域对象的读，happen-before 于后续对 final 变量的读 四个基本规则再加上 hapen-before 的传递性，就构成JVM对开发者的整个承诺图 1-7 从底向上看 volatile 背后的原理 第二章 Atomic类图 2-1 整个 Concurrent 包的层次体系 2.1 AtomicInteger 和 AtomicLong2.1.1 悲观锁与乐观锁悲观锁：数据发生并发冲突的概率很大，所以读操作之前就上锁。synchronized 关键字和 ReentrantLock 都是悲观锁的典型例子。乐观锁：数据发生并发冲突的概率很小，所以读操作之前不上锁。等到写操作的时候，再判断数据在此期间是否被其他线程修改了。如果被其他线程修改了，就把数据重新读出来，重复该过程；如果没有被修改，就写回去。判断数据是否被修改，同时写回新值，这两个操作要合成一个原子操作，也就是CAS（Compare And Set）。AtomicInteger就是典型的乐观锁 2.1.2 Unsafe的CAS详解public final boolean compareAndSet(int expect, int update){ return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } AtomicInteger 封装过的 compareAndSet 有两个参数。第一个参数 expect 是指变量的旧值（是读出来的值，写回去的时候，希望没有被其他线程修改）；第二个参数 update 是指变量的新值（修改过的，没有写入的值）。当 expect 变量等于当前变量时，说明在修改的期间，没有其他线程对此变量进行过修改，所以可以成功写入，变量被更新为 update，返回 true；否则返回 false； public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 该函数有4个参数，第一个是对象（AtomicInteger 变量）；第二个是对象的成员变量（AtomicInteger 里面包的 int 变量 value），它是 long 型整数，常被称为 xxxOffset，意思是某个成员变量在对应的类中的内存偏移量，表示该成员变量本身。无论是 Unsafe 还是 valueOffset，都是静态的，也就是类级别的，所有对象共用的。在转化的时候，先通过反射（getDeclaredField）获取 value 成员变量对应的 Field 对象，再通过 objectFieldOffset 函数转化成 valueOffset。此处的 valueOffset 就代表了 value 变量本身，后面执行CAS操作的时候，不是直接操作 value，而是操作 valueOffset。 2.1.3 自旋与阻塞当一个线程拿不到锁的时候，有两种基本的等待策略：策略1：放弃CPU，进入阻塞状态，等待后续被唤醒，再重新被操作系统调度。策略2：不放弃CPU，空转，不断重试，也就是所谓的“自旋”。这两种策略不是互斥的，可以结合使用。 2.2 AtomicBoolean 和 AtomicReference2.2.1 为什么需要 AtomicBooleanAtomicBoolean： if(flag == false){ flag = true; ... } 实现 compare 和 set 两个操作合在一起的原子性，这也是CAS提供的功能。 if(compareAndSet(false, true)){ ... } AtomicReference： public final boolean compareAndSet(V expect, V update){ return unsafe.compareAndSwapObject(this, valueOffset, exprct, update); } 2.2.2 如何支持 boolean 和 double 类型 AtomicBoolean 类型怎么支持？ 对于用 int 型来代替的，在入参的时候，将 boolean 类型转换成 int 类型；在返回值的时候，将 int 类型 转换成 boolean 类型。 double 类型怎么支持？2.3 AtomicStampedReference 和 AtomicMarkanle2.3.1 ABA问题与解决方法CAS 都是基于“值”来做比较的。但如果另外一个线程把变量的值从 A 改为 B，再从 B 改回到 A，尽管修改过两次，可是在当前线程做 CAS 操作的时候，却会因为值没变而认为数据没有被其他线程修改过，这就是所谓的ABA问题。解决方法：不仅比较“值”，还要比较“版本号”2.3.2 为什么没有 AtomicStampedInteger AtomictStampedLong因为要同时比较“值”和“版本号”，而 Integer 型或者 Long 型的 CAS 没有办法同时比较这两个变量，于是只能把值和版本号封装成一个对象，然后通过对象引用的 CAS 来实现。2.3.3 AtomicMarkableReferencePair 里面的版本号是 boolean 类型的，而不是整型的累加变量。因为是 boolean类型，只能有 true、false 两个版本号，所以并不能完全避免 ABA 问题，只是降低了 ABA 发生的概率。2.4 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater 和 AtomicReferenceFieldUpdater2.4.1 为什么需要 AtomicXXXFieldUpdater如果一个类是自己编写的，则可以在编写的时候把成员变量定义为 Atomic 类型。如果是一个已有的类，在不能更改其源码的情况下，要想实现对其成员变量的原子操作，就需要 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater 和 AtomicReferenceFieldUpdater。2.4.2 限制条件要想使用 AtomicIntegerFieldUpdater 修改成员变量，成员变量必须是 volatile 的 int 类型（不能是 Integer 包装类）2.5 AtomicIntegerArray、AtomicLongArray 和 AtomicReferenceArrayConcurrent 包提供了 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 三个数组元素的原子操作。注：并不是说对整个数组的操作是原子的，而是针对数组中一个元素的原子操作而言。2.5.1 使用方法相比与 AtomicInteger 的 getAndIncrement() 函数，这里只是多了一个传入参数：数组的下标 ipublic final boolean compareAndSet(int i, int expect, int update){...} public final int getAndDecrement(int i){...} public final int getAndSet(int i, int newValue){...} 2.5.2 实现原理其底层的 CAS 函数用的还是 compareAndSwapInt，但是把数组下标 i 转化成对应的内存偏移量，所用的方法和之前的 AtomicInteger 不太一样。private static long byteOffset(int i){ return ((long) i &lt;&lt; shift) + base; } 把下标 i 换成对应的内存地址，用到 shift 和 base 两个变量。这两个变量都是 AtomicIntegerArray 的静态成员变量，用 Unsafe 类的 arrayBaseOffset 和 arrayIndexScale 两个函数来获取。base 表示数组的首地址的位置，scale 表示一个数组元素的大小，i 的偏移量则等于 i * scale + base。但为了优化性能，使用了位移操作，shift 表示 scale 中 1 的位置（scale 是2的整数次方）。所以，偏移量的计算变成上面代码中的：i &lt;&lt; shift + base，表达的意思就是：i * scale + base。2.6 Striped64 与 LongAdder图 2-2 Striped64 相关的类的继承层次2.6.1 LongAdder 原理AtomicLong 内部是一个 volatile long 型变量，由多个线程对这个变量进行CAS操作。多个线程同时对一个变量进行CAS操作，在高并发的场景下仍不够快，如果再要提高性能，该怎么做？把一个变量拆分成多份，变为多个变量，有些类似于 ConcurrentHashMap 的分段锁的例子。把一个 Long 型拆成一个 base 变量外加多个 Cell，每个 Cell 包装了一个 Long 型变量。当多个线程并发累加的时候，如果并发度低，就直接加到 base 变量上；如果并发度高，冲突大，平摊到这些 Cell 上。在最后取值的时候，再把 base 和这些 Cell 求 sum 运算。2.6.2 最终一致性在 sum 求和函数中，并没有对 cells[] 数组加锁。也就是说，一边有线程对其执行求和操作，一边还有线程修改数组里的值，也就是最终一致性，而不是强一致性。2.6.3 伪共享于缓存行填充 @sun.misc.Contended每个CPU都有自己的缓存。缓存与主内存进行数据交换的基本单位叫 Cache Line（缓存行）。要刷新到主内存的时候，最少要刷新64字节。 2.6.4 LongAdder 核心实现当一个线程调用 add(x) 的时候，首先会尝试使用 casBase 把 x 加到 base 变量上。如果不成功，则再用 a.cas(..) 函数尝试把 x 加到 Cell 数组的某个元素上。如果还不成功，最后再调用 longAccumulate(..) 函数。注：Cell[] 数组的大小始终是2的整数次方，在运行中会不断扩容，每次扩容都是增长2倍。 2.6.5 LongAccumulatorLongAccumulator 与 LongAdder 构造函数对比： public LongAdder() {...} public LongAccumulator(LongBinaryOperator accumulatorFunction, long identity) {...} public interface LongBinaryOperator { long applyAsLong(long left, long right); } LongAdder 只能进行累加操作，并且初始值默认为0；LongAccumulator 可以自己定义一个二元操作符，并且传入一个初始值。操作符的左值，就是 base 变量或者 Cells[] 中元素的当前值；右值，就是 add() 函数传入的参数 x。 LongAccumulator 的 accumulate(x) 函数与 LongAdder 的 add(x) 函数类似，最后都是调用 Striped64 的 LongAccumulate(…) 函数。唯一的差别是 LongAdder 的 add(x) 函数调用的是 casBase(b, b+x)，LongAccumulator 调用的是casBase(b, r)，其中，r = function.applyAsLong(b = base, x)。2.6.6 DoubleAdder 与 DoubleAccumulator第三章 Lock 与 Condition3.1 互斥锁3.1.1 锁的可重入性可重入锁（ReentrantX）是指当一个线程调用 object.lock() 拿到锁，进入互斥区后，在此调用 object.lock()，仍然可以拿到该锁。通常的锁都要设计成可重入的，否则会发生死锁。3.1.2 类继承层次图 3-1 与 ReentrantLock 相关类之间的继承关系I 表示界面（Interface），A表示抽象类（Abstract Class），C表示类（Class），$表示内部类。实线表示继承关系，虚线表示引用关系。常用方法 Lock()/unLock()。lock() 不能被中断，对应的 lockInterrupttibly() 可以被中断。3.1.3 锁的公平性 vs. 非公平性Sync 是一个抽象类，它有两个子类 FairSync 与 NonfairSync，分别对应公平锁和非公平锁一个新的线程来了之后，看到有很多线程在排队，自己排到队伍末尾，这叫公平；线程来了之后直接去抢锁，这叫不公平。默认设置的是非公平锁，为了提高效率，减少线程切换。3.1.4 锁实现的基本原理Sync 的父类 AbstractQueuedSynchronizer 常被称作队列同步器（AQS）为了实现一把具有阻塞或唤醒功能的锁，需要几个核心要素： 需要一个 state 变量，标记该锁的状态。state 变量至少有两个值：0、1。对 state 变量的操作，要确保线程安全，也就是会用到 CAS。 需要记录当前是哪个线程持有锁。 需要底层支持对一个线程进行阻塞或唤醒操作。 需要有一个队列维护所有阻塞的线程。这个队列也必须是线程安全的无锁队列，也需要用到 CAS。 state 取值不仅可以是0、1，还可以大于1，就是为了支持锁的可重入性。例如，同样一个线程，调用5次lock，state 会变成5；然后调用5次 unlock，state 减为0.当 state = 0 时，没有线程持有锁，exclusiveOwnerThread = null；当 state = 1 时，有一个线程持有锁，exclusiveOwnerThread = 该线程；当 state &gt; 1 时，说明该线程重入了该锁。 在当前线程调用 park()，该线程就会堵塞；在另外一个线程中，调用 unpark(Thread t)，传入一个被阻塞的线程，就可以唤醒阻塞在 park() 地方的线程。unpark(Thread t)实现了一个线程对另一个线程的“精准唤醒”。 3.1.5 公平与非公平的 lock() 实现3.1.6 阻塞队列与唤醒机制park() 函数返回有两种情况：情况1：其他线程调用了 unpark(Thread t)情况2：其他线程调用了 t.interrupt()。注意，lock()不能响应中断，但LockSupport.park() 会响应中断。 3.1.7 unlock() 实现分析release() 里面做两件事：tryRelease(..) 函数释放锁；unparkSuccessor(..) 函数唤醒队列中的后继者。因为是排他锁，只有已经持有锁的线程才有资格调用 release(..)，这意味者没有其他线程与它争论。所以在 tryRelease(..) 函数中，对 state 值的修改，不需要CAS操作，直接减1即可。 3.1.8 lockInterruptibly() 实现分析当 parkAndCheckInterrupt() 返回 true 的时候，说明有其他线程发送中断信号，直接抛出 InterruptedException，跳出 for 循环，整个函数返回。 3.1.9 tryLock() 实现分析public boolean tryLock() { return sync.nonfairTryAcquire(1); } tryLock() 实现基于调用非公平锁的 tryAcquire(..)，对 state 进行 CAS 操作，如果操作成功就拿到锁；如果操作不成功则直接返回 false，也不阻塞。 3.2 读写锁读写锁（ReentrantReadWriteLock）就是读线程和读线程之间可以不用互斥了。 3.2.1 类继承层次图 3-3 ReentrantReadWriteLock 类继承层次ReentrantWriteLock 实现了该接口 ReadWriteLock rwLock = new ReentrantReadWriteLock(); Lock rLock = rwLock.readLock(); rLock.lock(); rLock.unlock(); Lock wLock = rwLock.writeLock(); wLock.lock(); wLock.unlock(); 3.2.2 读写锁实现的基本原理ReadLock 和 WriteLock 是两把锁，实际上是同意把锁的两个视图（读线程和写线程）读线程和读线程不互斥（可以同时拿到这把锁），读线程和写线程互斥，写线程和写线程互斥。当 state = 0 时，说明既没有线程持有读锁，也没有线程持有写锁；当 state != 0 时，要么有线程持有读锁，要么有线程持有写锁，两者不能同时成立，因为读和写互斥。这时再进一步通过 sharedCount(state) 和 exclusiveCount(state) 判断到底是读线程还是写线程持有了该锁。 3.2.3 AQS 的两对模板方法acquire/release、acquireShared/releaseShared 是 AQS 里面的两对模板方法。互斥锁和读写锁的写锁都是基于 acquire/release 模板方法来实现的，读写锁的读锁都是基于 acquireShared/releaseShared 模板方法来实现的。图 3-4 四种锁的策略的实现示意图最终对应关系： 读锁的公平实现：Sync.tryAcquireShared() + FairSync 中的两个覆写的子函数。 读锁的非公平实现：Sync.tryAcquireShared() + NonfairSync 中的两个覆写的子函数。 写锁的公平实现：Sync.tryAcquire() + FairSync 中的两个覆写的子函数。 写锁的非公平实现：Sync.tryAcquire() + NonfairSync 中的两个覆写的子函数。 对于公平，不论是读锁，还是写锁，只要队列中有其他线程在排队，就不能直接去抢锁，要排在队列尾部。对于非公平，读锁和写锁的实现策略略有差异。写锁，写线程能抢锁，前提是 state = 0，只有在没有其他线程持有读锁或写锁的情况下，它才有机会去抢锁。当 state != 0，由于持有写锁线程，再次重入。写线程是非公平的，不断去抢（一直返回 false）。但对于读线程，读线程和读线程不互斥的，对于读线程的非公平，要做一些“约束”。当发现队列的第一个元素是写线程，读线程要阻塞一下。 3.2.4 WriteLock 公平 vs. 非公平实现 tryAcquire() 实现分析 if(c != 0) and w == 0，说明当前一定是读线程拿着锁，写锁一定拿不到，返回false。 if(c != 0) and w != 0，说明当前一定是写线程拿着锁，执行 current != getExclusiveOwnerThread() 的判断，发现 ownerThread 不是自己，返回 false。 if(c != 0) and w == 0，且 curent = getExclusiveOwnerThread()，才会走到 if(w + exclusiveCount(acquires) &gt; MAX_COUNT)。判断重入次数，重入次数超过最大值，抛出异常。 if(c = 0)，说明当前既没有读线程，也没有写线程持有该锁。可以通过CAS操作开抢，抢成功后，调用 setExclusiveOwnerThread(current)，把 ownerThread 设成自己 tryRelease(..) 实现分析 因为写锁是排他的，在当前线程持有写锁的时候，其他线程既不会持有写锁，也不会持有读锁。所以，这里对 state 值的调减不需要 CAS 操作，直接减一即可。 3.2.5 ReadLock 公平 vs. 非公平实现 tryAcquireShared(..) 实现分析 tryReleaseShared(..) 实现分析 3.3 Condition3.3.1 Condition 与 Lock 的关系Condition 本身也是接口，其功能和 wait/notify 类似Condition 必须和 Lock 一起使用 3.3.2 Condition 的使用场景一个用数组实现的阻塞队列，执行 put(..) 操作的时候，队列满了，生产者线程被阻塞；执行 take() 操作的时候，队列为空，消费者线程被阻塞。 3.3.3 Condition 实现原理读写锁中的 ReadLock 是不支持 Condition 的，读写锁的写锁和互斥锁都支持 Condition。虽然它们都调用的是自己的内部类 Sync，但内部类 Sync 都继承子、自 AQS。 3.3.4 await() 实现分析 线程调用 await() 的时候，肯定已经拿到了锁。 在线程执行 wait 操作之前，必须先释放锁。 线程从 wait 中被唤醒后，必须用 acquireQueued(node, savedState) 函数重新拿锁。 checkInterruptWhileWaiting(node) 代码在 park(this) 代码之后，是为了检测在 park 期间是否收到过中断信号。 isOnSyncQueue(node) 用于判断该 Node 是否在 AQS 的同步队列里。 3.3.5 awaitUninterruptibly() 实现分析awaitUninterruptibly() 不会响应中断，其函数的定义不会有中断异常抛出，继续执行 while 循环。 3.3.6 notify() 实现分析在调用 notify() 的时候，必须先拿到锁，然后从队列中取出 firstWait，唤醒它。 3.4 StampedLock3.4.1 为什么引入 StampedLock图 3-1 三种锁的并发度对比因为 ReentrantLock 采用的“悲观锁”的策略。当第一个线程拿到锁之后，第二个、第三个读线程还可以拿到锁，使得写线程一直拿不到锁，可能导致写线程“饿死”。虽然在其公平或非公平的实现中，都尽量避免这种情形，但还是有可能发生。StampedLock 引入了“乐观锁策略”，读的时候不加锁，读出来发现数据被修改了，再升级为“悲观锁”，相当于降低了“读”的地位，把抢锁的天平往“写”的一方倾斜了一下，避免写线程被锁死。 3.4.2 使用场景首先，执行 move 操作的时候，要加写锁，写操作和写操作也是互斥的。关键在于读的时候，用了一个“乐观锁”sl.tryOptimisticRead()，相当于在读之前给数据的状态做了一个“快照”。然后，把数据拷贝到内存里面，再用之前，再对比一次版本号。如果版本号变了，则说明在读的期间有其他线程修改了数据。读出来的数据废弃，重新获取读锁。 long stamp = sl.tryOptimisticRead(); //在读之前，获取数据版本号 double currentX = x, currentY = y; //读：将一份数据拷贝到线程的栈内存中 if (!sl.validate(stamp)){...} //读之后：判断读出来数据是否可以使用（所谓可以使用，是指读的期间没有其他线程修改过数据） 这三行关键代码对顺序非常敏感，不能有重排序。因为 state 变量已经是 volatile，所以可以禁止重排序，但 stamp 并不是 volatile 的。为此，在 volatile(stamp) 函数里面插入内存屏障 3.4.3 “乐观锁”的实现原理3.4.4 悲观锁/写：“阻塞”与“自旋”策略实现差异第四章 同步工具类4.1 SemaphoreSemaphore 也就是信号量，提供了资源数量的并发访问控制图 4-1 Semaphore 相关类的继承体系 4.2 CountDownLatch因为是基于AQS阻塞队列实现的，所以可以让多个线程阻塞在 state = 0 条件上，通过 countDown() 一直累减 state，减到0后一次性唤醒所有线程。假设初始总数为M，N个线程 await()，M个线程countDown()，减到0之后，N个线程被唤醒。图 4-3 多个线程阻塞在 await() 示意图 4.2.1 CountDownLatch 使用场景一个主线程要等待10个 Worker 线程工作完毕才退出，就能使用 CountDownLatch 来实现 CountDownLatch doneSignal = new CountDownLatch(10); //初始为10 doneSignal.await(); //主线程调用该方法，阻塞在这 doneSignal.countDown(); //10个Worker线程，每个线程工作完毕后，调用1次countDown()，计算器减1。当减到0之后，主线程被唤醒 图 4-2 CountDownLatch 相关类的继承层次 4.2.2 await() 实现分析await() 调用的是AQS模版方法从 tryAcquireShared(..) 方法的实现来看，只要 state != 0，调用 await() 方法的线程便会被释放入AQS的阻塞队列，进入阻塞状态。 4.2.3 countDown() 实现分析countDown() 调用的AQS的模版方法 releaseShared()，里面的 tryReleaseShared(..) 被 CountDownLatch.Sync 重新实现。只有 state = 0，tryReleaseShared(..) 才会返回 true，然后执行 doReleaseShared(..)，一次性唤醒队列中所有阻塞的线程。 4.3 CyclicBarrier4.3.1 CyclicBarrier 使用场景等待所有线程到达同步点再开始下一个阶段。 4.3.2 CyclicBarrier 实现分析 CyclicBarrier 是可以被重用的。所有线程互相等待，到齐后一起被唤醒各自执行接下来的逻辑。每一轮被称为一个 Generation，就是一个同步点 CyclicBarrier 会响应中断。线程没有到齐，如果收到中断信号，所有阻塞线程会被唤醒，就是 breakBarrier() 函数。然后 count 被重置为初始值（parties），重新开始。 barrierAction 只会被执行一次。 4.4 Exchanger4.4.1 Exchanger 使用场景Exchanger 用于线程之间交换数据 4.4.2 Exchanger 实现原理Exchanger 的核心机制和 Lock 一样，也是 CAS + park/unpark。每个线程在调用 exchange(..) 函数交换数据的时候，会先创建一个 Node 对象，这个 Node 对象就是对该线程的包装，里面包含了两个字段：1个是线程要交互的数据，另1个是该线程自身。注：Node 本身是继承自AtomicReference 的，所以除了这两个字段，Node 还有第3个字段，记录的是对方所要交换的数据，初始为 NULL。Slot 的 AtomicReference 就是指向的一个 Node，通过 Slot 和 Node 相结合，实现了2个线程之间的数据交换。线程1持有数据 item1，线程2持有数据 item2，各自调用 exchange(..)，会各自生成一个 Node。而 Slot 只会指向2个 Node 中的1个：如果是线程1先调用的 exchange(..)，那么 Slot 就指向 Node1 ，线程1阻塞，等待线程2来交换；反之，如果是线程2先调用的 exchange(..) ，那么 Slot 就指向 Node2，线程2阻塞，等待线程1来交换数据。图 4-3 Slot 与 Node 相结合实现2个线程交换数据一个 Slot 只能支持2个线程之间交换数据，要实现多个线程并行地交换数据，需要多个Slot，因此在 Exchange 里面定义了 Slot 数组： private volatile Slot[] arena = new Slot[CAPACITY]; 4.4.3 exchanger(V x) 实现分析4.5 Phaser4.5.1 用 Phaser 替代 CyclicBarrier 和 CountDownLatch 用 Phaser 替代 CyclicBarrier Phaser ph = new Phaser(10); //初始为10 ph.awaitAdance(ph.getPhase()); //主线程调用该方法，阻塞在这。 ph.arrive(); //每个线程工作完成之后，调用1次arrive()。 用 Phaser 替代 CountDownLatch 4.5.2 Phaser 新特性特性1：动态调整线程个数CyclicBarrier 所要同步的线程个数是在构造函数中指定的，之后不能更改。而 Phaser 可以在运行期间动态地调整要同步的线程个数。 特性2：层次 Phaser父 Phaser 并不用感知子 Phaser 的存在，当子 Phaser 中注册的参与者数量大于0时，会把自己向父节点注册；当子 Phaser 中注册的参与者数量等于0时，会自动向父节点解注册。父 Phaser 把子 Phaser 当作一个正常参与的线程就可以了。 4.5.3 state 变量解析state 变量在构造函数中是如何赋值的？ 当 parties = 0 时，state 被赋予一个 EMPTY 常量，常量为1； 当 parties != 0 时，把 phase 值左移32位；把 parties 左移16位；然后 parties 也作为最低的16位，3个值做或操作，赋值给 state。4.5.4 阻塞与唤醒（Treiber Strack）基于上述的 state 变量，对其执行 CAS 操作，并进行相应的阻塞与唤醒。右边的主线程会调用 awaitAdcance() 进行阻塞；左边的 arrive() 会对 state 进行 CAS 的累减操作，当未到达的线程数减到0时，唤醒右边阻塞的主线程。图 4-10 基于 state 的 CAS 的阻塞与唤醒示意图4.5.5 arrive() 函数分析arrive() 和 arriveAndDeregister() 内部调用的都是 doArrive(boolean)函数。arrive() 把“未达到线程数”减1； arriveAndDeregister() 把“未到达线程数”和“下一轮的总线程数”都减1.4.5.6 awaitAdvance() 函数分析第五章 并发容器5.1 BlockingQueue在所有的并发容器中，BlockingQueue 是最常见的一种。BlockingQueue 是一个带阻塞功能的队列当入队列时，若队列已满，则阻塞调用者；当出队列时，若队列为空，则阻塞调用者。图 5-1 BlockingQueue 的各种实现类5.1.1 ArrayBlockingQueueArrayBlockingQueue 是一个用数组实行的环形队列，在构造函数中，会要求传入数组的容量。public ArrayBlockingQueue(int capacity, boolean fair) {...} 5.1.2 LinkedBlockingQueueLinkedBlockingQueue 是一种基于单向链表的阻塞队列。因为队头和队尾是2个指针分开操作的，所以用了2把锁 + 2个条件，同时有1个 AtomicInteger 的原子变量记录 count 数。LinkedBlockingQueue 和 ArrayBlockingQueue 的实现差异： 为了提高并发度，用2把锁，分别控制队头、队尾的操作。意味着在 put(..) 和 put(..) 之间、take(..) 和 take(..) 之间互斥的，put(..) 和 take(..) 之间并不互斥的。但对于 count 变量，双方都需要操作，所以必须是原子类型。 因为各自拿了一把锁，所以当需要调用对方的 condition 的 signal 时，还必须再加上对方的锁，就是 signalNotEmpty() 和 signalNotFull() 函数。 不仅 put 会通知 take，take 也会通知 put。当 put 发现非满时，也会通知其他 put 线程；当 take 发现非空的时候，也会通知其他 take 线程。 5.1.3 PriorityBlockingQueue队列通常是先进先出的，而 PriorityQueue 是按照元素的优先级从小到大出队列的。PriorityQueue 中的2个元素之间需要可以比较大小，并实现 Comparable 接口。在阻塞的实现方面，和 ArrayBlockingQueue 的机制相似，主要区别是用数组实现了一个二叉堆，从而实现按优先级从小到大出队列。另一个区别是没有 notFull 条件，当元素个数超过数组长度时，执行扩容操作。 5.1.4 DelayQueueDelayQueue 即延迟队列，也就是一个按延迟时间从小到大出队的 PriorityQueue。所谓延迟时间，就是“未来将要执行的时间” - “当前时间”。为此，放入 DelayQueue 中的元素，必须实现 Delayed 接口。 public interface Delayed extends Comparable&lt;Delayed&gt;{ long getDelay(TimeUnit unit); } 关于该接口，有两点说明： 如果 getDelay 的返回值小于或等于0，则说明该元素到期，需要从队列中拿出来执行。 该接口首先继承了 Comparable 接口，所以要实现该接口，必须实现 Comparable 接口 不是每放入一个元素，都需要通知等待的线程。放入的元素，如果其延迟时间大于当前堆顶的元素延迟时间，就没必要通知等待的线程；只有当延迟时间是最小的，在堆顶时，才有必要通知等待的线程，也就是上面代码中的 if(q.peek()==e)段落。 5.1.5 SynchronousQueueSynchronousQueue 是一种特殊的 BlockingQueue，它本身没有容量。先调 put(..)，线程会阻塞；直到另一个线程调用 take()，两个线程才同时解锁，反之亦然。如果是公平模式，则用 TransferQueue 实现；如果是非公平模式，则用 TransferStack 实现。put/take 都调用了 transfer(..) 接口。而 TransferQueue 和 TransferStack 分别实现了这个接口。该接口在 SynchronousQueue 内部。如果是 put(..)，则第1个参数就是对应的元素；如果是 take()，则是第1个为 null。后2个参数分别为是否设置超时和对应的超时时间。 abstract static class Transferer{ abstract Object transfer(Object e, boolean timed, long nanos); } TransferQueue TransferQueue 是一个基于单向链表而实现的队列，通过 head 和 tail 2个指针记录头部和尾部。初始的时候，head 和 tail 会指向一个空节点。TransferQueue 的工作原理阶段(a)：队列中是一个空的节点，head/tail都指向这个空节点。阶段(b)：3个线程分别调用 put，生成3个 QNode，进入队列。阶段(c)：来了一个线程调用 take，会和队列头部的第1个 QNode 进行配对。阶段(d)：第1个 QNode 出队列。关键点：put 节点和 take 节点一旦相遇，就会配对出队列，所以在队列中不可能同时存在 put 节点和 take 节点，要么所有节点都是 put 节点，要么所有节点都是 take 节点。 TransferStack TransferStack 是一个单向链表，只需要 head 指针就能实现入栈和出栈操作。链表中的节点有三种状态，REQUEST 对应 take 节点，DATE 对应 put 节点，二者配对后，会生成一个 FULFILLING 节点，入栈，然后 FULLING 节点和被配对的节点一起出栈。TransferStack 的工作原理阶段(a)：head 指向 NULL。不同于 TransferQueue，这里没有空的头节点。阶段(b)：3个线程调用3次 put，依次入栈。阶段(c)：线程4调用 take，和栈顶的第1个元素配对，生成 FULLFILLING 节点，入栈。阶段(d)：栈顶的2个元素同时入栈。 5.2 BlockingDequeBlockingDeque 定义了一个阻塞的双端队列接口。该接口继承了 BlockingQueue 接口的同时，增加对应双端队列操作接口。该接口只有一个实现，就是 LinkedBlockingDeque 5.3 CopyOnWriteCopyOnWrite 指在“写”的时候，不是直接“写”源数据，而是把数据拷贝一份进行修改，再通过悲观锁或者乐观锁的方式写回。 5.3.1 CopyOnWriteArrayList5.3.2 CopyOnWriteArraySetCopyOnWriteArraySet 就是用 Array 实现的一个 Set，保证所有元素都不重复。 5.4 ConcurrentLinkedQueue/Deque 初始化 初始化的时候，head 和 tail 都执行一个 NULL 节点。 入队列 初始的时候，队列中有1个节点 item1，tail 指向该节点，假设线程1要入队 item2 节点：step1：p = tail，q = p.next = NULL。step2：对p的 next 执行 CAS 操作，追加 item2，成功之后，p = tail。所以上面的 casTail 函数不会执行，直接返回。此时 tail 指针没有变化。step3：p = tail，q = p.next。step4：q != NULL，因此不会入队新节点。p，q都后移1位。step5：q = NULL，对p的 next 执行 CAS 操作，入队 item3 节点。step6：p != t，满足条件，执行上面的 casTail 操作，tail 后移2个位置，到达队列尾部。关键点： 即使 tail 指针没有移动，只要对p的 next 指针成功进行 CAS 操作，就算成功入队列。 只有当 p != tail 的时候，才会后移 tail 指针。也就是说，每连续追加2个节点，才后移1次 tail 指针。即使 CAS 失败，也可以由下一个线程来移动 tail 指针。 出队列 假设初始的时候 head 指向空节点，队列中有 item1，item2，item3 三个节点。step1：p = head，q = p.next，p != q。step2：后移p指针，使得 p = q。step3：出队列。关键点：此处并没有直接删除 item1 节点，只是把该节点的 item 通过 CAS 操作置为了 NULL。step4：p != head，此时队列中有了2个 NULL 节点，，再前移1次 head 指针，对其进行 updateHead 操作。关键点： 出队列的判断并非观察 tail 指针的位置，而是依赖于 head 指针后续的节点是否为 NULL 这一条件。 只要对节点的 item 执行 CAS 操作，置为 NULL 成功，则出队列成功。即使 head 指针没有成功移动，也可以由下一个线程继续完成。 队列判空 因为 head/tail 并不是精确地指向队列头部和尾部，所以不能简单地通过比较 head/tail 指针来判断队列是否为空，而是需要从 head 指针开始遍历，找第1个不为 NULL 的节点。如果找到，则队列不为空；如果找不到，则队列为空。 5.5 ConcurrentHashMapHashMap 通常的实现方式是“数组 + 链表”，这种方式被称为“拉链法”。 5.5.1 JDK7 中的实现方式 构造函数分析 第1个参数，initialCapacity 是整个 ConcurrentHashMap 的初始大小。用 initialCapacity 除以 ssize，是每个 Segment 的初始大小。这里也会保证 Segment 里面 HashEntry[] 数组的大小是2的整数次方。 第2个参数，loadFactor 即负载因子，传给了 Segment 内部。当每个 Segment 的元素达到一定阀值，进行 rehash。Segment 的个数不能扩容，但每个 Segment 的内部可以扩容。 第3个参数，concurrenyLevel 是“并发度”，也就是 Segment 数组的大小。这个值一旦在构造函数中设定，之后不能再扩容。为了提升 hash 的计算性能，会保证数组的大小始终是2的整数次方。 put(..) 函数分析 进入 scanAndLockForPut(key, hash, value) 做什么？一是拿不到锁，不立即阻塞，而是先自旋，若自旋到一定次数仍未拿到锁，再调用 lock() 阻塞；二是在自旋的过程中遍历了链表，若发现没有重复的节点，则提前新建一个节点，为后面再插入节省时间。 扩容 函数的参数，也就是将要加入的最新节点。在扩容完成之后，把该节点加入新的 Hash 表。 整个数组的长度是2的整数次方，每次按二倍扩容，而 hash 函数就是对数组长度取模，即 node.hash &amp; sizeMask。因此，如果元素之前处于第i个位置，当再次 hash 时，必然处于第i个或第 i+oldCapacity 个位置。 lastRun 到链表末尾的所有元素，其 hash 值没有改变，所以不需要依次重新拷贝，只需把这部分链表链接到新链表锁对应的位置就可以，也就是 new Table[lastIdx] = lastRun。lastRun 之前的元素则需要依次拷贝 get 实现分析 整个 get 过程是两次 hash 第一次 hash，函数为 (h&gt;&gt;&gt;segmentShift) &amp; segmentMask，计算出所在的 Segment； 第二次 hash，函数为 h &amp; (tab.length - 1)，即h对数组长度取模，找到 Segment 里面对应的 HashEntry 数组下标，然后遍历该位置的链表 整个读过程完全没有加锁，而是使用了 UNSAFE.getObjectVolatile 函数。 5.5.2 JDK8 中的实现方式链表和红黑树之间可以相互转换：初始的时候是链表，当链表中的元素超过某个阀值时，把链表转换成红黑树；反之，当红黑树中的元素个数小于某个阀值，再转换为链表。为什么 JDK8 要做这种改变？在 JDK7 中的分段锁，有三个好处： 减少 Hash 冲突，避免一个槽里有太多元素。 提高读和写的并发度。段与段之间相互独立。 提供扩容的并发度。扩容的时候，不是整个 ConcurrentHashMap 一起扩容，而是每个 Segment 独立扩容。 针对这三个好处，JDK8 相应的处理方式： 使用红黑树，当一个槽里有很多元素时，其查询和更新速度会比链表快很多，Hash 冲突的问题由此得到很好的解决。 加锁的粒度，并非整个 ConcurrentHashMap，而是对每个头节点分别加锁，即并发度，就是 Node 数组长度，初始长度为16，和在 JDK7 中初始 Segment 的个数相同。 并发扩容，在 JDK7 中，一旦 Segment 的个数在初始化的时候确立，不能再更改，并发度被固定。之后只是在每个 Segment 内部扩容，这意味着每个 Segment 独立扩容，互不影响，不存在并发扩容的问题。在 JDK8 中，相当于只有1个 Segment，当一个线程要扩容 Node 数组的时候，其他线程还要读写。5.6 ConcurrentSkipListMap/SetConcurrentSkipListMap 是一个 key 无序的 HashMap，HashMap 则是 key 有序的，实现了 NavigableMap 接口，此接口又继承了 SortedMap 接口。5.6.1 ConcurrentSkipListMap为什么要使用 SkipList 实现 Map？在 Java 的 util 包中，有一个非线程安全的 HashMap，也就是 TreeMap，是 key 有序的，基于红黑树实现。而在 Concurrent 包中，提供的 key 有序的 HashMap，也就是 ConcurrentSkipMap，是基于 SkipList（调查表）来实现的。5.6.2 ConcurrentSkipListSet第六章 线程池与 Future6.1 线程池的实现原理当没有任务的时候，线程是进入睡眠一小段时间？还是进入阻塞？如果进入阻塞，如何让唤醒？ 做法1：不使用阻塞队列，只使用一般的线程安全的队列，也无阻塞—唤醒机制。当队列为空时，线程池中的线程只能睡眠一会，然后醒来去看队列中有没有新任务到来，如此不断轮询。 做法2：不使用阻塞队列，但在队列外部、线程池内部实现了阻塞—唤醒机制。 做法3：使用阻塞队列 做法3最完善，既避免了线程池内部自己实现阻塞—唤醒机制的麻烦，也避免了做法1的睡眠—轮询带来的资源消耗和延迟。 6.2 线程池的类继承体系两个核心类：ThreadPoolExecutor 和 ScheduledThreadPoolExecutor，后者不仅可以执行某个任务，还可以周期性地执行任务。向线程池中提交的每个任务，都必须实现 Runnable 接口，通过最上面的 Executor 接口中的 execute(Runnable command) 向线程池提交任务。在 ExecutorService 中，定义了线程池的关闭接口 shutdown()，还定义了可以返回值的任务，也就是 Callable。 6.3 ThreadPoolExecutor6.3.1 核心数据结构每一个线程是一个 Worker 对象。Worder 是 ThreadPoolExecutor 的内部类。Worder 继承于 AQS，也就是 Worker 本身就是一把锁。 6.3.2 核心配置参数解释 corePoolSize：在线程池始终维护的线程个数。 maxPoolSize：在 corePoolSize 已满、队列也满的情况下，扩充至此值。 keepAliveTime/TimeUnit：maxPoolSize 中的空闲线程，销毁所需要的时间，总线程数收缩回 corePoolSize。 blockingQueue：线程池所用的队列类型。 threadFactory：线程创建工厂，可以自定义，也可以默认。 RejectedExecutionHandler：corePoolSize 已满，队列已满，maxPoolSize 已满，最后的拒绝策略。 6个配置参数的处理流程：Step1：判断当前线程数是否大于或等于 coolPoolSize。如果小于，则新建线程执行；如果大于，则进入 Step2。Step2：判断队列是否已满。如未满，则放入；如已满，则进入 step3。Step3：判断当前线程数是否大于或等于 maxPoolSize。如果小于，则新建线程执行；如果大于，则进入 step4。Step4：根据拒绝策略，拒绝任务总结：首先判断 corePoolSize，其次判断 blockingQueue 是否已满，接着判断 maxPoolSize，最后使用拒绝策略。基于这种流程，如果队列是无界的，将永远没有机会走到 step3，也即 maxPoolSize 没有使用，也一定不会走到 step4。 6.3.3 线程池的优雅关闭 线程池的生命周期 线程池有两个关闭函数，shutdown() 和 shutdownNow()，这两个函数会让线程池切换到不同的状态。在队列为空，线程池也为空之后，进入 TIDYING 状态；最后执行一个钩子函数 terminated()，进入 TERMINATED 状态，线程池才“寿终正寝”。状态前移只会从小的状态值往大的状态值迁移，不会逆向迁移。 正确关闭线程池的步骤 在调用 shutdown() 和 shutdownNow() 之后，线程池并不会立即关闭，接下来需要调用 awaitTermination() 来等待线程池关闭。awaitTermination(..) 不断循环判断线程池是否到达了最终状态 TERMINATED，如果是，就返回；如果不是，则通过 termination 条件变量阻塞一段时间，“苏醒”之后，继续判断。 shutdown() 与 shutdownNow() 的区别 前者不会清空任务队列，会等所有任务执行完成，后者再清空任务队列。 前者只会中断空闲的线程，后者会中断所有线程。6.3.4 任务的提交过程分析6.3.5 任务的执行过程分析场景1：当调用 shutdown() 的时候，所有线程都处于空闲状态。这意味着任务队列一定是空的。此时，所有线程都会阻塞在 getTask() 函数的地方。然后，所有线程都会收到 interruptIdleWorkers() 发来的中断信号，getTask() 返回 null，所有 Worker 都会退出 while 循环，之后执行 processWorkerExit。场景2：当调用 shutdown() 的时候，所有线程都处于忙碌状态。此时，队列可能是空的，可能是非空的。interruptIdleWorkers() 内部的 tryLock 调用失败，什么都不会做，所有线程会继续执行自己当前的任务。之后所有线程会执行完队列中的任务，直到队列为空，getTask() 才会返回 null。之后，和场景1一样，退出 while 循环。场景3：当调用 shutdown() 的时候，部分线程忙碌，部分线程空闲。有部分线程空闲，说明队列一定是空的，这些线程肯定阻塞在 getTask() 函数的地方。空闲的这些线程会和场景1一样处理，不空闲的线程会和场景2一样处理。6.3.6 线程池的4种拒绝策略 让调用者直接在自己的线程里面执行，线程池不做处理。 线程池直接抛出异常。 线程池直接把任务丢掉，当作什么也没有发生。 把队列里面最老的任务删除掉，把该任务放入队列中。 6.4 Callable 与 Future6.5 ScheduledThreadPoolExecutorScheduledThreadPoolExecutor 实现了按时间调度来执行任务，两方面： 延迟执行任务： public ScheduledFuture &lt;?&gt; schedule(Runable command, long delay, TimeUnit unit); public &lt;V&gt;ScheduledFuture &lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); 周期执行任务： public ScheduledFuture &lt;?&gt; scheduleAtFixedRate(Runable command, long initalDelay, TimeUnit unit); public &lt;V&gt;ScheduledFuture &lt;V&gt; schedulWithFixedRate(Runable command, long initalDelay, long delay, TimeUnit unit); 两个函数的区别： AtFixedRate：按固定频率执行，与任务本身执行时间无关。但有个前提条件，任务执行时间必须小于间隔时间。 WithFixedDelay：按固定间隔执行，与任务本身执行时间有关。6.5.1 延迟执行和周期性执行的原理6.5.2 延迟执行传进去的是一个 Runnable，外加延迟时间 delay。6.5.3 周期性执行包装一个 ScheduledFutureTask 对象，只是在延迟时间参差之外多了一个周期参数，然后放入 DelayedWorkerQueue 就结束了。 withFixedRate 和 atFixedRate 的区别体现在 setNextRunTime 里面。 如果是 atFixedRate，period &gt; 0，下一次开始执行时间等于上一次开始执行时间 + period； 如果是 withFixedRate，period &lt; 0，下一次开始执行时间等于 triggerTime(-p)，为 now + (-period)，now 即是上一次执行的结束时间。6.6 Executors 工具类第七章 ForkJoinPool7.1 ForkJoinPool 用法例1：快排第一步：利用数组的第一个元素把数组划分成两半，左边数组里面的元素小于或等于该元素，右边数组里面的元素比该元素大；第二步：对左右的2个子数组分别排序。7.2 核心数据结构7.3 工作窃取队列窃取算法是指一个 Worker 线程在执行完毕自己队列中的任务之后，可以窃取其他线程队列中的任务来执行，从而实现负载均衡，以防有的线程很空闲，有的线程很忙。这个过程要用到工作窃取队列。这个队列只有三个操作： Worker 线程自己，在队列头部，通过对 queueTop 指针执行加、减操作，实现入队或出队，这是单线程的； 其他 Worker 线程，在队列尾部，通过对 queueBase 进行累加，实现出队操作，也就是窃取，这是多线程的，需要通过 CAS 操作。 关键点： 整个队列是环形的，也就是一个数组实现的 RingBuffer。并且 queueBase 会一直累加，不会减少；queueTop 会累加、减小。最后，queueBase、queueTop 的值都会大于整个数组的长度，只是计算数组的下标的时候，会取 queueTop &amp; (queue.length-1)，queueBase &amp; (queue.length-1)。因为 queue.length 是2的整数次方，这里也就是对 queue.length 是2的整数次方，这里也是对 queue.length 进行取模操作。 当 queueTop - queueBase = queue.length-1 的时候，队列为满，此时需要扩容； 当 queueTop = queueBase 的时候，队列为空，Worker 线程即将进入阻塞状态 当队列满了之后会扩容，所以被称为是动态的。 7.4 ForkJoinPool 状态控制7.4.1 状态变量 ctl 解析ctl 变量的64比特位被分为五部分：AC：最高的16个比特位，表示 Active 线程数 -parallelism，parallelism 是上面的构造函数传进去的参数；TC：次高的16个比特位，表示 Total 线程数 -parallelism；ST：1个比特位，如果是1，表示整个 ForkJoinPool 正在关闭；EC：15个比特位，表示阻塞栈的栈顶线程的 wait count；ID：16个比特位，表示阻塞栈的栈顶线程对应的 poolIndex。 7.4.2 阻塞栈 Treiber Stack要实现多个线程的阻塞、唤醒，除了 park/unpark 这一对操作原语，还需要一个无锁链表实现的阻塞队列，把所有阻塞的线程串在一起。在 ForkJoinPool 中，没有使用阻塞队列，而是使用了阻塞栈。把所有空闲的 Worker 线程放在一个栈里面，这个栈同样通过链来实现，名为 Treiber Stack。首先，ForkJoinWorkerThread 有一个 poolIndex 变量，记录了自己在 ForkJoinWorkerThread[] 数组中的下标位置，poolIndex 变量就相当于每个 ForkJoinPoolWorkerThread 对象的地址；其次 ForkJoinWorkerThread 还有一个 nextWait 变量，记录了前一个阻塞线程的 poolIndex，这个 nextWait 变量就相当于链表的 next 指针，把所有的阻塞线程串联在一起，组成一个Treiber Stack。最后，ctl 变量的最低16位，记录了栈的栈顶线程的 poolIndex；中间的15位，记录了栈顶的线程被阻塞的次数，也称为 wait count。 7.4.3 ctl 变量的初始值因为在初始的时候，ForkJoinPool 中的线程个数为0，所以 AC = 0 - parallelism，TC = 0 - parallelism。这意味着只有高32位的AC、TC 两个部分填充了值，低32位都是0填充。 7.4.4 ForkJoinWorkerThread 状态与个数分析ForkJoinPool 中的线程可能的状态有三种： 空闲状态（放在Treiber Stack里面） 活跃状态（正在执行某个 ForkJoinTask，未阻塞） 阻塞状态（正在执行某个 ForkJoinTask，但阻塞了，于是调用 join，等待另外一个任务的结果返回） ctl更好地反映出了三种状态：高32位：u = (int)(ctl&gt;&gt;&gt;32)，然后 u 又拆分成 tc、ac 两个16位；低32位：e = (int)ctl e&gt;0，说明 Treiber Stack 不为空，有空闲线程；e = 0，说明没有空闲线程； ac&gt;0，说明有活跃线程；ac &lt;= 0，说明没有空闲线程，并且还未超出 parallelism； tc&gt;0，说明总线程数 &gt; parallelism。 tc 与 ac 的差值，也就是总线程数与活跃线程数的差异，在 ForkJoinPool 中有另外一个变量 blockedCount 记录。所以，通过 crl 和 blockedCount 这两个变量，可以知道在整个 ForkJoinPool 中所有空闲线程、活跃线程以及阻塞线程的数量。 7.5 Worker 线程的阻塞-唤醒7.5.1 阻塞-入栈函数的第一个参数就是要阻塞的线程，第二个参数是当前的 ctl 变量的值。入栈，也就是3步：第一步：w.nextWait = (int)c，即使 w.nextWait 指针，指向栈顶；第二步：long nc = (long)(v &amp; E_MASK) | (c - AC_UNIT) &amp; (AC_MASK|TC_MASK))，即新的栈顶就是当前的线程w，同时把 ac 的值减1，即活跃线程数减1；第三步：将 nc 通过 CAS 赋值给 ctl 变量 UNSAFE。compareAndSwapLong(this, ctlOffset, c, nc)。此时入栈成功，ctl 变量更新成功。最后，调用 LockSupport.park(this) 阻塞自己。但是在这期间做了很多其他事情： 统计 stealCount。 判断 ForkJoinPool 是否关闭，以及是否所有线程都处于空闲状态，整个 ForkJoinPool 是否处于静默状态 在阻塞之前，为了保险，又重新扫描了一遍队列，观察是否有任务可以执行。 7.5.2 唤醒-出栈当 signalWorker 函数的参数为空，它会唤醒栈顶的线程，如：e &gt; 0，说明栈不为空，此时 e 的最低16位，存储的是栈顶线程的poolIndex，取出来唤醒；e = 0，说明栈为空，此时开一个新线程。 7.6 任务的提交过程分析如何区分一个任务是内部任务还是外部任务？可以通过调用该函数的线程类型判断。如果线程类型是 ForkJoinWorkerThread，说明是线程池内部的某个线程在调用该函数，则把该任务放入该线程的局部队列；否则，是外部线程在调用该函数，则将该任务加入全局队列。 7.6.1 内部提交任务 pushTask由于工作窃取队列的特性，其对 queueTop 的操作是单线程的，所以此处不需要执行 CAS 操作。当 queueTop - queueBase = 0 的时候，队列为空，此处为了保险，写作 queueTop - queueBase &lt;= 2，不影响正确性。 7.6.2 外部提交任务 addSubmission外部多个线程会调用该函数，所以要加锁，入队列和扩容的逻辑和线程内部的队列基本相同，最后，调用 signalWork()，通知一个空闲线程来取。 7.7 工作窃取算法：任务的执行过程分析7.7.1 顺序锁 SeqLock 读线程在读取共享数据之前先读取 sequence number，在读取数据之后仔读一次 sequence number，如果两次的值不同，说明在此期间有其他线程修改了数据，此次读取数据无效重新读取； 写线程，在写入数据之前，累加一次 sequence number，在写入数据之后，再累加一次 sequence number。 最初，sequence number = 0，读线程不会修改 sequence number，而一个写线程会累加两次 sequence number，所以 sequence number 始终是偶数。如果 sequence number 是奇数，说明当前某个写线程正在修改数据，其他写线程被互斥。对于写线程而言，发现 sequence number 是奇数，就不能修改共享数据了。对于读线程而言，发现 sequence number 是奇数，也不能再读取数据；如果发现 sequence number 是偶数，那么在读取数据前后分别读取一次 sequence number，如果两次的值相同，则读取成功，否则重新读取。 7.7.2 scanGuard 解析scanGuard 变量充当了顺序锁的 sequence number 的功能，共享数据就是 Worker 线程数组 ws。所以，在scan 函数中，在函数开始的时候，读取了一次 scanGuard，扫描完 ws 对应的队列，又读取了一次 scanGuard，发现两次的值不同。说明在这期间 ws 的数组发生了变化，可能是新加了线程，ws 数组扩容了，于是返回false，重新进入 scan 函数。 7.8 ForkJoinTask 的 fork/join7.8.1 fork7.8.2 join 的层层嵌套7.9 ForkJoinPool 的优雅关闭7.9.1 关键的 terminate 变量7.9.2 shutdown() 与 shutdownNow() 的区别shutdown() 只拒绝新提交的任务； shutdownNow() 会取消现有的全局队列和局部队列中的任务，同时唤醒所有空闲的线程，让这些线程自动退出。 第八章 CompletableFuture8.1 CompletableFuture 用法8.1.1 最简单的用法CompletableFuture 实现了 Future 接口，所以它也具有 Future 的特性：调用 get() 方法会阻塞在那，知道结果返回。 8.1.2 提交任务：runAsync 与 supplyAsyncCompletableFuture 和 Future 很相似，都可以提交两类任务：一类是无返回值的，另一类是有返回值的。 8.1.3 链式的 CompletableFuture：thenRun、thenAccept 和 thenApply对于 Future，在提交任务之后，只能调用 get() 等结果返回；但对于CompletableFuture，可以在结果上面加一个 callback，当得到结果之后，再接着执行 callback。最后紧急执行 callback 的区别： thenRun 后面跟的是一个无参数、无返回值的方法，即 Runnable，所以最终的返回值是 CompletableFuture 类型。 thenAccept 后main跟的是一个有参数、无返回值的方法，称为 Consumer，返回值也是CompletableFuture 类型。顾名思义，只进不出，所以称为 Consumer；前面的 Supplier，是无参数，有返回值，只出不进，和 Consumer 刚好相反。 thenApply 后面跟的是一个有参数、有返回值的方法，称为 Function。返回值是 CompletableFuture 类型。 8.1.4 CompletableFuture 的组合：thenCompose 与 thenCombine8.1.5 任意个 CompletableFuture 的组合thenCompose 与 thenCombine 只能组合2个 CompletableFuture，而 allof 和anyof 可以组合任意多个 CompletableFuture。这个两个函数都是静态函数，参数是变长的 CompletableFuture 的集合，allof 是与，anyof 是或 8.2 四种任务原型runAsync 与 supplierAsync 是 CompletableFuture 的静态方法；而 thenAccept、runAsync、thenApply 是 CompletableFuture 的成员方法。因为初始的时候没有 CompletableFuture 对象，也没有参数可传，所以提交的只能是 Runnable 或者 Supplier，只能是静态方法；通过静态方法生成 CompletableFuture 对象之后，便可以链式地提交其他任务了，这个时候就可以提交 Runnable、Consumer、Function，且都是成员方法。 8.3 CompletionFuture 接口8.4 CompletableFuture 内部原理8.4.1 CompletableFuture 的构造：ForkJoinPoolasyncPool 是一个 static类型，supplierAsync、asyncSupplyStage 都是 static 函数。Static 函数返回一个 CompletableFuture 类型对象，之后可以链式调用，CompletionStage 里面的各个方法。 8.4.2 任务类型的适配8.4.3 任务的链式执行过程分析AsyncSupply 三个关键点： 继承自 ForkJoinTask，所以能够提交ForkJoinPool 来执行 封装了 Supplier f，即它所执行任务的具体内容 该任务的返回值，即 CompletableFuture d，也被封装在里面。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://quricolouis.github.io/tags/Java/"},{"name":"JDK源码","slug":"JDK源码","permalink":"http://quricolouis.github.io/tags/JDK%E6%BA%90%E7%A0%81/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"author":"QuricoLouis"},{"title":"树的遍历(评测机)","slug":"树的遍历（评测机）","date":"2021-07-15T07:41:45.000Z","updated":"2021-09-11T15:24:40.959Z","comments":true,"path":"posts/b3608e84.html","link":"","permalink":"http://quricolouis.github.io/posts/b3608e84.html","excerpt":"","text":"public class Tree { class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int val) { this.val = val; } TreeNode(int val, TreeNode left, TreeNode right) { this.val = val; this.left = left; this.right = right; } } public static void main(String[] args) { Integer[] data = {5, 4, 8, 11, null, 13, 4, 7, 2, null, null, null, 1}; Tree tree = new Tree(); TreeNode root = tree.createTree(data, 0); System.out.println(tree.preorderTraversal(root)); System.out.println(tree.inorderTraversal(root)); System.out.println(tree.postorderTraversal(root)); System.out.println(tree.levelOrder(root)); } /** * 创建树 * * @param arr * @param index * @return */ private TreeNode createTree(Integer[] arr, int index) { TreeNode treeNode = null; if (index &lt; arr.length) { Integer value = arr[index]; if (value == null) { return null; } treeNode = new TreeNode(value); treeNode.left = createTree(arr, 2 * index + 1); treeNode.right = createTree(arr, 2 * index + 2); return treeNode; } return treeNode; } /** * 前序遍历 * * @param root * @return */ public List&lt;Integer&gt; preorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); preorder(root, res); return res; } public void preorder(TreeNode root, List&lt;Integer&gt; res) { if (root == null) { return; } res.add(root.val); preorder(root.left, res); preorder(root.right, res); } /** * 中序遍历 * * @param root * @return */ public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); inorder(root, res); return res; } public void inorder(TreeNode root, List&lt;Integer&gt; res) { if (root == null) { return; } inorder(root.left, res); res.add(root.val); inorder(root.right, res); } /** * 后序遍历 * * @param root * @return */ public List&lt;Integer&gt; postorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); postorder(root, res); return res; } public void postorder(TreeNode root, List&lt;Integer&gt; res) { if (root == null) return; postorder(root.left, res); postorder(root.right, res); res.add(root.val); } /** * 层序遍历 * * @param root * @return */ public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; queue = new ArrayDeque&lt;&gt;(); if (root != null) { queue.add(root); } while (!queue.isEmpty()) { int n = queue.size(); List&lt;Integer&gt; level = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) { TreeNode node = queue.poll(); level.add(node.val); if (node.left != null) { queue.add(node.left); } if (node.right != null) { queue.add(node.right); } } res.add(level); } return res; }","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"http://quricolouis.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"http://quricolouis.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"树","slug":"树","permalink":"http://quricolouis.github.io/tags/%E6%A0%91/"}],"author":"QuricoLouis"},{"title":"链表(评测机)","slug":"链表（评测机）","date":"2021-07-11T07:41:45.000Z","updated":"2021-09-11T15:24:40.954Z","comments":true,"path":"posts/523c3831.html","link":"","permalink":"http://quricolouis.github.io/posts/523c3831.html","excerpt":"","text":"public class LinkedList { class ListNode { int val; ListNode next; ListNode() { } ListNode(int val) { this.val = val; } } public ListNode head; public ListNode tail; public static void main(String[] args) { int[] nums = new int[]{4,6,7,8,3,6,9}; LinkedList list = new LinkedList(); for (int num :nums) list.add(num); list.print(list.head); } /** * 链表添加数据 * @param date */ public void add(int date) { if (head == null) { head = new ListNode(date); tail = head; } else { tail.next = new ListNode(date); tail = tail.next; } } /** * 打印链表 * @param node */ public void print(ListNode node){ if(node == null) return; tail = node; while(tail != null){ System.out.print(tail.val + \" \"); tail = tail.next; } } }","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"http://quricolouis.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"http://quricolouis.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"链表","slug":"链表","permalink":"http://quricolouis.github.io/tags/%E9%93%BE%E8%A1%A8/"}],"author":"QuricoLouis"},{"title":"Git笔记","slug":"git","date":"2021-07-01T07:41:45.000Z","updated":"2021-09-11T15:21:23.144Z","comments":true,"path":"posts/5bd9b965.html","link":"","permalink":"http://quricolouis.github.io/posts/5bd9b965.html","excerpt":"","text":"版本控制工具集中式版本控制工具CVS、SVN(Subversion)、VSS 优点：每个人都可以在一定程度上看到项目中的其他人正在做些什 么。而管理员也可以轻松掌控每个开发者的权限，并且管理一个集中化的版本控制系统，要 远 比在各个客户端上维护本地数据库来得轻松容易。 缺点：是中央服务器的单点故障。如果服务器宕 机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作 分布式版本控制工具Git、Mercurial、Bazaar、Darcs 优点：客户端提取的不是最新版本的文件快照，而是把代码 仓库完整地镜像下来（本地库）。这样任何一处协同工作用的文件发生故障，事后都可以用 其他客户 端的本地仓库进行恢复。因为每个客户端的每一次文件提取操作，实际上都是一次 对整个文件仓库的完整备份。 1. 服务器断网的情况下也可以进行开发（因为版本控制是在本地进行的） 2. 每个客户端保存的也都是整个完整的项目（包含历史记录，更加安全） Git工作机制 Git常用命令 Git分支操作 分支好处​ 同时并行推进多个功能开发，提高开发效率。 ​ 各个分支在开发过程中，如果某一个分支开发失败，不会对其他分支有任何影响。失败 的分支删除重新开始即可。 常用命令 远程操作常用命令","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"Git","slug":"Git","permalink":"http://quricolouis.github.io/tags/Git/"}],"author":"QuricoLouis"}],"categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"http://quricolouis.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Big Data","slug":"Big-Data","permalink":"http://quricolouis.github.io/tags/Big-Data/"},{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"java","slug":"java","permalink":"http://quricolouis.github.io/tags/java/"},{"name":"Java","slug":"Java","permalink":"http://quricolouis.github.io/tags/Java/"},{"name":"分布式","slug":"分布式","permalink":"http://quricolouis.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"JDK源码","slug":"JDK源码","permalink":"http://quricolouis.github.io/tags/JDK%E6%BA%90%E7%A0%81/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"数据结构","slug":"数据结构","permalink":"http://quricolouis.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"树","slug":"树","permalink":"http://quricolouis.github.io/tags/%E6%A0%91/"},{"name":"链表","slug":"链表","permalink":"http://quricolouis.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"Git","slug":"Git","permalink":"http://quricolouis.github.io/tags/Git/"}]}