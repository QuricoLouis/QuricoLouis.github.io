{"meta":{"title":"QuricoLouis","subtitle":"QuricoLouisの博客","description":"本科 | 软件工程 | java后端开发","author":"QuricoLouis","url":"http://QuricoLouis.github.io","root":"/"},"pages":[{"title":"404","date":"2019-08-10T08:41:10.000Z","updated":"2021-07-29T15:54:31.389Z","comments":true,"path":"404.html","permalink":"http://quricolouis.github.io/404.html","excerpt":"","text":""},{"title":"","date":"2021-08-01T12:24:03.576Z","updated":"2021-08-01T12:23:25.599Z","comments":true,"path":"baidu_verify_code-THscGEvLSO.html","permalink":"http://quricolouis.github.io/baidu_verify_code-THscGEvLSO.html","excerpt":"","text":"4b3181e196b183a3def76e34226db00f"},{"title":"放松一下","date":"2019-08-10T08:41:10.000Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/index.html","permalink":"http://quricolouis.github.io/List/index.html","excerpt":"","text":"影音资源共享"},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2021-07-29T15:54:31.432Z","comments":true,"path":"archives/index.html","permalink":"http://quricolouis.github.io/archives/index.html","excerpt":"","text":""},{"title":"about","date":"2019-10-24T16:00:00.000Z","updated":"2021-07-29T15:54:31.432Z","comments":true,"path":"about/index.html","permalink":"http://quricolouis.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-10-24T16:00:00.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"categories/index.html","permalink":"http://quricolouis.github.io/categories/index.html","excerpt":"","text":""},{"title":"统计","date":"2020-10-31T02:11:28.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"census/index.html","permalink":"http://quricolouis.github.io/census/index.html","excerpt":"","text":""},{"title":"留言板","date":"2019-10-24T16:00:00.000Z","updated":"2021-08-01T07:44:50.374Z","comments":true,"path":"contact/index.html","permalink":"http://quricolouis.github.io/contact/index.html","excerpt":"","text":"畅所欲言 在这里可以留下你的足迹，欢迎在下方留言，欢迎交换友链，一起交流学习！ 友链 QuricoLouisの友链信息 博客名称: QuricoLouisの博客 博客网址: http://QuricoLouis.github.io 博客头像: https://cdn.jsdelivr.net/gh/QuricoLouis/imgBed/blog/20210731104423.png 博客介绍: The harder you work, the luckier you will be"},{"title":"资源分享","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"resource/index.html","permalink":"http://quricolouis.github.io/resource/index.html","excerpt":"","text":""},{"title":"友链","date":"2019-07-19T08:42:10.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"friends/index.html","permalink":"http://quricolouis.github.io/friends/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.433Z","comments":true,"path":"tags/index.html","permalink":"http://quricolouis.github.io/tags/index.html","excerpt":"","text":""},{"title":"相册","date":"2021-07-29T15:54:31.392Z","updated":"2021-07-29T15:54:31.392Z","comments":true,"path":"List/galleries/index.html","permalink":"http://quricolouis.github.io/List/galleries/index.html","excerpt":"","text":""},{"title":"视频","date":"2019-08-10T08:41:10.000Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/movies/index.html","permalink":"http://quricolouis.github.io/List/movies/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/music/index.html","permalink":"http://quricolouis.github.io/List/music/index.html","excerpt":"","text":""},{"title":"听听音乐","date":"2019-07-19T08:40:27.000Z","updated":"2021-07-29T15:54:31.395Z","comments":true,"path":"List/tools/index.html","permalink":"http://quricolouis.github.io/List/tools/index.html","excerpt":"","text":""},{"title":"乖巧小狗","date":"2021-07-29T15:54:31.392Z","updated":"2021-07-29T15:54:31.392Z","comments":true,"path":"List/galleries/乖巧小狗/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E4%B9%96%E5%B7%A7%E5%B0%8F%E7%8B%97/index.html","excerpt":"","text":""},{"title":"二次元风","date":"2021-07-29T15:54:31.392Z","updated":"2021-07-29T15:54:31.392Z","comments":true,"path":"List/galleries/二次元风/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E4%BA%8C%E6%AC%A1%E5%85%83%E9%A3%8E/index.html","excerpt":"","text":""},{"title":"动漫人物","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/动漫人物/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E4%BA%BA%E7%89%A9/index.html","excerpt":"","text":""},{"title":"动漫风景","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/动漫风景/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"呆萌猫咪","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/呆萌猫咪/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%91%86%E8%90%8C%E7%8C%AB%E5%92%AA/index.html","excerpt":"","text":""},{"title":"城市风光","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/城市风光/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%9F%8E%E5%B8%82%E9%A3%8E%E5%85%89/index.html","excerpt":"","text":""},{"title":"清新花卉","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/清新花卉/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E6%B8%85%E6%96%B0%E8%8A%B1%E5%8D%89/index.html","excerpt":"","text":""},{"title":"动漫插画","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/动漫插画/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E5%8A%A8%E6%BC%AB%E6%8F%92%E7%94%BB/index.html","excerpt":"","text":""},{"title":"炫酷跑车","date":"2021-07-29T15:54:31.393Z","updated":"2021-07-29T15:54:31.393Z","comments":true,"path":"List/galleries/炫酷跑车/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E7%82%AB%E9%85%B7%E8%B7%91%E8%BD%A6/index.html","excerpt":"","text":""},{"title":"甜美食品","date":"2021-07-29T15:54:31.394Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/galleries/甜美食品/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E7%94%9C%E7%BE%8E%E9%A3%9F%E5%93%81/index.html","excerpt":"","text":""},{"title":"自然风景","date":"2021-07-29T15:54:31.394Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/galleries/自然风景/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E8%87%AA%E7%84%B6%E9%A3%8E%E6%99%AF/index.html","excerpt":"","text":""},{"title":"璀璨星空","date":"2021-07-29T15:54:31.394Z","updated":"2021-07-29T15:54:31.394Z","comments":true,"path":"List/galleries/璀璨星空/index.html","permalink":"http://quricolouis.github.io/List/galleries/%E7%92%80%E7%92%A8%E6%98%9F%E7%A9%BA/index.html","excerpt":"","text":""}],"posts":[{"title":"负载均衡原理及算法","slug":"负载均衡原理及算法","date":"2021-09-09T06:39:23.103Z","updated":"2021-09-09T06:39:39.185Z","comments":true,"path":"posts/59472fd8.html","link":"","permalink":"http://quricolouis.github.io/posts/59472fd8.html","excerpt":"","text":"@TOC 背景面对大量用户访问、高并发请求，单机网站可以从软硬件两个方面寻求解决方法： 硬件方面：可以使用高性能的服务器、大型数据库，存储设备，高性能Web服务器； 软件方面：采用高效率的编程语言(比如Go，Erlang，Scala)等。 但是，当单机容量达到极限时，我们需要考虑业务拆分和分布式部署，来解决大型网站访问量大，并发量高，海量数据的问题。即需要从架构方面寻求解决方案。 概述 负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。 负载均衡（Load Balance），意思是将负载（如前端的访问请求）进行平衡、（通过负载均衡算法）分摊到多个操作单元（服务器，中间件）上进行执行。是解决高性能，单点故障（高可用），扩展性（水平伸缩）的终极解决方案。可以理解为，负载均衡是高可用和高并发共同使用的一种技术。 负载均衡的作用： 1、增加吞吐量，解决并发压力（高性能）； 2、提供故障转移（高可用）； 3、通过添加或减少服务器数量，提供网站伸缩性（扩展性）； 4、安全防护（负载均衡设备上做一些过滤，黑白名单等处理）。 原理系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。 纵向扩展，是从单机的角度通过增加硬件处理能力，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。 典型负载均衡架构如下： 分类按照软硬件分类硬件负载均衡采用硬件的方式实现负载均衡，一般是单独的负载均衡服务器，价格昂贵，常用的有：F5、A10、Citrix Netscaler。 优点： 硬件负载均衡稳定性更强，双机或集群的效果更佳，可以应对高并发、高吞吐的网络环境中。 在策略配置方面，可以实现深度的健康检查方法，而不是简单的ping或tcp的方式，而是可以针对业务层进行健康检查，整体的策略调度更灵活、配置更方便，在七层负载方面更具优势。 缺点： 价格昂贵； 扩展能力差，无法进行扩展和定制； 调试和维护比较麻烦，需要专业人员。 选择： 核心系统必须使用硬件负载均衡设备； 测试系统和一般系统可以使用软件负载均衡设备。软件负载均衡硬件负载均衡价格昂贵，在实际应用中远不如软件负载均衡普遍。常用的软件负载均衡软件有Nginx、LVS、HaProxy、ats、perlbal、pound等。 Nginx/LVS/HAProxy是目前使用最广泛的三种负载均衡软件。对比： LVS：是基于四层的转发（只能做端口转发，不能做基于URL、目录的转发） HAproxy：是基于四层和七层的转发，是专业的代理服务器 Nginx：是WEB服务器，缓存服务器，又是反向代理服务器，可以做七层的转发 选择： HAproxy和Nginx可做七层转发，URL和目录转发都可以； 中小型企业推荐使用HAproxy（配置简单）； 在很大并发量的时候选择LVS。 按照地理结构分类本地负载均衡本地负载均衡针对本地范围的服务器群做负载均衡 全局负载均衡全局负载均衡针对不同地理位置、不同网络结构的服务器群做负载均衡 全局负载均衡具备的特点： 提高服务器响应速度，解决网络拥塞问题，达到高质量的网络访问效果。 能够远距离为用户提供完全的透明服务,真正实现与地理位置无关性 能够避免各种单点失效，既包括数据中心、服务器等的单点失效，也包括专线故障引起的单点失效。按照实现技术DNS负载均衡 最早的负载均衡技术，利用域名解析实现负载均衡，在DNS服务器，配置多个A记录，这些A记录对应的服务器构成集群。大型网站总是部分使用DNS解析，作为第一级负载均衡。 优点： 使用简单：负载均衡工作交给DNS服务器处理，不需要专门的服务器维护； 提高性能：可以支持基于地址的域名解析，解析成距离用户最近的服务器地址，可以加快访问速度。 缺点： 可用性差：新增/修改DNS后，解析时间较长； 扩展性低：DNS负载均衡的控制权在域名商，扩展性有限。 实践建议：将DNS作为第一级负载均衡。 IP负载均衡IP负载均衡，在网络层通过修改请求目标地址进行负载均衡。优点： 在内核进程完成数据分发，比在应用层分发性能更好。 缺点： 所有请求响应都需要经过负载均衡服务器，集群最大吞吐量受限于负载均衡服务器网卡带宽。 链路层负载均衡在通信协议的数据链路层修改mac地址，进行负载均衡。 数据分发时，不修改ip地址，指修改目标mac地址，配置真实物理服务器集群所有机器虚拟ip和负载均衡服务器ip地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。 优点：性能好。 缺点：配置复杂。 实践建议：直接路由（DR）模式最常用。 混合型负载均衡由于多个服务器群内硬件设备、规模、提供服务等差异，可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务，从而达到最佳的性能，将这种方式称之为混合型负载均衡。 按照OSI层次二层负载均衡（数据链路层）负载均衡服务器对外依然提供一个 VIP（浮动IP），集群中不同的机器采用相同IP地址，但机器的MAC地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标MAC地址的方式将请求转发到目标机器实现负载均衡。 三层负载均衡（网络层）负载均衡服务器对外依然提供一个VIP，但集群中不同的机器采用不同的IP地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过IP将请求转发至不同的真实服务器。 四层负载均衡（传输层）四层负载均衡服务器在接受到客户端请求后，通过修改数据包的地址信息（IP+端口号）将流量转发到应用服务器。 七层负载均衡（应用层）七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用HTTP、DNS 等。七层负载就可以基于这些协议来负载。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。 部署方式路由模式路由模式的部署方式，服务器的网关必须设置成负载均衡机的LAN口地址，且与WAN口分署不同的逻辑网络。因此所有返回的流量也都经过负载均衡。这种方式对网络的改动小，能均衡任何下行流量。 桥接模式桥接模式配置简单，不改变现有网络。负载均衡的WAN口和LAN口分别连接上行设备和下行服务器。LAN口不需要配置IP（WAN口与LAN口是桥连接），所有的服务器与负载均衡均在同一逻辑网络中。由于这种安装方式容错性差，网络架构缺乏弹性，对广播风暴及其他生成树协议循环相关联的错误敏感，因此一般不推荐这种安装架构。 服务直接返回模式这种安装方式负载均衡的LAN口不使用，WAN口与服务器在同一个网络中，互联网的客户端访问负载均衡的虚IP（VIP），虚IP对应负载均衡机的WAN口，负载均衡根据策略将流量分发到服务器上，服务器直接响应客户端的请求。因此对于客户端而言，响应他的IP不是负载均衡机的虚IP（VIP），而是服务器自身的IP地址。也就是说返回的流量是不经过负载均衡的。因此这种方式适用大流量高带宽要求的服务。 常用算法轮询轮询为负载均衡中较为基础也较为简单的算法，它不需要配置额外参数。假设配置文件中共有 M 台服务器，该算法遍历服务器节点列表，并按节点次序每轮选择一台服务器处理请求。当所有节点均被调用过一次后，该算法将从第一个节点开始重新一轮遍历。 特点：由于该算法中每个请求按时间顺序逐一分配到不同的服务器处理，因此适用于服务器性能相近的集群情况，其中每个服务器承载相同的负载。但对于服务器性能不同的集群而言，该算法容易引发资源分配不合理等问题。 优点：服务器请求数目相同；实现简单、高效；易水平扩展。 缺点：服务器压力不一样，不适合服务器配置不同的情况；请求到目的结点的不确定，造成其无法适用于有写操作的场景。 应用场景：数据库或应用服务层中只有读的场景。 加权轮询为了避免普通轮询带来的弊端，加权轮询应运而生。在加权轮询中，每个服务器会有各自的 weight。一般情况下，weight 的值越大意味着该服务器的性能越好，可以承载更多的请求。该算法中，客户端的请求按权值比例分配，当一个请求到达时，优先为其分配权值最大的服务器。 特点：加权轮询可以应用于服务器性能不等的集群中，使资源分配更加合理化。 其核心思想是，遍历各服务器节点，并计算节点权值，计算规则为 current_weight 与其对应的 effective_weight 之和，每轮遍历中选出权值最大的节点作为最优服务器节点。其中 effective_weight 会在算法的执行过程中随资源情况和响应情况而改变。 IP哈希ip_hash 依据发出请求的客户端 IP 的 hash 值来分配服务器，该算法可以保证同 IP 发出的请求映射到同一服务器，或者具有相同 hash 值的不同 IP 映射到同一服务器。 特点：该算法在一定程度上解决了集群部署环境下 Session 不共享的问题。 比率（Ratio）给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。 优先权（Priority）给所有服务器分组，给每个组定义优先权。当最高优先级中所有服务器出现故障，将请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。 最少连接将请求分配到连接数最少的服务器（目前处理请求最少的服务器）。 优点：根据服务器当前的请求处理情况，动态分配； 缺点：算法实现相对复杂，需要监控服务器请求连接数； 最快模式（Fastest）传递连接给那些响应最快的服务器。 观察模式（Observed）连接数目和响应时间这两项的最佳平衡为依据为新的请求选择服务器。 预测模式（Predictive）利用收集到的服务器当前的性能指标，进行预测分析，选择一台服务器在下一个时间片内，其性能将达到最佳的服务器相应用户的请求。 动态性能分配(Dynamic Ratio-APM)根据收集到的应用程序和应用服务器的各项性能参数，动态调整流量分配。 动态服务器补充(Dynamic Server Act)当主服务器群中因故障导致数量减少时，动态地将备份服务器补充至主服务器群。 服务质量(QoS）按不同的优先级对数据流进行分配。 服务类型(ToS)按不同的服务类型（在 Type of Field 中标识）负载均衡对数据流进行分配。 规则模式针对不同的数据流设置导向规则，用户可自行设置。 网络分层负载均衡架构互联网领域对于负载均衡的架构是随着网站规模提升不断演进的，大致分为如下几个阶段： 第一阶段：利用Nginx或HAProxy进行单点的负载均衡，该阶段服务器刚从单机向集群转变，需要在七层做转发。 第二阶段：随着网络规模扩大，Nginx单点瓶颈突出，这时使用LVS或者商用Array就是首要选择，Nginx此时就作为LVS或者Array的节点来使用，具体LVS或Array的是选择是根据公司规模和预算来选择。 第三阶段：这时网络服务已经成为主流产品，此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升，这时无论从开发适合自身产品的定制，以及降低成本来讲开源的LVS，已经成为首选，这时LVS会成为主流。 常见互联网分布式架构可分为用户层、反向代理层、Web站点层、业务服务层、数据存储层。互联网分层架构：每层之间交互都有相应的负载均衡方案： 客户端层-&gt;反向代理层：DNS轮询。 反向代理层-&gt;Web站点层：Ngnix（均衡策略：请求轮询/最少连接路由/IP哈希）。 Web站点层-&gt;业务服务层：连接池。 业务服务层-&gt;数据存储层：数据分片，读写分离。 拓：四层负载均衡和七层负载均衡的区别1. 从技术实现原理上 所谓四层负载均衡就是使用IP加端口的方式进行路由转发；七层负载均衡一般是基于请求URL地址的方式进行代理转发。同理，还有基于MAC地址信息(虚拟MAC地址到真实MAC地址)进行转发的二层负载均衡和基于IP地址(虚拟IP到真实IP)的三层负载均衡。 四层负载均衡具体实现方式为：通过报文中的IP地址和端口，再加上负载均衡设备所采用的负载均衡算法，最终确定选择后端哪台下游服务器。以TCP为例，客户端向负载均衡发送SYN请求建立第一次连接，通过配置的负载均衡算法选择一台后端服务器，并且将报文中的IP地址信息修改为后台服务器的IP地址信息，因此TCP三次握手连接是与后端服务器直接建立起来的。 七层服务均衡在应用层选择服务器，只能先与负载均衡设备进行TCP连接，然后负载均衡设备再与后端服务器建立另外一条TCP连接通道。因此，七层设备在网络性能损耗会更多一些。 2. 从安全视角上 四层负载均衡与服务器直接建立起TCP连接，很容易遭受SYN Flood攻击。SYN Flood是一种广为人知的DDoS（分布式拒绝服务攻击）的方式之一，这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，从而使得被攻击方资源耗尽的攻击方式。从技术实现原理上可以看出，四层负载均衡很容易将垃圾流量转发至后台服务器，而七层设备则可以过滤这些恶意并清洗这些流量，但要求设备本身具备很强的抗DDOS流量的能力。 3. 常见四层和七层负载均衡设备 四层: F5、LVS等七层: nginx、apache等 参考链接百度百科负载均衡常用算法介绍负载均衡算法及方案四层负载均衡和七层负载均衡区别在哪里？","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://quricolouis.github.io/tags/Java/"},{"name":"分布式","slug":"分布式","permalink":"http://quricolouis.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"author":"QuricoLouis"},{"title":"Java并发实现原理「JDK源码剖析」","slug":"Java并发实现原理「JDK源码剖析」","date":"2021-08-27T03:41:03.000Z","updated":"2021-09-06T08:54:32.104Z","comments":true,"path":"posts/cd039684.html","link":"","permalink":"http://quricolouis.github.io/posts/cd039684.html","excerpt":"","text":"第一章 多线程基础1.1 线程关闭1.1.1 stop() 与 destory() 函数问：运行一半的线程能否强制杀死？答：在Java中，stop()、destory()之类的函数官方明确不建议使用，如果强制杀死线程，则线程中所用的资源，例&nbsp; 如文件描述符、网络连接等不能正常关闭。一个线程一旦运行起，就不要去强行打断它，合理的关闭方法是让其运行完（也就是函数执行完毕），干净地&nbsp; 释放掉所有的资源，然后推出。如果是一个不断循环运行的线程，就需要用到线程间的通信机制，让主线程通知其退出。 1.1.2 守护线程当在一个JVM进程里开多个线程时，这些线程被分成两类：守护线程和非守护线程。默认开的是非守护线程。当所有的非守护线程推出后，整个JVM进程就会退出。意思就是守护线程“不算数”，守护线程不影响整个JVM进程的退出。例如：垃圾回收线程就是守护线程，它们在后台默默工作，当开发者的所有前台线程(非守护线程)都退出之后，整个JVM进程就退出了。 1.2 interruptedException() 函数与 interrupt() 函数1.2.1 什么情况下会抛出 interrupted 异常只有声明了会抛出 InterruptedException 的函数才会抛出异常例： public static native void sleep(long millis) throws InterruptedException{...} public final void wait() throws InterruptedException{...} public final void join() throws InterruptedException{...} 1.2.2 轻量级阻塞与重量级阻塞轻量级阻塞：能够被中断的阻塞。对应的线程状态是 WAITING 或者 TIMED_WAITING。重量级阻塞：像 synchronized 这种不能被中断的阻塞。对应的状态 BLOCKED。图1-1 线程的状态迁移过程 1.2.3 t.isInterrupted() 与 Thread.interrupted()t.interrupted() 相当于给线程发送了一个唤醒的信号,果线程此时恰好处于 waiting 或者 timed_waiting 状态， 就会抛出一个InterruptedException，并且线程被唤醒。而如果线程此时并没有被阻塞，则线程什么都不会做。但在后续，线程可以判断自己是否收到过其他线程发来的中断信号，然后做一些对应的处理。前者是静态函数，后者是非静态函数，两者之间的区别在于前者只是读取中断状态，不做修改状态；后者不仅读取中断状态，还会重置中断标志位。 1.3 synchronized 关键字1.3.1 锁的对象是什么synchronized关键字的意思是给某个对象加了把锁 对于非静态成员函数，锁其实是家在 a 对象上面的； 对于静态成员函数，锁是加在 A.class 上面的 一个静态成员函数和一个非静态成员函数，都加了synchronized关键字，分别被两个线程调用，它们是否互斥？答：因为是两把不同的锁，所以不会互斥 1.3.2 锁的本质是什么图 1-2 线程、锁和资源关系图多个线程要访问同一个资源。线程就是一段段运行的代码；资源就是一个变量、一个对象或一个文件等；而锁就是要实现线程对资源的访问控制，保证同一时间只能有一个线程去访问某一个资源。从程序角度，锁就是一个“对象”，这个对象要完成的事情： 这个对象内部得有一个标志位（state变量），记录自己有没有被某个线程占用。最简单的情况是这个 state 有 0、1 两个取值，0 表示没有线程占用这个锁，1 表示有某个线程占用了这个锁 如果这个对象被某个线程占用，它得记录这个线程的 thread ID，知道自己是被哪个线程占用了。 这个对象还得维护一个 thread id list，记录其他所有阻塞的、等待拿这个锁的线程。在当前线程释放锁之后（也就是把state从1改回0），从这个 thread id list 里面取一个线程唤醒。 既然锁是一个对象，要访问的共享资源本身也是一个对象，这两个对象可以合成一个对象。资源和锁合二为一，使得在 Java 里面，synchronized 关键字可以加在任何对象的成员上面。这也就意味着，这个对象既是共享资源，同时也具备“锁”的功能。 1.3.3 synchronized 实现原理在 Java 的对象头里，有一块数据叫 Mark Word。在64位机器上，Mark Word 是8字节（64位）的，这64位中有2个重要字段：锁标志位和**占用锁的 tread ID。 ** 1.4 wait() 与 notify()1.4.1 生产者-消费者模型生产者-消费者模型是一个常见的多线程编程模型。图 1-4 生产者-消费者模型一个内存队列，多个生产者线程我那个内存队列放数据；多个消费者线程从内存队列中取数据要实现这样一个编程模型，需要做下面几件事情： 内存队列本身要加锁，才能实现线程安全。 阻塞。当内存队列满了，生产者放不进去时，会被阻塞；当内存队列是空的时候，消费者无事可做，会被阻塞。 双向管理。消费者被阻塞之后，生产者放入新数据，要 notify() 消费者；反之，生产者被阻塞之后，消费者消费了数据，要 notify() 生产者。 第 1 件事必须要做，第 2 件事和第 3 件事不一定要做。 如何阻塞？ 办法1：线程自己阻塞自己，也就是生产者、消费者线程各自调用 wait() 和 notify()。办法2：用一个阻塞队列，当取不到或者放不进去数据的时候，入队/出队函数本身就是阻塞的。 如何双向通知？ 办法1：wait() 和 notify() 机制。办法2：Condition机制 1.4.2 为什么必须和 synchronized 一起使用开两个线程，线程A调用f1()，线程B调用f2()。两个线程之间要通信，对于同一个对象来说，一个线程调用该对象的 wait()，另一个线程调用该对象的 notify()，该对象本身就需要同步！所以，在调用 wait()、notify() 之前，要先通过 synchronized 关键字同步给对象，也就是给该对象加锁。 1.4.3 为什么 wait() 的时候必须释放锁wait()内部伪代码： wait(){ //释放锁 //阻塞，等待被其他线程notify //重新拿锁 } 1.4.4 wait() 与 notify() 的问题生产者本来只想通知消费者，但它把其他的生产者也通知了；消费者本来只想通知生产者，但它把其他的消费者也通知了。原因是 wait() 和 notify() 作用的对象和 synchronized 作用的对象是同一个，每个对象没有区分标识。精确唤醒我们可以用 Condition 来实现。 1.5 volatile 关键字volatile三重功效 64位写入的原子性 内存可见性 禁止重排序1.5.1 64位写入的原子性（Half Write）多线程场景下，线程 A 调用 set(100)，线程 B 调用 get()，在某些场景下，返回值可能不是 100 。这是因为 JVM 规范没有要求 64 位的 long 或者 double 的写入是原子的。在 32 位的机器上，一个 64 位变量的写入可能被拆分成两个 32 位的写操作来执行。这样一来，读取线程就可能读到一半的值 。解决办法也：在 long 前面加上 volatile 关键字。1.5.2 内存可见性不仅 64 位，32 位或者位数更小的赋值和取值操作，其实也有问题。比如一个线程修改变量值为 true 之后，另一个线程去读，读到的事 false，但是之后能读到 true。也就是最终一致性，不是强一致性。所以，内存可见性， 指的是写完之后立即对其他线程可见，它的反面不是不可见，而是稍后才能看见。解决这个问题很容易，给变量加上 volatile 关键字即可。1.5.3 重排序：DCL问题单例模式的线程安全，常用写法为DCL（Double Checking Locking）public case Sington { private static Sington instance; private static Sington getInstance() { if (instance == null) { // DCL synchronized(Sington.class) { // 为了性能，延迟使用synchronized if (instance == null) instance = new Instance(); // 有问题的代码 } } } return instance; } 上述的 instance = new Instance() 代码有问题：其底册会分为三个操作： 分配一块内存 在内存上初始化成员变量 把 instance 引用指向内存。 操作2和3可能重排序。即先把 instance 指向内存，再初始化成员变量，因为二者先后没有依赖关系。此时，另一个线程可能拿到一个未完全初始化的对象，直接去访问里面的成员变量，就可能出错。这就是典型的“构造函数溢出”问题。解决方法：为 instance 变量加上 volatile 修饰。 1.6 JVM与happen-before1.6.1 为什么会存在“内存可见性”问题图 1-4 加入 Store Buffer 和 Load Buffer 的 CPU 缓存体系L1、L2、L3 和主内存之间是同步的，有缓存一致性协议的保证，但是 Store Buffer、Load Buffer 和 L1之间却是异步的。也就是说，往内存中写入一个变量，这个变量会保存在 Storre Buffer 里面，稍后才会异步地写入 L1 中，同时同步 写入主内存中。图 1-5 操作系统内核视角下的CPU缓存模型多个 CPU，多个 CPU 多核，每个核上面可能还有多个硬件线程，对于操作系统来讲，就相当于一个个逻辑 CPU。每个逻辑CPU都有自己的缓存，这些缓存和主内存之间不是完全同步的。图 1-6 JVM抽象内存模型对应到 Java 里，就是 JVM 抽象内存模型 1.6.2 重排序与内存可见性的问题重排序分类： 编译器重排序：对于没有先后依赖关系的语句，编译器可以重新调整语句的执行顺序 CPU 指令重排序：在指令级别，让没有依赖关系的多条指令并行 CPU 内存重排序：CPU 有自己的缓存，指令的执行顺序和写入主内存的顺序不完全一致 CPU 内存重排序是造成“内存可见性”问题的主因例：假设有两个线程，线程 1 执行 X = 1 命令 和 a = Y 命令，线程 2 执行 Y = 1 命令 和 b = X 命令。最后 a、b 的结果应该是什么？因为 线程 1 和 线程 2 的执行顺序不确定，所以结果可能是 a = 0, b = 1 a = 1, b = 0 a = 1, b = 1 正常就这三种可能性，但实际还可能是 a = 0, b = 0，为什么呢？原因是线程 1先执行 X = 1 后执行 a = Y，但此时 X = 1 还在自己的 Store Buffer 里，但在线程2看来，a = Y 和 X = 1 顺序却是颠倒的。指令没有重排序，写入内存的操作被延迟了，也就是内存被重排序了，这就造成内存可见行问题。 1.6.3&nbsp; as-if-serial 语义对于开发者而言，希望不要有任何的重排序，指令执行顺序和代码顺序严格一致，写内存的顺序也严格和代码顺序一致。对于编译器和CPU，希望尽最大可能进行重排序，提升运行效率。单线程程序的重排序规则：只要操作之间没有依赖性，编译器和 CPU 就可以任意重排序，因为执行结果不会改变。这也就是 as-if-serial 语义。多线程程序的重排序规则：编译器和 CPU 只能保证每个线程的 as-if-serial 语义。线程之间的数据依赖和线程影响，需要编译器和 CPU 的上层来决定。 1.6.4 happen-before 是什么如果 A happen-before B，意味着 A 的执行结果必须对 B 可见，也就是保证跨线程的内存可见性。A happen-before B 不代表A一定在B之前执行。基于 happen-before 这种描述方法，JMM 对开发者做出了一系列承诺： 单线程中的每个操作，happen-before 对应线程中任意后续操作 对 volatile 变量的写入，happen-before 对应后续对这个变量的读取 对 synchronized 的解锁，happen-before 对应后续对这个锁的加锁 对于非 volatile 变量的写入和读取，不在这个承诺之列。通俗来讲，就是JVM对编译器和CPU来说，volatilt 变量不能重排序；非 volatilt 变量可以任意重排序。 1.6.5 happen-before 的传递性volatile、synchronized 都具有 happen-before 语义。 1.6.6 C++中的 volatile 关键字在 Java 中的 volatile 关键字不仅具有内存可见性，还会禁止 volatile 变量写入和非 volatile 变量写入的重排序；C++ 中的 volatile 关键字不会禁止这种重排序。 1.7 内存屏障为了禁止编译器重排序和CPU重排序，在编译器和CPU层面都有对应的指令。编译器的内存屏障，知只是为了告诉编译器不要对指令进行重排序。当变异完成之后，这种内存屏障就消失了。CPU内存屏障是CPU提供的指令，可以由开发者显示调用。 1.7.1 Linux 中的内存屏障通过函数 smp_wmb() 插入了一个 Store Barrier 屏障，从而确保了： 更新指针的操作，不会被重排序到修改数据之前。 更新指针的时候，Store Cache 被刷新，其他CPU可见1.7.2 JDK 中的内存屏障JDK8开始，Java在 Unsafe 类中提供了三个内存屏障函数(不是最基本的内存屏障)：public final class Unsafe{ public native void loadFence(); //loadFence=LoadLoad+LoadStore public native void storeFence(); //storeFence=StoreFence+LoadStore public native void fullFence(); //fullFence=LoadFence+StoreFence+StoreLoad } 在理论层面，可以把基本的CPU内存屏障分为4种： LoadLoad：禁止读和读的重排序 StoreStore：禁止写和写的重排序 LoadStore：禁止读和写的重排序 StoreLoad：禁止写和读的重排序 1.7.3 volatile 实现原理实现 volatile 关键字的语义参考做法： 在 volatile 写操作的前面插入一个 StoreStore 屏障。保证 volatile 写操作不会和之前的写操作重排序。 在 volatile 写操作的后面插入一个 StoreLoad 屏障。保证 volatile 写操作不会和之后的读操作重排序。 在 volatile 读操作的后面插入一个 LoadLoad 屏障 + LoadStore 屏障。保证 volatile 读操作不会和之后的读操作、写操作重排序。 1.8 final 关键字1.8.1 构造函数溢出问题对于构造函数溢出，就是一个对象的构造并不是“原子的”，当一个线程正在构造对象时，另外一个线程却可以读到未构造好的“一半对象”。 1.8.2 final 的 happen-before 语义解决构造函数溢出的办法： 给变量都加上 volitile 关键字 为 read/write 函数都加上 synchronized 关键字 给变量加上 final 关键字 final 的 happen-before 语义： 对 final 域的写（构造函数内部），happen-before 于后续对 final 域所在对象的读 对 final 域所在对象的读，happen-before 于后续对 final 域的读 通过这种 happen-before 语义的限定，保证了 final 域的赋值，一定在构造函数之前完成，不会出现另外一个线程读取到了对象，但对象里面的变量却还没有初始化的情形，避免出现构造函数溢出的问题。 1.8.3 happen-before 规则总结 单线程中的每个操作，happen-before 于该线程中任意后续操作 对 volatile 变量的写，happen-before 于后续对这个变量的读 对 synchronized 的解锁，happen-before 于后续对这个锁的加锁 对 final 变量的写，happen-before 于 final 域对象的读，happen-before 于后续对 final 变量的读 四个基本规则再加上 hapen-before 的传递性，就构成JVM对开发者的整个承诺图 1-7 从底向上看 volatile 背后的原理 第二章 Atomic类图 2-1 整个 Concurrent 包的层次体系 2.1 AtomicInteger 和 AtomicLong2.1.1 悲观锁与乐观锁悲观锁：数据发生并发冲突的概率很大，所以读操作之前就上锁。synchronized 关键字和 ReentrantLock 都是悲观锁的典型例子。乐观锁：数据发生并发冲突的概率很小，所以读操作之前不上锁。等到写操作的时候，再判断数据在此期间是否被其他线程修改了。如果被其他线程修改了，就把数据重新读出来，重复该过程；如果没有被修改，就写回去。判断数据是否被修改，同时写回新值，这两个操作要合成一个原子操作，也就是CAS（Compare And Set）。AtomicInteger就是典型的乐观锁 2.1.2 Unsafe的CAS详解public final boolean compareAndSet(int expect, int update){ return unsafe.compareAndSwapInt(this, valueOffset, expect, update); } AtomicInteger 封装过的 compareAndSet 有两个参数。第一个参数 expect 是指变量的旧值（是读出来的值，写回去的时候，希望没有被其他线程修改）；第二个参数 update 是指变量的新值（修改过的，没有写入的值）。当 expect 变量等于当前变量时，说明在修改的期间，没有其他线程对此变量进行过修改，所以可以成功写入，变量被更新为 update，返回 true；否则返回 false； public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 该函数有4个参数，第一个是对象（AtomicInteger 变量）；第二个是对象的成员变量（AtomicInteger 里面包的 int 变量 value），它是 long 型整数，常被称为 xxxOffset，意思是某个成员变量在对应的类中的内存偏移量，表示该成员变量本身。无论是 Unsafe 还是 valueOffset，都是静态的，也就是类级别的，所有对象共用的。在转化的时候，先通过反射（getDeclaredField）获取 value 成员变量对应的 Field 对象，再通过 objectFieldOffset 函数转化成 valueOffset。此处的 valueOffset 就代表了 value 变量本身，后面执行CAS操作的时候，不是直接操作 value，而是操作 valueOffset。 2.1.3 自旋与阻塞当一个线程拿不到锁的时候，有两种基本的等待策略：策略1：放弃CPU，进入阻塞状态，等待后续被唤醒，再重新被操作系统调度。策略2：不放弃CPU，空转，不断重试，也就是所谓的“自旋”。这两种策略不是互斥的，可以结合使用。 2.2 AtomicBoolean 和 AtomicReference2.2.1 为什么需要 AtomicBooleanAtomicBoolean： if(flag == false){ flag = true; ... } 实现 compare 和 set 两个操作合在一起的原子性，这也是CAS提供的功能。 if(compareAndSet(false, true)){ ... } AtomicReference： public final boolean compareAndSet(V expect, V update){ return unsafe.compareAndSwapObject(this, valueOffset, exprct, update); } 2.2.2 如何支持 boolean 和 double 类型 AtomicBoolean 类型怎么支持？ 对于用 int 型来代替的，在入参的时候，将 boolean 类型转换成 int 类型；在返回值的时候，将 int 类型 转换成 boolean 类型。 double 类型怎么支持？2.3 AtomicStampedReference 和 AtomicMarkanle2.3.1 ABA问题与解决方法CAS 都是基于“值”来做比较的。但如果另外一个线程把变量的值从 A 改为 B，再从 B 改回到 A，尽管修改过两次，可是在当前线程做 CAS 操作的时候，却会因为值没变而认为数据没有被其他线程修改过，这就是所谓的ABA问题。解决方法：不仅比较“值”，还要比较“版本号”2.3.2 为什么没有 AtomicStampedInteger AtomictStampedLong因为要同时比较“值”和“版本号”，而 Integer 型或者 Long 型的 CAS 没有办法同时比较这两个变量，于是只能把值和版本号封装成一个对象，然后通过对象引用的 CAS 来实现。2.3.3 AtomicMarkableReferencePair 里面的版本号是 boolean 类型的，而不是整型的累加变量。因为是 boolean类型，只能有 true、false 两个版本号，所以并不能完全避免 ABA 问题，只是降低了 ABA 发生的概率。2.4 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater 和 AtomicReferenceFieldUpdater2.4.1 为什么需要 AtomicXXXFieldUpdater如果一个类是自己编写的，则可以在编写的时候把成员变量定义为 Atomic 类型。如果是一个已有的类，在不能更改其源码的情况下，要想实现对其成员变量的原子操作，就需要 AtomicIntegerFieldUpdater、AtomicLongFieldUpdater 和 AtomicReferenceFieldUpdater。2.4.2 限制条件要想使用 AtomicIntegerFieldUpdater 修改成员变量，成员变量必须是 volatile 的 int 类型（不能是 Integer 包装类）2.5 AtomicIntegerArray、AtomicLongArray 和 AtomicReferenceArrayConcurrent 包提供了 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray 三个数组元素的原子操作。注：并不是说对整个数组的操作是原子的，而是针对数组中一个元素的原子操作而言。2.5.1 使用方法相比与 AtomicInteger 的 getAndIncrement() 函数，这里只是多了一个传入参数：数组的下标 ipublic final boolean compareAndSet(int i, int expect, int update){...} public final int getAndDecrement(int i){...} public final int getAndSet(int i, int newValue){...} 2.5.2 实现原理其底层的 CAS 函数用的还是 compareAndSwapInt，但是把数组下标 i 转化成对应的内存偏移量，所用的方法和之前的 AtomicInteger 不太一样。private static long byteOffset(int i){ return ((long) i &lt;&lt; shift) + base; } 把下标 i 换成对应的内存地址，用到 shift 和 base 两个变量。这两个变量都是 AtomicIntegerArray 的静态成员变量，用 Unsafe 类的 arrayBaseOffset 和 arrayIndexScale 两个函数来获取。base 表示数组的首地址的位置，scale 表示一个数组元素的大小，i 的偏移量则等于 i * scale + base。但为了优化性能，使用了位移操作，shift 表示 scale 中 1 的位置（scale 是2的整数次方）。所以，偏移量的计算变成上面代码中的：i &lt;&lt; shift + base，表达的意思就是：i * scale + base。2.6 Striped64 与 LongAdder图 2-2 Striped64 相关的类的继承层次2.6.1 LongAdder 原理AtomicLong 内部是一个 volatile long 型变量，由多个线程对这个变量进行CAS操作。多个线程同时对一个变量进行CAS操作，在高并发的场景下仍不够快，如果再要提高性能，该怎么做？把一个变量拆分成多份，变为多个变量，有些类似于 ConcurrentHashMap 的分段锁的例子。把一个 Long 型拆成一个 base 变量外加多个 Cell，每个 Cell 包装了一个 Long 型变量。当多个线程并发累加的时候，如果并发度低，就直接加到 base 变量上；如果并发度高，冲突大，平摊到这些 Cell 上。在最后取值的时候，再把 base 和这些 Cell 求 sum 运算。2.6.2 最终一致性在 sum 求和函数中，并没有对 cells[] 数组加锁。也就是说，一边有线程对其执行求和操作，一边还有线程修改数组里的值，也就是最终一致性，而不是强一致性。2.6.3 伪共享于缓存行填充 @sun.misc.Contended每个CPU都有自己的缓存。缓存与主内存进行数据交换的基本单位叫 Cache Line（缓存行）。要刷新到主内存的时候，最少要刷新64字节。 2.6.4 LongAdder 核心实现当一个线程调用 add(x) 的时候，首先会尝试使用 casBase 把 x 加到 base 变量上。如果不成功，则再用 a.cas(..) 函数尝试把 x 加到 Cell 数组的某个元素上。如果还不成功，最后再调用 longAccumulate(..) 函数。注：Cell[] 数组的大小始终是2的整数次方，在运行中会不断扩容，每次扩容都是增长2倍。 2.6.5 LongAccumulatorLongAccumulator 与 LongAdder 构造函数对比： public LongAdder() {...} public LongAccumulator(LongBinaryOperator accumulatorFunction, long identity) {...} public interface LongBinaryOperator { long applyAsLong(long left, long right); } LongAdder 只能进行累加操作，并且初始值默认为0；LongAccumulator 可以自己定义一个二元操作符，并且传入一个初始值。操作符的左值，就是 base 变量或者 Cells[] 中元素的当前值；右值，就是 add() 函数传入的参数 x。 LongAccumulator 的 accumulate(x) 函数与 LongAdder 的 add(x) 函数类似，最后都是调用 Striped64 的 LongAccumulate(…) 函数。唯一的差别是 LongAdder 的 add(x) 函数调用的是 casBase(b, b+x)，LongAccumulator 调用的是casBase(b, r)，其中，r = function.applyAsLong(b = base, x)。2.6.6 DoubleAdder 与 DoubleAccumulator第三章 Lock 与 Condition3.1 互斥锁3.1.1 锁的可重入性可重入锁（ReentrantX）是指当一个线程调用 object.lock() 拿到锁，进入互斥区后，在此调用 object.lock()，仍然可以拿到该锁。通常的锁都要设计成可重入的，否则会发生死锁。3.1.2 类继承层次图 3-1 与 ReentrantLock 相关类之间的继承关系I 表示界面（Interface），A表示抽象类（Abstract Class），C表示类（Class），$表示内部类。实线表示继承关系，虚线表示引用关系。常用方法 Lock()/unLock()。lock() 不能被中断，对应的 lockInterrupttibly() 可以被中断。3.1.3 锁的公平性 vs. 非公平性Sync 是一个抽象类，它有两个子类 FairSync 与 NonfairSync，分别对应公平锁和非公平锁一个新的线程来了之后，看到有很多线程在排队，自己排到队伍末尾，这叫公平；线程来了之后直接去抢锁，这叫不公平。默认设置的是非公平锁，为了提高效率，减少线程切换。3.1.4 锁实现的基本原理Sync 的父类 AbstractQueuedSynchronizer 常被称作队列同步器（AQS）为了实现一把具有阻塞或唤醒功能的锁，需要几个核心要素： 需要一个 state 变量，标记该锁的状态。state 变量至少有两个值：0、1。对 state 变量的操作，要确保线程安全，也就是会用到 CAS。 需要记录当前是哪个线程持有锁。 需要底层支持对一个线程进行阻塞或唤醒操作。 需要有一个队列维护所有阻塞的线程。这个队列也必须是线程安全的无锁队列，也需要用到 CAS。 state 取值不仅可以是0、1，还可以大于1，就是为了支持锁的可重入性。例如，同样一个线程，调用5次lock，state 会变成5；然后调用5次 unlock，state 减为0.当 state = 0 时，没有线程持有锁，exclusiveOwnerThread = null；当 state = 1 时，有一个线程持有锁，exclusiveOwnerThread = 该线程；当 state &gt; 1 时，说明该线程重入了该锁。 在当前线程调用 park()，该线程就会堵塞；在另外一个线程中，调用 unpark(Thread t)，传入一个被阻塞的线程，就可以唤醒阻塞在 park() 地方的线程。unpark(Thread t)实现了一个线程对另一个线程的“精准唤醒”。 3.1.5 公平与非公平的 lock() 实现3.1.6 阻塞队列与唤醒机制park() 函数返回有两种情况：情况1：其他线程调用了 unpark(Thread t)情况2：其他线程调用了 t.interrupt()。注意，lock()不能响应中断，但LockSupport.park() 会响应中断。 3.1.7 unlock() 实现分析release() 里面做两件事：tryRelease(..) 函数释放锁；unparkSuccessor(..) 函数唤醒队列中的后继者。因为是排他锁，只有已经持有锁的线程才有资格调用 release(..)，这意味者没有其他线程与它争论。所以在 tryRelease(..) 函数中，对 state 值的修改，不需要CAS操作，直接减1即可。 3.1.8 lockInterruptibly() 实现分析当 parkAndCheckInterrupt() 返回 true 的时候，说明有其他线程发送中断信号，直接抛出 InterruptedException，跳出 for 循环，整个函数返回。 3.1.9 tryLock() 实现分析public boolean tryLock() { return sync.nonfairTryAcquire(1); } tryLock() 实现基于调用非公平锁的 tryAcquire(..)，对 state 进行 CAS 操作，如果操作成功就拿到锁；如果操作不成功则直接返回 false，也不阻塞。 3.2 读写锁读写锁（ReentrantReadWriteLock）就是读线程和读线程之间可以不用互斥了。 3.2.1 类继承层次图 3-3 ReentrantReadWriteLock 类继承层次ReentrantWriteLock 实现了该接口 ReadWriteLock rwLock = new ReentrantReadWriteLock(); Lock rLock = rwLock.readLock(); rLock.lock(); rLock.unlock(); Lock wLock = rwLock.writeLock(); wLock.lock(); wLock.unlock(); 3.2.2 读写锁实现的基本原理ReadLock 和 WriteLock 是两把锁，实际上是同意把锁的两个视图（读线程和写线程）读线程和读线程不互斥（可以同时拿到这把锁），读线程和写线程互斥，写线程和写线程互斥。当 state = 0 时，说明既没有线程持有读锁，也没有线程持有写锁；当 state != 0 时，要么有线程持有读锁，要么有线程持有写锁，两者不能同时成立，因为读和写互斥。这时再进一步通过 sharedCount(state) 和 exclusiveCount(state) 判断到底是读线程还是写线程持有了该锁。 3.2.3 AQS 的两对模板方法acquire/release、acquireShared/releaseShared 是 AQS 里面的两对模板方法。互斥锁和读写锁的写锁都是基于 acquire/release 模板方法来实现的，读写锁的读锁都是基于 acquireShared/releaseShared 模板方法来实现的。图 3-4 四种锁的策略的实现示意图最终对应关系： 读锁的公平实现：Sync.tryAcquireShared() + FairSync 中的两个覆写的子函数。 读锁的非公平实现：Sync.tryAcquireShared() + NonfairSync 中的两个覆写的子函数。 写锁的公平实现：Sync.tryAcquire() + FairSync 中的两个覆写的子函数。 写锁的非公平实现：Sync.tryAcquire() + NonfairSync 中的两个覆写的子函数。 对于公平，不论是读锁，还是写锁，只要队列中有其他线程在排队，就不能直接去抢锁，要排在队列尾部。对于非公平，读锁和写锁的实现策略略有差异。写锁，写线程能抢锁，前提是 state = 0，只有在没有其他线程持有读锁或写锁的情况下，它才有机会去抢锁。当 state != 0，由于持有写锁线程，再次重入。写线程是非公平的，不断去抢（一直返回 false）。但对于读线程，读线程和读线程不互斥的，对于读线程的非公平，要做一些“约束”。当发现队列的第一个元素是写线程，读线程要阻塞一下。 3.2.4 WriteLock 公平 vs. 非公平实现 tryAcquire() 实现分析 if(c != 0) and w == 0，说明当前一定是读线程拿着锁，写锁一定拿不到，返回false。 if(c != 0) and w != 0，说明当前一定是写线程拿着锁，执行 current != getExclusiveOwnerThread() 的判断，发现 ownerThread 不是自己，返回 false。 if(c != 0) and w == 0，且 curent = getExclusiveOwnerThread()，才会走到 if(w + exclusiveCount(acquires) &gt; MAX_COUNT)。判断重入次数，重入次数超过最大值，抛出异常。 if(c = 0)，说明当前既没有读线程，也没有写线程持有该锁。可以通过CAS操作开抢，抢成功后，调用 setExclusiveOwnerThread(current)，把 ownerThread 设成自己 tryRelease(..) 实现分析 因为写锁是排他的，在当前线程持有写锁的时候，其他线程既不会持有写锁，也不会持有读锁。所以，这里对 state 值的调减不需要 CAS 操作，直接减一即可。 3.2.5 ReadLock 公平 vs. 非公平实现 tryAcquireShared(..) 实现分析 tryReleaseShared(..) 实现分析 3.3 Condition3.3.1 Condition 与 Lock 的关系Condition 本身也是接口，其功能和 wait/notify 类似Condition 必须和 Lock 一起使用 3.3.2 Condition 的使用场景一个用数组实现的阻塞队列，执行 put(..) 操作的时候，队列满了，生产者线程被阻塞；执行 take() 操作的时候，队列为空，消费者线程被阻塞。 3.3.3 Condition 实现原理读写锁中的 ReadLock 是不支持 Condition 的，读写锁的写锁和互斥锁都支持 Condition。虽然它们都调用的是自己的内部类 Sync，但内部类 Sync 都继承子、自 AQS。 3.3.4 await() 实现分析 线程调用 await() 的时候，肯定已经拿到了锁。 在线程执行 wait 操作之前，必须先释放锁。 线程从 wait 中被唤醒后，必须用 acquireQueued(node, savedState) 函数重新拿锁。 checkInterruptWhileWaiting(node) 代码在 park(this) 代码之后，是为了检测在 park 期间是否收到过中断信号。 isOnSyncQueue(node) 用于判断该 Node 是否在 AQS 的同步队列里。 3.3.5 awaitUninterruptibly() 实现分析awaitUninterruptibly() 不会响应中断，其函数的定义不会有中断异常抛出，继续执行 while 循环。 3.3.6 notify() 实现分析在调用 notify() 的时候，必须先拿到锁，然后从队列中取出 firstWait，唤醒它。 3.4 StampedLock3.4.1 为什么引入 StampedLock图 3-1 三种锁的并发度对比因为 ReentrantLock 采用的“悲观锁”的策略。当第一个线程拿到锁之后，第二个、第三个读线程还可以拿到锁，使得写线程一直拿不到锁，可能导致写线程“饿死”。虽然在其公平或非公平的实现中，都尽量避免这种情形，但还是有可能发生。StampedLock 引入了“乐观锁策略”，读的时候不加锁，读出来发现数据被修改了，再升级为“悲观锁”，相当于降低了“读”的地位，把抢锁的天平往“写”的一方倾斜了一下，避免写线程被锁死。 3.4.2 使用场景首先，执行 move 操作的时候，要加写锁，写操作和写操作也是互斥的。关键在于读的时候，用了一个“乐观锁”sl.tryOptimisticRead()，相当于在读之前给数据的状态做了一个“快照”。然后，把数据拷贝到内存里面，再用之前，再对比一次版本号。如果版本号变了，则说明在读的期间有其他线程修改了数据。读出来的数据废弃，重新获取读锁。 long stamp = sl.tryOptimisticRead(); //在读之前，获取数据版本号 double currentX = x, currentY = y; //读：将一份数据拷贝到线程的栈内存中 if (!sl.validate(stamp)){...} //读之后：判断读出来数据是否可以使用（所谓可以使用，是指读的期间没有其他线程修改过数据） 这三行关键代码对顺序非常敏感，不能有重排序。因为 state 变量已经是 volatile，所以可以禁止重排序，但 stamp 并不是 volatile 的。为此，在 volatile(stamp) 函数里面插入内存屏障 3.4.3 “乐观锁”的实现原理3.4.4 悲观锁/写：“阻塞”与“自旋”策略实现差异第四章 同步工具类4.1 SemaphoreSemaphore 也就是信号量，提供了资源数量的并发访问控制图 4-1 Semaphore 相关类的继承体系 4.2 CountDownLatch因为是基于AQS阻塞队列实现的，所以可以让多个线程阻塞在 state = 0 条件上，通过 countDown() 一直累减 state，减到0后一次性唤醒所有线程。假设初始总数为M，N个线程 await()，M个线程countDown()，减到0之后，N个线程被唤醒。图 4-3 多个线程阻塞在 await() 示意图 4.2.1 CountDownLatch 使用场景一个主线程要等待10个 Worker 线程工作完毕才退出，就能使用 CountDownLatch 来实现 CountDownLatch doneSignal = new CountDownLatch(10); //初始为10 doneSignal.await(); //主线程调用该方法，阻塞在这 doneSignal.countDown(); //10个Worker线程，每个线程工作完毕后，调用1次countDown()，计算器减1。当减到0之后，主线程被唤醒 图 4-2 CountDownLatch 相关类的继承层次 4.2.2 await() 实现分析await() 调用的是AQS模版方法从 tryAcquireShared(..) 方法的实现来看，只要 state != 0，调用 await() 方法的线程便会被释放入AQS的阻塞队列，进入阻塞状态。 4.2.3 countDown() 实现分析countDown() 调用的AQS的模版方法 releaseShared()，里面的 tryReleaseShared(..) 被 CountDownLatch.Sync 重新实现。只有 state = 0，tryReleaseShared(..) 才会返回 true，然后执行 doReleaseShared(..)，一次性唤醒队列中所有阻塞的线程。 4.3 CyclicBarrier4.3.1 CyclicBarrier 使用场景等待所有线程到达同步点再开始下一个阶段。 4.3.2 CyclicBarrier 实现分析 CyclicBarrier 是可以被重用的。所有线程互相等待，到齐后一起被唤醒各自执行接下来的逻辑。每一轮被称为一个 Generation，就是一个同步点 CyclicBarrier 会响应中断。线程没有到齐，如果收到中断信号，所有阻塞线程会被唤醒，就是 breakBarrier() 函数。然后 count 被重置为初始值（parties），重新开始。 barrierAction 只会被执行一次。 4.4 Exchanger4.4.1 Exchanger 使用场景Exchanger 用于线程之间交换数据 4.4.2 Exchanger 实现原理Exchanger 的核心机制和 Lock 一样，也是 CAS + park/unpark。每个线程在调用 exchange(..) 函数交换数据的时候，会先创建一个 Node 对象，这个 Node 对象就是对该线程的包装，里面包含了两个字段：1个是线程要交互的数据，另1个是该线程自身。注：Node 本身是继承自AtomicReference 的，所以除了这两个字段，Node 还有第3个字段，记录的是对方所要交换的数据，初始为 NULL。Slot 的 AtomicReference 就是指向的一个 Node，通过 Slot 和 Node 相结合，实现了2个线程之间的数据交换。线程1持有数据 item1，线程2持有数据 item2，各自调用 exchange(..)，会各自生成一个 Node。而 Slot 只会指向2个 Node 中的1个：如果是线程1先调用的 exchange(..)，那么 Slot 就指向 Node1 ，线程1阻塞，等待线程2来交换；反之，如果是线程2先调用的 exchange(..) ，那么 Slot 就指向 Node2，线程2阻塞，等待线程1来交换数据。图 4-3 Slot 与 Node 相结合实现2个线程交换数据一个 Slot 只能支持2个线程之间交换数据，要实现多个线程并行地交换数据，需要多个Slot，因此在 Exchange 里面定义了 Slot 数组： private volatile Slot[] arena = new Slot[CAPACITY]; 4.4.3 exchanger(V x) 实现分析4.5 Phaser4.5.1 用 Phaser 替代 CyclicBarrier 和 CountDownLatch 用 Phaser 替代 CyclicBarrier Phaser ph = new Phaser(10); //初始为10 ph.awaitAdance(ph.getPhase()); //主线程调用该方法，阻塞在这。 ph.arrive(); //每个线程工作完成之后，调用1次arrive()。 用 Phaser 替代 CountDownLatch 4.5.2 Phaser 新特性特性1：动态调整线程个数CyclicBarrier 所要同步的线程个数是在构造函数中指定的，之后不能更改。而 Phaser 可以在运行期间动态地调整要同步的线程个数。 特性2：层次 Phaser父 Phaser 并不用感知子 Phaser 的存在，当子 Phaser 中注册的参与者数量大于0时，会把自己向父节点注册；当子 Phaser 中注册的参与者数量等于0时，会自动向父节点解注册。父 Phaser 把子 Phaser 当作一个正常参与的线程就可以了。 4.5.3 state 变量解析state 变量在构造函数中是如何赋值的？ 当 parties = 0 时，state 被赋予一个 EMPTY 常量，常量为1； 当 parties != 0 时，把 phase 值左移32位；把 parties 左移16位；然后 parties 也作为最低的16位，3个值做或操作，赋值给 state。4.5.4 阻塞与唤醒（Treiber Strack）基于上述的 state 变量，对其执行 CAS 操作，并进行相应的阻塞与唤醒。右边的主线程会调用 awaitAdcance() 进行阻塞；左边的 arrive() 会对 state 进行 CAS 的累减操作，当未到达的线程数减到0时，唤醒右边阻塞的主线程。图 4-10 基于 state 的 CAS 的阻塞与唤醒示意图4.5.5 arrive() 函数分析arrive() 和 arriveAndDeregister() 内部调用的都是 doArrive(boolean)函数。arrive() 把“未达到线程数”减1； arriveAndDeregister() 把“未到达线程数”和“下一轮的总线程数”都减1.4.5.6 awaitAdvance() 函数分析第五章 并发容器5.1 BlockingQueue在所有的并发容器中，BlockingQueue 是最常见的一种。BlockingQueue 是一个带阻塞功能的队列当入队列时，若队列已满，则阻塞调用者；当出队列时，若队列为空，则阻塞调用者。图 5-1 BlockingQueue 的各种实现类5.1.1 ArrayBlockingQueueArrayBlockingQueue 是一个用数组实行的环形队列，在构造函数中，会要求传入数组的容量。public ArrayBlockingQueue(int capacity, boolean fair) {...} 5.1.2 LinkedBlockingQueueLinkedBlockingQueue 是一种基于单向链表的阻塞队列。因为队头和队尾是2个指针分开操作的，所以用了2把锁 + 2个条件，同时有1个 AtomicInteger 的原子变量记录 count 数。LinkedBlockingQueue 和 ArrayBlockingQueue 的实现差异： 为了提高并发度，用2把锁，分别控制队头、队尾的操作。意味着在 put(..) 和 put(..) 之间、take(..) 和 take(..) 之间互斥的，put(..) 和 take(..) 之间并不互斥的。但对于 count 变量，双方都需要操作，所以必须是原子类型。 因为各自拿了一把锁，所以当需要调用对方的 condition 的 signal 时，还必须再加上对方的锁，就是 signalNotEmpty() 和 signalNotFull() 函数。 不仅 put 会通知 take，take 也会通知 put。当 put 发现非满时，也会通知其他 put 线程；当 take 发现非空的时候，也会通知其他 take 线程。 5.1.3 PriorityBlockingQueue队列通常是先进先出的，而 PriorityQueue 是按照元素的优先级从小到大出队列的。PriorityQueue 中的2个元素之间需要可以比较大小，并实现 Comparable 接口。在阻塞的实现方面，和 ArrayBlockingQueue 的机制相似，主要区别是用数组实现了一个二叉堆，从而实现按优先级从小到大出队列。另一个区别是没有 notFull 条件，当元素个数超过数组长度时，执行扩容操作。 5.1.4 DelayQueueDelayQueue 即延迟队列，也就是一个按延迟时间从小到大出队的 PriorityQueue。所谓延迟时间，就是“未来将要执行的时间” - “当前时间”。为此，放入 DelayQueue 中的元素，必须实现 Delayed 接口。 public interface Delayed extends Comparable&lt;Delayed&gt;{ long getDelay(TimeUnit unit); } 关于该接口，有两点说明： 如果 getDelay 的返回值小于或等于0，则说明该元素到期，需要从队列中拿出来执行。 该接口首先继承了 Comparable 接口，所以要实现该接口，必须实现 Comparable 接口 不是每放入一个元素，都需要通知等待的线程。放入的元素，如果其延迟时间大于当前堆顶的元素延迟时间，就没必要通知等待的线程；只有当延迟时间是最小的，在堆顶时，才有必要通知等待的线程，也就是上面代码中的 if(q.peek()==e)段落。 5.1.5 SynchronousQueueSynchronousQueue 是一种特殊的 BlockingQueue，它本身没有容量。先调 put(..)，线程会阻塞；直到另一个线程调用 take()，两个线程才同时解锁，反之亦然。如果是公平模式，则用 TransferQueue 实现；如果是非公平模式，则用 TransferStack 实现。put/take 都调用了 transfer(..) 接口。而 TransferQueue 和 TransferStack 分别实现了这个接口。该接口在 SynchronousQueue 内部。如果是 put(..)，则第1个参数就是对应的元素；如果是 take()，则是第1个为 null。后2个参数分别为是否设置超时和对应的超时时间。 abstract static class Transferer{ abstract Object transfer(Object e, boolean timed, long nanos); } TransferQueue TransferQueue 是一个基于单向链表而实现的队列，通过 head 和 tail 2个指针记录头部和尾部。初始的时候，head 和 tail 会指向一个空节点。TransferQueue 的工作原理阶段(a)：队列中是一个空的节点，head/tail都指向这个空节点。阶段(b)：3个线程分别调用 put，生成3个 QNode，进入队列。阶段(c)：来了一个线程调用 take，会和队列头部的第1个 QNode 进行配对。阶段(d)：第1个 QNode 出队列。关键点：put 节点和 take 节点一旦相遇，就会配对出队列，所以在队列中不可能同时存在 put 节点和 take 节点，要么所有节点都是 put 节点，要么所有节点都是 take 节点。 TransferStack TransferStack 是一个单向链表，只需要 head 指针就能实现入栈和出栈操作。链表中的节点有三种状态，REQUEST 对应 take 节点，DATE 对应 put 节点，二者配对后，会生成一个 FULFILLING 节点，入栈，然后 FULLING 节点和被配对的节点一起出栈。TransferStack 的工作原理阶段(a)：head 指向 NULL。不同于 TransferQueue，这里没有空的头节点。阶段(b)：3个线程调用3次 put，依次入栈。阶段(c)：线程4调用 take，和栈顶的第1个元素配对，生成 FULLFILLING 节点，入栈。阶段(d)：栈顶的2个元素同时入栈。 5.2 BlockingDequeBlockingDeque 定义了一个阻塞的双端队列接口。该接口继承了 BlockingQueue 接口的同时，增加对应双端队列操作接口。该接口只有一个实现，就是 LinkedBlockingDeque 5.3 CopyOnWriteCopyOnWrite 指在“写”的时候，不是直接“写”源数据，而是把数据拷贝一份进行修改，再通过悲观锁或者乐观锁的方式写回。 5.3.1 CopyOnWriteArrayList5.3.2 CopyOnWriteArraySetCopyOnWriteArraySet 就是用 Array 实现的一个 Set，保证所有元素都不重复。 5.4 ConcurrentLinkedQueue/Deque 初始化 初始化的时候，head 和 tail 都执行一个 NULL 节点。 入队列 初始的时候，队列中有1个节点 item1，tail 指向该节点，假设线程1要入队 item2 节点：step1：p = tail，q = p.next = NULL。step2：对p的 next 执行 CAS 操作，追加 item2，成功之后，p = tail。所以上面的 casTail 函数不会执行，直接返回。此时 tail 指针没有变化。step3：p = tail，q = p.next。step4：q != NULL，因此不会入队新节点。p，q都后移1位。step5：q = NULL，对p的 next 执行 CAS 操作，入队 item3 节点。step6：p != t，满足条件，执行上面的 casTail 操作，tail 后移2个位置，到达队列尾部。关键点： 即使 tail 指针没有移动，只要对p的 next 指针成功进行 CAS 操作，就算成功入队列。 只有当 p != tail 的时候，才会后移 tail 指针。也就是说，每连续追加2个节点，才后移1次 tail 指针。即使 CAS 失败，也可以由下一个线程来移动 tail 指针。 出队列 假设初始的时候 head 指向空节点，队列中有 item1，item2，item3 三个节点。step1：p = head，q = p.next，p != q。step2：后移p指针，使得 p = q。step3：出队列。关键点：此处并没有直接删除 item1 节点，只是把该节点的 item 通过 CAS 操作置为了 NULL。step4：p != head，此时队列中有了2个 NULL 节点，，再前移1次 head 指针，对其进行 updateHead 操作。关键点： 出队列的判断并非观察 tail 指针的位置，而是依赖于 head 指针后续的节点是否为 NULL 这一条件。 只要对节点的 item 执行 CAS 操作，置为 NULL 成功，则出队列成功。即使 head 指针没有成功移动，也可以由下一个线程继续完成。 队列判空 因为 head/tail 并不是精确地指向队列头部和尾部，所以不能简单地通过比较 head/tail 指针来判断队列是否为空，而是需要从 head 指针开始遍历，找第1个不为 NULL 的节点。如果找到，则队列不为空；如果找不到，则队列为空。 5.5 ConcurrentHashMapHashMap 通常的实现方式是“数组 + 链表”，这种方式被称为“拉链法”。 5.5.1 JDK7 中的实现方式 构造函数分析 第1个参数，initialCapacity 是整个 ConcurrentHashMap 的初始大小。用 initialCapacity 除以 ssize，是每个 Segment 的初始大小。这里也会保证 Segment 里面 HashEntry[] 数组的大小是2的整数次方。 第2个参数，loadFactor 即负载因子，传给了 Segment 内部。当每个 Segment 的元素达到一定阀值，进行 rehash。Segment 的个数不能扩容，但每个 Segment 的内部可以扩容。 第3个参数，concurrenyLevel 是“并发度”，也就是 Segment 数组的大小。这个值一旦在构造函数中设定，之后不能再扩容。为了提升 hash 的计算性能，会保证数组的大小始终是2的整数次方。 put(..) 函数分析 进入 scanAndLockForPut(key, hash, value) 做什么？一是拿不到锁，不立即阻塞，而是先自旋，若自旋到一定次数仍未拿到锁，再调用 lock() 阻塞；二是在自旋的过程中遍历了链表，若发现没有重复的节点，则提前新建一个节点，为后面再插入节省时间。 扩容 函数的参数，也就是将要加入的最新节点。在扩容完成之后，把该节点加入新的 Hash 表。 整个数组的长度是2的整数次方，每次按二倍扩容，而 hash 函数就是对数组长度取模，即 node.hash &amp; sizeMask。因此，如果元素之前处于第i个位置，当再次 hash 时，必然处于第i个或第 i+oldCapacity 个位置。 lastRun 到链表末尾的所有元素，其 hash 值没有改变，所以不需要依次重新拷贝，只需把这部分链表链接到新链表锁对应的位置就可以，也就是 new Table[lastIdx] = lastRun。lastRun 之前的元素则需要依次拷贝 get 实现分析 整个 get 过程是两次 hash 第一次 hash，函数为 (h&gt;&gt;&gt;segmentShift) &amp; segmentMask，计算出所在的 Segment； 第二次 hash，函数为 h &amp; (tab.length - 1)，即h对数组长度取模，找到 Segment 里面对应的 HashEntry 数组下标，然后遍历该位置的链表 整个读过程完全没有加锁，而是使用了 UNSAFE.getObjectVolatile 函数。 5.5.2 JDK8 中的实现方式链表和红黑树之间可以相互转换：初始的时候是链表，当链表中的元素超过某个阀值时，把链表转换成红黑树；反之，当红黑树中的元素个数小于某个阀值，再转换为链表。为什么 JDK8 要做这种改变？在 JDK7 中的分段锁，有三个好处： 减少 Hash 冲突，避免一个槽里有太多元素。 提高读和写的并发度。段与段之间相互独立。 提供扩容的并发度。扩容的时候，不是整个 ConcurrentHashMap 一起扩容，而是每个 Segment 独立扩容。 针对这三个好处，JDK8 相应的处理方式： 使用红黑树，当一个槽里有很多元素时，其查询和更新速度会比链表快很多，Hash 冲突的问题由此得到很好的解决。 加锁的粒度，并非整个 ConcurrentHashMap，而是对每个头节点分别加锁，即并发度，就是 Node 数组长度，初始长度为16，和在 JDK7 中初始 Segment 的个数相同。 并发扩容，在 JDK7 中，一旦 Segment 的个数在初始化的时候确立，不能再更改，并发度被固定。之后只是在每个 Segment 内部扩容，这意味着每个 Segment 独立扩容，互不影响，不存在并发扩容的问题。在 JDK8 中，相当于只有1个 Segment，当一个线程要扩容 Node 数组的时候，其他线程还要读写。5.6 ConcurrentSkipListMap/SetConcurrentSkipListMap 是一个 key 无序的 HashMap，HashMap 则是 key 有序的，实现了 NavigableMap 接口，此接口又继承了 SortedMap 接口。5.6.1 ConcurrentSkipListMap为什么要使用 SkipList 实现 Map？在 Java 的 util 包中，有一个非线程安全的 HashMap，也就是 TreeMap，是 key 有序的，基于红黑树实现。而在 Concurrent 包中，提供的 key 有序的 HashMap，也就是 ConcurrentSkipMap，是基于 SkipList（调查表）来实现的。5.6.2 ConcurrentSkipListSet第六章 线程池与 Future6.1 线程池的实现原理当没有任务的时候，线程是进入睡眠一小段时间？还是进入阻塞？如果进入阻塞，如何让唤醒？ 做法1：不使用阻塞队列，只使用一般的线程安全的队列，也无阻塞—唤醒机制。当队列为空时，线程池中的线程只能睡眠一会，然后醒来去看队列中有没有新任务到来，如此不断轮询。 做法2：不使用阻塞队列，但在队列外部、线程池内部实现了阻塞—唤醒机制。 做法3：使用阻塞队列 做法3最完善，既避免了线程池内部自己实现阻塞—唤醒机制的麻烦，也避免了做法1的睡眠—轮询带来的资源消耗和延迟。 6.2 线程池的类继承体系两个核心类：ThreadPoolExecutor 和 ScheduledThreadPoolExecutor，后者不仅可以执行某个任务，还可以周期性地执行任务。向线程池中提交的每个任务，都必须实现 Runnable 接口，通过最上面的 Executor 接口中的 execute(Runnable command) 向线程池提交任务。在 ExecutorService 中，定义了线程池的关闭接口 shutdown()，还定义了可以返回值的任务，也就是 Callable。 6.3 ThreadPoolExecutor6.3.1 核心数据结构每一个线程是一个 Worker 对象。Worder 是 ThreadPoolExecutor 的内部类。Worder 继承于 AQS，也就是 Worker 本身就是一把锁。 6.3.2 核心配置参数解释 corePoolSize：在线程池始终维护的线程个数。 maxPoolSize：在 corePoolSize 已满、队列也满的情况下，扩充至此值。 keepAliveTime/TimeUnit：maxPoolSize 中的空闲线程，销毁所需要的时间，总线程数收缩回 corePoolSize。 blockingQueue：线程池所用的队列类型。 threadFactory：线程创建工厂，可以自定义，也可以默认。 RejectedExecutionHandler：corePoolSize 已满，队列已满，maxPoolSize 已满，最后的拒绝策略。 6个配置参数的处理流程：Step1：判断当前线程数是否大于或等于 coolPoolSize。如果小于，则新建线程执行；如果大于，则进入 Step2。Step2：判断队列是否已满。如未满，则放入；如已满，则进入 step3。Step3：判断当前线程数是否大于或等于 maxPoolSize。如果小于，则新建线程执行；如果大于，则进入 step4。Step4：根据拒绝策略，拒绝任务总结：首先判断 corePoolSize，其次判断 blockingQueue 是否已满，接着判断 maxPoolSize，最后使用拒绝策略。基于这种流程，如果队列是无界的，将永远没有机会走到 step3，也即 maxPoolSize 没有使用，也一定不会走到 step4。 6.3.3 线程池的优雅关闭 线程池的生命周期 线程池有两个关闭函数，shutdown() 和 shutdownNow()，这两个函数会让线程池切换到不同的状态。在队列为空，线程池也为空之后，进入 TIDYING 状态；最后执行一个钩子函数 terminated()，进入 TERMINATED 状态，线程池才“寿终正寝”。状态前移只会从小的状态值往大的状态值迁移，不会逆向迁移。 正确关闭线程池的步骤 在调用 shutdown() 和 shutdownNow() 之后，线程池并不会立即关闭，接下来需要调用 awaitTermination() 来等待线程池关闭。awaitTermination(..) 不断循环判断线程池是否到达了最终状态 TERMINATED，如果是，就返回；如果不是，则通过 termination 条件变量阻塞一段时间，“苏醒”之后，继续判断。 shutdown() 与 shutdownNow() 的区别 前者不会清空任务队列，会等所有任务执行完成，后者再清空任务队列。 前者只会中断空闲的线程，后者会中断所有线程。6.3.4 任务的提交过程分析6.3.5 任务的执行过程分析场景1：当调用 shutdown() 的时候，所有线程都处于空闲状态。这意味着任务队列一定是空的。此时，所有线程都会阻塞在 getTask() 函数的地方。然后，所有线程都会收到 interruptIdleWorkers() 发来的中断信号，getTask() 返回 null，所有 Worker 都会退出 while 循环，之后执行 processWorkerExit。场景2：当调用 shutdown() 的时候，所有线程都处于忙碌状态。此时，队列可能是空的，可能是非空的。interruptIdleWorkers() 内部的 tryLock 调用失败，什么都不会做，所有线程会继续执行自己当前的任务。之后所有线程会执行完队列中的任务，直到队列为空，getTask() 才会返回 null。之后，和场景1一样，退出 while 循环。场景3：当调用 shutdown() 的时候，部分线程忙碌，部分线程空闲。有部分线程空闲，说明队列一定是空的，这些线程肯定阻塞在 getTask() 函数的地方。空闲的这些线程会和场景1一样处理，不空闲的线程会和场景2一样处理。6.3.6 线程池的4种拒绝策略 让调用者直接在自己的线程里面执行，线程池不做处理。 线程池直接抛出异常。 线程池直接把任务丢掉，当作什么也没有发生。 把队列里面最老的任务删除掉，把该任务放入队列中。 6.4 Callable 与 Future6.5 ScheduledThreadPoolExecutorScheduledThreadPoolExecutor 实现了按时间调度来执行任务，两方面： 延迟执行任务： public ScheduledFuture &lt;?&gt; schedule(Runable command, long delay, TimeUnit unit); public &lt;V&gt;ScheduledFuture &lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); 周期执行任务： public ScheduledFuture &lt;?&gt; scheduleAtFixedRate(Runable command, long initalDelay, TimeUnit unit); public &lt;V&gt;ScheduledFuture &lt;V&gt; schedulWithFixedRate(Runable command, long initalDelay, long delay, TimeUnit unit); 两个函数的区别： AtFixedRate：按固定频率执行，与任务本身执行时间无关。但有个前提条件，任务执行时间必须小于间隔时间。 WithFixedDelay：按固定间隔执行，与任务本身执行时间有关。6.5.1 延迟执行和周期性执行的原理6.5.2 延迟执行传进去的是一个 Runnable，外加延迟时间 delay。6.5.3 周期性执行包装一个 ScheduledFutureTask 对象，只是在延迟时间参差之外多了一个周期参数，然后放入 DelayedWorkerQueue 就结束了。 withFixedRate 和 atFixedRate 的区别体现在 setNextRunTime 里面。 如果是 atFixedRate，period &gt; 0，下一次开始执行时间等于上一次开始执行时间 + period； 如果是 withFixedRate，period &lt; 0，下一次开始执行时间等于 triggerTime(-p)，为 now + (-period)，now 即是上一次执行的结束时间。6.6 Executors 工具类第七章 ForkJoinPool7.1 ForkJoinPool 用法例1：快排第一步：利用数组的第一个元素把数组划分成两半，左边数组里面的元素小于或等于该元素，右边数组里面的元素比该元素大；第二步：对左右的2个子数组分别排序。7.2 核心数据结构7.3 工作窃取队列窃取算法是指一个 Worker 线程在执行完毕自己队列中的任务之后，可以窃取其他线程队列中的任务来执行，从而实现负载均衡，以防有的线程很空闲，有的线程很忙。这个过程要用到工作窃取队列。这个队列只有三个操作： Worker 线程自己，在队列头部，通过对 queueTop 指针执行加、减操作，实现入队或出队，这是单线程的； 其他 Worker 线程，在队列尾部，通过对 queueBase 进行累加，实现出队操作，也就是窃取，这是多线程的，需要通过 CAS 操作。 关键点： 整个队列是环形的，也就是一个数组实现的 RingBuffer。并且 queueBase 会一直累加，不会减少；queueTop 会累加、减小。最后，queueBase、queueTop 的值都会大于整个数组的长度，只是计算数组的下标的时候，会取 queueTop &amp; (queue.length-1)，queueBase &amp; (queue.length-1)。因为 queue.length 是2的整数次方，这里也就是对 queue.length 是2的整数次方，这里也是对 queue.length 进行取模操作。 当 queueTop - queueBase = queue.length-1 的时候，队列为满，此时需要扩容； 当 queueTop = queueBase 的时候，队列为空，Worker 线程即将进入阻塞状态 当队列满了之后会扩容，所以被称为是动态的。 7.4 ForkJoinPool 状态控制7.4.1 状态变量 ctl 解析ctl 变量的64比特位被分为五部分：AC：最高的16个比特位，表示 Active 线程数 -parallelism，parallelism 是上面的构造函数传进去的参数；TC：次高的16个比特位，表示 Total 线程数 -parallelism；ST：1个比特位，如果是1，表示整个 ForkJoinPool 正在关闭；EC：15个比特位，表示阻塞栈的栈顶线程的 wait count；ID：16个比特位，表示阻塞栈的栈顶线程对应的 poolIndex。 7.4.2 阻塞栈 Treiber Stack要实现多个线程的阻塞、唤醒，除了 park/unpark 这一对操作原语，还需要一个无锁链表实现的阻塞队列，把所有阻塞的线程串在一起。在 ForkJoinPool 中，没有使用阻塞队列，而是使用了阻塞栈。把所有空闲的 Worker 线程放在一个栈里面，这个栈同样通过链来实现，名为 Treiber Stack。首先，ForkJoinWorkerThread 有一个 poolIndex 变量，记录了自己在 ForkJoinWorkerThread[] 数组中的下标位置，poolIndex 变量就相当于每个 ForkJoinPoolWorkerThread 对象的地址；其次 ForkJoinWorkerThread 还有一个 nextWait 变量，记录了前一个阻塞线程的 poolIndex，这个 nextWait 变量就相当于链表的 next 指针，把所有的阻塞线程串联在一起，组成一个Treiber Stack。最后，ctl 变量的最低16位，记录了栈的栈顶线程的 poolIndex；中间的15位，记录了栈顶的线程被阻塞的次数，也称为 wait count。 7.4.3 ctl 变量的初始值因为在初始的时候，ForkJoinPool 中的线程个数为0，所以 AC = 0 - parallelism，TC = 0 - parallelism。这意味着只有高32位的AC、TC 两个部分填充了值，低32位都是0填充。 7.4.4 ForkJoinWorkerThread 状态与个数分析ForkJoinPool 中的线程可能的状态有三种： 空闲状态（放在Treiber Stack里面） 活跃状态（正在执行某个 ForkJoinTask，未阻塞） 阻塞状态（正在执行某个 ForkJoinTask，但阻塞了，于是调用 join，等待另外一个任务的结果返回） ctl更好地反映出了三种状态：高32位：u = (int)(ctl&gt;&gt;&gt;32)，然后 u 又拆分成 tc、ac 两个16位；低32位：e = (int)ctl e&gt;0，说明 Treiber Stack 不为空，有空闲线程；e = 0，说明没有空闲线程； ac&gt;0，说明有活跃线程；ac &lt;= 0，说明没有空闲线程，并且还未超出 parallelism； tc&gt;0，说明总线程数 &gt; parallelism。 tc 与 ac 的差值，也就是总线程数与活跃线程数的差异，在 ForkJoinPool 中有另外一个变量 blockedCount 记录。所以，通过 crl 和 blockedCount 这两个变量，可以知道在整个 ForkJoinPool 中所有空闲线程、活跃线程以及阻塞线程的数量。 7.5 Worker 线程的阻塞-唤醒7.5.1 阻塞-入栈函数的第一个参数就是要阻塞的线程，第二个参数是当前的 ctl 变量的值。入栈，也就是3步：第一步：w.nextWait = (int)c，即使 w.nextWait 指针，指向栈顶；第二步：long nc = (long)(v &amp; E_MASK) | (c - AC_UNIT) &amp; (AC_MASK|TC_MASK))，即新的栈顶就是当前的线程w，同时把 ac 的值减1，即活跃线程数减1；第三步：将 nc 通过 CAS 赋值给 ctl 变量 UNSAFE。compareAndSwapLong(this, ctlOffset, c, nc)。此时入栈成功，ctl 变量更新成功。最后，调用 LockSupport.park(this) 阻塞自己。但是在这期间做了很多其他事情： 统计 stealCount。 判断 ForkJoinPool 是否关闭，以及是否所有线程都处于空闲状态，整个 ForkJoinPool 是否处于静默状态 在阻塞之前，为了保险，又重新扫描了一遍队列，观察是否有任务可以执行。 7.5.2 唤醒-出栈当 signalWorker 函数的参数为空，它会唤醒栈顶的线程，如：e &gt; 0，说明栈不为空，此时 e 的最低16位，存储的是栈顶线程的poolIndex，取出来唤醒；e = 0，说明栈为空，此时开一个新线程。 7.6 任务的提交过程分析如何区分一个任务是内部任务还是外部任务？可以通过调用该函数的线程类型判断。如果线程类型是 ForkJoinWorkerThread，说明是线程池内部的某个线程在调用该函数，则把该任务放入该线程的局部队列；否则，是外部线程在调用该函数，则将该任务加入全局队列。 7.6.1 内部提交任务 pushTask由于工作窃取队列的特性，其对 queueTop 的操作是单线程的，所以此处不需要执行 CAS 操作。当 queueTop - queueBase = 0 的时候，队列为空，此处为了保险，写作 queueTop - queueBase &lt;= 2，不影响正确性。 7.6.2 外部提交任务 addSubmission外部多个线程会调用该函数，所以要加锁，入队列和扩容的逻辑和线程内部的队列基本相同，最后，调用 signalWork()，通知一个空闲线程来取。 7.7 工作窃取算法：任务的执行过程分析7.7.1 顺序锁 SeqLock 读线程在读取共享数据之前先读取 sequence number，在读取数据之后仔读一次 sequence number，如果两次的值不同，说明在此期间有其他线程修改了数据，此次读取数据无效重新读取； 写线程，在写入数据之前，累加一次 sequence number，在写入数据之后，再累加一次 sequence number。 最初，sequence number = 0，读线程不会修改 sequence number，而一个写线程会累加两次 sequence number，所以 sequence number 始终是偶数。如果 sequence number 是奇数，说明当前某个写线程正在修改数据，其他写线程被互斥。对于写线程而言，发现 sequence number 是奇数，就不能修改共享数据了。对于读线程而言，发现 sequence number 是奇数，也不能再读取数据；如果发现 sequence number 是偶数，那么在读取数据前后分别读取一次 sequence number，如果两次的值相同，则读取成功，否则重新读取。 7.7.2 scanGuard 解析scanGuard 变量充当了顺序锁的 sequence number 的功能，共享数据就是 Worker 线程数组 ws。所以，在scan 函数中，在函数开始的时候，读取了一次 scanGuard，扫描完 ws 对应的队列，又读取了一次 scanGuard，发现两次的值不同。说明在这期间 ws 的数组发生了变化，可能是新加了线程，ws 数组扩容了，于是返回false，重新进入 scan 函数。 7.8 ForkJoinTask 的 fork/join7.8.1 fork7.8.2 join 的层层嵌套7.9 ForkJoinPool 的优雅关闭7.9.1 关键的 terminate 变量7.9.2 shutdown() 与 shutdownNow() 的区别shutdown() 只拒绝新提交的任务； shutdownNow() 会取消现有的全局队列和局部队列中的任务，同时唤醒所有空闲的线程，让这些线程自动退出。 第八章 CompletableFuture8.1 CompletableFuture 用法8.1.1 最简单的用法CompletableFuture 实现了 Future 接口，所以它也具有 Future 的特性：调用 get() 方法会阻塞在那，知道结果返回。 8.1.2 提交任务：runAsync 与 supplyAsyncCompletableFuture 和 Future 很相似，都可以提交两类任务：一类是无返回值的，另一类是有返回值的。 8.1.3 链式的 CompletableFuture：thenRun、thenAccept 和 thenApply对于 Future，在提交任务之后，只能调用 get() 等结果返回；但对于CompletableFuture，可以在结果上面加一个 callback，当得到结果之后，再接着执行 callback。最后紧急执行 callback 的区别： thenRun 后面跟的是一个无参数、无返回值的方法，即 Runnable，所以最终的返回值是 CompletableFuture 类型。 thenAccept 后main跟的是一个有参数、无返回值的方法，称为 Consumer，返回值也是CompletableFuture 类型。顾名思义，只进不出，所以称为 Consumer；前面的 Supplier，是无参数，有返回值，只出不进，和 Consumer 刚好相反。 thenApply 后面跟的是一个有参数、有返回值的方法，称为 Function。返回值是 CompletableFuture 类型。 8.1.4 CompletableFuture 的组合：thenCompose 与 thenCombine8.1.5 任意个 CompletableFuture 的组合thenCompose 与 thenCombine 只能组合2个 CompletableFuture，而 allof 和anyof 可以组合任意多个 CompletableFuture。这个两个函数都是静态函数，参数是变长的 CompletableFuture 的集合，allof 是与，anyof 是或 8.2 四种任务原型runAsync 与 supplierAsync 是 CompletableFuture 的静态方法；而 thenAccept、runAsync、thenApply 是 CompletableFuture 的成员方法。因为初始的时候没有 CompletableFuture 对象，也没有参数可传，所以提交的只能是 Runnable 或者 Supplier，只能是静态方法；通过静态方法生成 CompletableFuture 对象之后，便可以链式地提交其他任务了，这个时候就可以提交 Runnable、Consumer、Function，且都是成员方法。 8.3 CompletionFuture 接口8.4 CompletableFuture 内部原理8.4.1 CompletableFuture 的构造：ForkJoinPoolasyncPool 是一个 static类型，supplierAsync、asyncSupplyStage 都是 static 函数。Static 函数返回一个 CompletableFuture 类型对象，之后可以链式调用，CompletionStage 里面的各个方法。 8.4.2 任务类型的适配8.4.3 任务的链式执行过程分析AsyncSupply 三个关键点： 继承自 ForkJoinTask，所以能够提交ForkJoinPool 来执行 封装了 Supplier f，即它所执行任务的具体内容 该任务的返回值，即 CompletableFuture d，也被封装在里面。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://quricolouis.github.io/tags/Java/"},{"name":"JDK源码","slug":"JDK源码","permalink":"http://quricolouis.github.io/tags/JDK%E6%BA%90%E7%A0%81/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"author":"QuricoLouis"},{"title":"Git笔记","slug":"git","date":"2021-05-01T07:41:45.000Z","updated":"2021-09-06T08:54:57.446Z","comments":true,"path":"posts/5bd9b965.html","link":"","permalink":"http://quricolouis.github.io/posts/5bd9b965.html","excerpt":"","text":"版本控制工具集中式版本控制工具CVS、SVN(Subversion)、VSS 优点：每个人都可以在一定程度上看到项目中的其他人正在做些什 么。而管理员也可以轻松掌控每个开发者的权限，并且管理一个集中化的版本控制系统，要 远 比在各个客户端上维护本地数据库来得轻松容易。 缺点：是中央服务器的单点故障。如果服务器宕 机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作 分布式版本控制工具Git、Mercurial、Bazaar、Darcs 优点：客户端提取的不是最新版本的文件快照，而是把代码 仓库完整地镜像下来（本地库）。这样任何一处协同工作用的文件发生故障，事后都可以用 其他客户 端的本地仓库进行恢复。因为每个客户端的每一次文件提取操作，实际上都是一次 对整个文件仓库的完整备份。 1. 服务器断网的情况下也可以进行开发（因为版本控制是在本地进行的） 2. 每个客户端保存的也都是整个完整的项目（包含历史记录，更加安全） Git工作机制 Git常用命令 Git分支操作 分支好处​ 同时并行推进多个功能开发，提高开发效率。 ​ 各个分支在开发过程中，如果某一个分支开发失败，不会对其他分支有任何影响。失败 的分支删除重新开始即可。 常用命令 远程操作常用命令","categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://quricolouis.github.io/tags/Git/"},{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"}],"author":"QuricoLouis"},{"title":"树的遍历(评测机)","slug":"树的遍历（评测机）","date":"2021-04-15T07:41:45.000Z","updated":"2021-09-06T08:58:30.684Z","comments":true,"path":"posts/b3608e84.html","link":"","permalink":"http://quricolouis.github.io/posts/b3608e84.html","excerpt":"","text":"public class Tree { class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int val) { this.val = val; } TreeNode(int val, TreeNode left, TreeNode right) { this.val = val; this.left = left; this.right = right; } } public static void main(String[] args) { Integer[] data = {5, 4, 8, 11, null, 13, 4, 7, 2, null, null, null, 1}; Tree tree = new Tree(); TreeNode root = tree.createTree(data, 0); System.out.println(tree.preorderTraversal(root)); System.out.println(tree.inorderTraversal(root)); System.out.println(tree.postorderTraversal(root)); System.out.println(tree.levelOrder(root)); } /** * 创建树 * * @param arr * @param index * @return */ private TreeNode createTree(Integer[] arr, int index) { TreeNode treeNode = null; if (index &lt; arr.length) { Integer value = arr[index]; if (value == null) { return null; } treeNode = new TreeNode(value); treeNode.left = createTree(arr, 2 * index + 1); treeNode.right = createTree(arr, 2 * index + 2); return treeNode; } return treeNode; } /** * 前序遍历 * * @param root * @return */ public List&lt;Integer&gt; preorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); preorder(root, res); return res; } public void preorder(TreeNode root, List&lt;Integer&gt; res) { if (root == null) { return; } res.add(root.val); preorder(root.left, res); preorder(root.right, res); } /** * 中序遍历 * * @param root * @return */ public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); inorder(root, res); return res; } public void inorder(TreeNode root, List&lt;Integer&gt; res) { if (root == null) { return; } inorder(root.left, res); res.add(root.val); inorder(root.right, res); } /** * 后序遍历 * * @param root * @return */ public List&lt;Integer&gt; postorderTraversal(TreeNode root) { List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); postorder(root, res); return res; } public void postorder(TreeNode root, List&lt;Integer&gt; res) { if (root == null) return; postorder(root.left, res); postorder(root.right, res); res.add(root.val); } /** * 层序遍历 * * @param root * @return */ public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; queue = new ArrayDeque&lt;&gt;(); if (root != null) { queue.add(root); } while (!queue.isEmpty()) { int n = queue.size(); List&lt;Integer&gt; level = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; n; i++) { TreeNode node = queue.poll(); level.add(node.val); if (node.left != null) { queue.add(node.left); } if (node.right != null) { queue.add(node.right); } } res.add(level); } return res; }","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"http://quricolouis.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"http://quricolouis.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"树","slug":"树","permalink":"http://quricolouis.github.io/tags/%E6%A0%91/"}],"author":"QuricoLouis"},{"title":"链表(评测机)","slug":"链表（评测机）","date":"2021-04-11T07:41:45.000Z","updated":"2021-09-06T08:58:16.964Z","comments":true,"path":"posts/523c3831.html","link":"","permalink":"http://quricolouis.github.io/posts/523c3831.html","excerpt":"","text":"public class LinkedList { class ListNode { int val; ListNode next; ListNode() { } ListNode(int val) { this.val = val; } } public ListNode head; public ListNode tail; public static void main(String[] args) { int[] nums = new int[]{4,6,7,8,3,6,9}; LinkedList list = new LinkedList(); for (int num :nums) list.add(num); list.print(list.head); } /** * 链表添加数据 * @param date */ public void add(int date) { if (head == null) { head = new ListNode(date); tail = head; } else { tail.next = new ListNode(date); tail = tail.next; } } /** * 打印链表 * @param node */ public void print(ListNode node){ if(node == null) return; tail = node; while(tail != null){ System.out.print(tail.val + \" \"); tail = tail.next; } } }","categories":[{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"http://quricolouis.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"http://quricolouis.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"链表","slug":"链表","permalink":"http://quricolouis.github.io/tags/%E9%93%BE%E8%A1%A8/"}],"author":"QuricoLouis"}],"categories":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/categories/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"算法与数据结构","slug":"算法与数据结构","permalink":"http://quricolouis.github.io/categories/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"面试笔记","slug":"面试笔记","permalink":"http://quricolouis.github.io/tags/%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/"},{"name":"Java","slug":"Java","permalink":"http://quricolouis.github.io/tags/Java/"},{"name":"分布式","slug":"分布式","permalink":"http://quricolouis.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"JDK源码","slug":"JDK源码","permalink":"http://quricolouis.github.io/tags/JDK%E6%BA%90%E7%A0%81/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://quricolouis.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"Git","slug":"Git","permalink":"http://quricolouis.github.io/tags/Git/"},{"name":"算法","slug":"算法","permalink":"http://quricolouis.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"http://quricolouis.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"树","slug":"树","permalink":"http://quricolouis.github.io/tags/%E6%A0%91/"},{"name":"链表","slug":"链表","permalink":"http://quricolouis.github.io/tags/%E9%93%BE%E8%A1%A8/"}]}